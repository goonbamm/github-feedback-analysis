"""Metric calculation logic for GitHub feedback analysis."""

from __future__ import annotations

from dataclasses import dataclass
from datetime import datetime
from typing import Dict, List, Optional

from .console import Console
from .models import (
    AnalysisStatus,
    CollectionResult,
    MetricSnapshot,
    DetailedFeedbackSnapshot,
    CommitMessageFeedback,
    PRTitleFeedback,
    ReviewToneFeedback,
    IssueFeedback,
    MonthlyTrend,
    TechStackAnalysis,
    CollaborationNetwork,
    ReflectionPrompts,
    YearEndReview,
)

console = Console()


# Award tier configurations
AWARD_TIERS = {
    "commits": [
        (1000, "ğŸ’ ì½”ë“œ ì „ì„¤ ìƒ (ë‹¤ì´ì•„ëª¬ë“œ) â€” 1000íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ì €ì¥ì†Œì˜ ì‚´ì•„ìˆëŠ” ì—­ì‚¬ë¥¼ ì¼ìŠµë‹ˆë‹¤."),
        (500, "ğŸ† ì½”ë“œ ë§ˆìŠ¤í„° ìƒ (í”Œë˜í‹°ë„˜) â€” 500íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ì½”ë“œë² ì´ìŠ¤ì˜ ì¤‘ì¶”ë¥¼ ì™„ì„±í–ˆìŠµë‹ˆë‹¤."),
        (200, "ğŸ¥‡ ì½”ë“œ ëŒ€ì¥ì¥ì´ ìƒ (ê³¨ë“œ) â€” 200íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ì €ì¥ì†Œì˜ í•µì‹¬ì„ ë‹¨ë‹¨í•˜ê²Œ ë‹¤ì¡ŒìŠµë‹ˆë‹¤."),
        (100, "ğŸ¥ˆ ì½”ë“œ ì¥ì¸ ìƒ (ì‹¤ë²„) â€” 100íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ê¾¸ì¤€í•œ ê°œì„ ì„ ì´ì–´ê°”ìŠµë‹ˆë‹¤."),
        (50, "ğŸ¥‰ ì½”ë“œ ê²¬ìŠµìƒ ìƒ (ë¸Œë¡ ì¦ˆ) â€” 50íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ì„±ì¥ì˜ ë°œíŒì„ ë§ˆë ¨í–ˆìŠµë‹ˆë‹¤."),
    ],
    "pull_requests": [
        (200, "ğŸ’ ë¦´ë¦¬ìŠ¤ ì „ì„¤ ìƒ (ë‹¤ì´ì•„ëª¬ë“œ) â€” 200ê±´ ì´ìƒì˜ Pull Requestë¡œ ë°°í¬ì˜ ìƒˆ ì—­ì‚¬ë¥¼ ì—´ì—ˆìŠµë‹ˆë‹¤."),
        (100, "ğŸ† ë°°í¬ ì œë… ìƒ (í”Œë˜í‹°ë„˜) â€” 100ê±´ ì´ìƒì˜ Pull Requestë¡œ ë¦´ë¦¬ìŠ¤ í•¨ëŒ€ë¥¼ ì§€íœ˜í–ˆìŠµë‹ˆë‹¤."),
        (50, "ğŸ¥‡ ë¦´ë¦¬ìŠ¤ ì„ ì¥ ìƒ (ê³¨ë“œ) â€” 50ê±´ ì´ìƒì˜ Pull Requestë¡œ ì¶œì‹œ íë¦„ì„ ì´ëŒì—ˆìŠµë‹ˆë‹¤."),
        (25, "ğŸ¥ˆ ë¦´ë¦¬ìŠ¤ í•­í•´ì‚¬ ìƒ (ì‹¤ë²„) â€” 25ê±´ ì´ìƒì˜ Pull Requestë¡œ í˜‘ì—… ë¦´ë¦¬ìŠ¤ë¥¼ ì£¼ë„í–ˆìŠµë‹ˆë‹¤."),
        (10, "ğŸ¥‰ ë°°í¬ ì„ ì› ìƒ (ë¸Œë¡ ì¦ˆ) â€” 10ê±´ ì´ìƒì˜ Pull Requestë¡œ íŒ€ ë°°í¬ì— ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤."),
    ],
    "reviews": [
        (200, "ğŸ’ ì§€ì‹ ì „íŒŒì ìƒ (ë‹¤ì´ì•„ëª¬ë“œ) â€” 200íšŒ ì´ìƒì˜ ë¦¬ë·°ë¡œ íŒ€ ì „ì²´ì˜ ì„±ì¥ì„ ì´ëŒì—ˆìŠµë‹ˆë‹¤."),
        (100, "ğŸ† ë©˜í† ë§ ëŒ€ê°€ ìƒ (í”Œë˜í‹°ë„˜) â€” 100íšŒ ì´ìƒì˜ ë¦¬ë·°ë¡œ ì§€ì‹ ê³µìœ  ë¬¸í™”ë¥¼ ì •ì°©ì‹œì¼°ìŠµë‹ˆë‹¤."),
        (50, "ğŸ¥‡ ë¦¬ë·° ì „ë¬¸ê°€ ìƒ (ê³¨ë“œ) â€” 50íšŒ ì´ìƒì˜ ë¦¬ë·°ë¡œ ì½”ë“œ í’ˆì§ˆì„ í•œ ë‹¨ê³„ ëŒì–´ì˜¬ë ¸ìŠµë‹ˆë‹¤."),
        (20, "ğŸ¥ˆ ì„±ì¥ ë©˜í†  ìƒ (ì‹¤ë²„) â€” 20íšŒ ì´ìƒì˜ ë¦¬ë·°ë¡œ íŒ€ì˜ ì„±ì¥ì„ ë’·ë°›ì¹¨í–ˆìŠµë‹ˆë‹¤."),
        (10, "ğŸ¥‰ ì½”ë“œ ì§€ì›ì ìƒ (ë¸Œë¡ ì¦ˆ) â€” 10íšŒ ì´ìƒì˜ ë¦¬ë·°ë¡œ ë™ë£Œë¥¼ ë„ì™”ìŠµë‹ˆë‹¤."),
    ],
    "issues": [
        (50, "ğŸ”§ ë¬¸ì œ í•´ê²°ì‚¬ ìƒ â€” 50ê±´ ì´ìƒì˜ ì´ìŠˆë¥¼ ë‹¤ë£¨ë©° ì €ì¥ì†Œ í’ˆì§ˆì„ ê°œì„ í–ˆìŠµë‹ˆë‹¤."),
        (20, "ğŸ› ï¸ ë²„ê·¸ í—Œí„° ìƒ â€” 20ê±´ ì´ìƒì˜ ì´ìŠˆë¥¼ ì²˜ë¦¬í•˜ë©° ì•ˆì •ì„± í™•ë³´ì— ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤."),
    ],
    "velocity": [
        (50, "âš¡ ë²ˆê°œ ê°œë°œì ìƒ â€” ì›” í‰ê·  50íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ë†€ë¼ìš´ ì†ë„ë¥¼ ë³´ì—¬ì¤¬ìŠµë‹ˆë‹¤."),
        (20, "ğŸš€ ì†ë„ì™• ìƒ â€” ì›” í‰ê·  20íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ë¹ ë¥¸ ê°œë°œ í…œí¬ë¥¼ ìœ ì§€í–ˆìŠµë‹ˆë‹¤."),
        (10, "ğŸƒ ìŠ¤í”„ë¦°í„° ìƒ â€” ì›” í‰ê·  10íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ê¾¸ì¤€í•œ ì§„ì „ì„ ì´ë¤˜ìŠµë‹ˆë‹¤."),
    ],
    "collaboration": [
        (20, "ğŸ¤ í˜‘ì—… ë§ˆìŠ¤í„° ìƒ â€” ì›” í‰ê·  20íšŒ ì´ìƒì˜ PRê³¼ ë¦¬ë·°ë¡œ íŒ€ì›Œí¬ì˜ ì¤‘ì‹¬ì´ ë˜ì—ˆìŠµë‹ˆë‹¤."),
        (10, "ğŸ‘¥ í˜‘ì—… ì „ë¬¸ê°€ ìƒ â€” ì›” í‰ê·  10íšŒ ì´ìƒì˜ PRê³¼ ë¦¬ë·°ë¡œ íŒ€ ì‹œë„ˆì§€ë¥¼ ê°•í™”í–ˆìŠµë‹ˆë‹¤."),
        (5, "ğŸ¤— íŒ€ í”Œë ˆì´ì–´ ìƒ â€” ì›” í‰ê·  5íšŒ ì´ìƒì˜ PRê³¼ ë¦¬ë·°ë¡œ í˜‘ì—… ë¬¸í™”ì— ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤."),
    ],
    "activity_consistency": [
        ((30, 6), "ğŸ“… ê¾¸ì¤€í•¨ì˜ ë‹¬ì¸ ìƒ â€” 6ê°œì›” ì´ìƒ ì›” í‰ê·  30íšŒ ì´ìƒì˜ í™œë™ìœ¼ë¡œ ì¼ê´€ì„±ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤."),
        ((15, 3), "ğŸ”„ ì§€ì†ì„± ìƒ â€” ê¾¸ì¤€í•œ ì›”ë³„ í™œë™ìœ¼ë¡œ ì„±ì‹¤í•¨ì„ ë³´ì—¬ì¤¬ìŠµë‹ˆë‹¤."),
    ],
    "change_scale": [
        (10000, "ğŸŒ‹ ì½”ë“œ í™”ì‚° ìƒ â€” 10000ì¤„ ì´ìƒì˜ í­ë°œì ì¸ ë³€ê²½ìœ¼ë¡œ ìƒˆë¡œìš´ ì‹œëŒ€ë¥¼ ì—´ì—ˆìŠµë‹ˆë‹¤."),
        (5000, "ğŸ—ï¸ ëŒ€ê·œëª¨ ì•„í‚¤í…íŠ¸ ìƒ â€” 5000ì¤„ ì´ìƒì˜ ë³€ê²½ìœ¼ë¡œ ëŒ€ë‹´í•œ ë¦¬íŒ©í„°ë§ì„ ì™„ìˆ˜í–ˆìŠµë‹ˆë‹¤."),
        (2000, "ğŸ”¨ ëŒ€í˜• ë¹Œë” ìƒ â€” 2000ì¤„ ì´ìƒì˜ ë³€ê²½ìœ¼ë¡œ í° ê·œëª¨ì˜ ê°œì„ ì„ ì´ë¤„ëƒˆìŠµë‹ˆë‹¤."),
        (1000, "ğŸ  ì¤‘í˜• ê±´ì¶•ê°€ ìƒ â€” 1000ì¤„ ì´ìƒì˜ ë³€ê²½ìœ¼ë¡œ ì˜ë¯¸ìˆëŠ” ê°œì„ ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤."),
    ],
    "review_dedication": [
        (3.0, "ğŸ” ë¦¬ë·° ë§¤ë‹ˆì•„ ìƒ â€” ìì‹ ì˜ PRë³´ë‹¤ 3ë°° ì´ìƒ ë§ì€ ë¦¬ë·°ë¡œ íŒ€ ì„±ì¥ì— í—Œì‹ í–ˆìŠµë‹ˆë‹¤."),
        (2.0, "ğŸ‘ï¸ ì½”ë“œ ê°ì‹œì ìƒ â€” ìì‹ ì˜ PRë³´ë‹¤ 2ë°° ì´ìƒ ë§ì€ ë¦¬ë·°ë¡œ í’ˆì§ˆ ê´€ë¦¬ì— ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤."),
    ],
}


@dataclass(slots=True)
class Analyzer:
    """Transform collected data into actionable metrics."""

    web_base_url: str = "https://github.com"

    def compute_metrics(
        self,
        collection: CollectionResult,
        detailed_feedback: Optional[DetailedFeedbackSnapshot] = None,
        monthly_trends_data: Optional[List[Dict]] = None,
        tech_stack_data: Optional[Dict[str, int]] = None,
        collaboration_data: Optional[Dict[str, Any]] = None,
    ) -> MetricSnapshot:
        """Compute derived metrics from the collected artefacts."""

        console.log("Analyzing repository trends", f"repo={collection.repo}")

        (
            month_span,
            velocity_score,
            collaboration_score,
            stability_score,
            total_activity,
            period_label,
        ) = self._calculate_scores(collection)

        highlights = self._build_highlights(
            collection,
            period_label,
            month_span,
            velocity_score,
            total_activity,
        )
        spotlight_examples = self._build_spotlight_examples(collection)
        summary = self._build_summary(
            period_label,
            total_activity,
            velocity_score,
            collaboration_score,
            stability_score,
        )
        story_beats = self._build_story_beats(collection, period_label, total_activity)
        awards = self._determine_awards(collection)
        stats = self._build_stats(collection, velocity_score)
        evidence = self._build_evidence(collection)

        # Build year-end specific insights
        monthly_trends = self._build_monthly_trends(monthly_trends_data)
        tech_stack = self._build_tech_stack_analysis(tech_stack_data)
        collaboration = self._build_collaboration_network(collaboration_data)
        reflection_prompts = self._build_reflection_prompts(collection)
        year_end_review = self._build_year_end_review(collection, highlights, awards)

        return MetricSnapshot(
            repo=collection.repo,
            months=collection.months,
            generated_at=datetime.utcnow(),
            status=AnalysisStatus.ANALYSED,
            summary=summary,
            stats=stats,
            evidence=evidence,
            highlights=highlights,
            spotlight_examples=spotlight_examples,
            yearbook_story=story_beats,
            awards=awards,
            detailed_feedback=detailed_feedback,
            monthly_trends=monthly_trends,
            tech_stack=tech_stack,
            collaboration=collaboration,
            reflection_prompts=reflection_prompts,
            year_end_review=year_end_review,
        )

    def _calculate_scores(
        self, collection: CollectionResult
    ) -> tuple[int, float, float, int, int, str]:
        month_span = max(collection.months, 1)
        velocity_score = collection.commits / month_span
        collaboration_score = (collection.pull_requests + collection.reviews) / month_span
        stability_score = max(collection.commits - collection.issues, 0)
        total_activity = collection.commits + collection.pull_requests + collection.reviews
        period_label = "ì˜¬í•´" if collection.months >= 12 else f"ì§€ë‚œ {collection.months}ê°œì›”"

        return (
            month_span,
            velocity_score,
            collaboration_score,
            stability_score,
            total_activity,
            period_label,
        )

    def _build_highlights(
        self,
        collection: CollectionResult,
        period_label: str,
        month_span: int,
        velocity_score: float,
        total_activity: int,
    ) -> List[str]:
        highlights: List[str] = []
        if collection.commits:
            highlights.append(
                f"{period_label}ì— ì´ {collection.commits}íšŒì˜ ì»¤ë°‹ìœ¼ë¡œ ì½”ë“œë¥¼ ë‹¤ë“¬ê³  ì›” í‰ê·  {velocity_score:.1f}íšŒì˜ ê°œì„ ì„ ì´ì–´ê°”ìŠµë‹ˆë‹¤."
            )
        if collection.pull_requests:
            highlights.append(
                f"{collection.pull_requests}ê±´ì˜ Pull Requestë¥¼ ë³‘í•©í•˜ë©° íŒ€ ë°°í¬ ì£¼ê¸°ë¥¼ ì•ˆì •í™”í–ˆê³  ì›” {collection.pull_requests / month_span:.1f}ê±´ì˜ ë¦´ë¦¬ìŠ¤ë¥¼ ìœ ì§€í–ˆìŠµë‹ˆë‹¤."
            )
        if collection.reviews:
            highlights.append(
                f"{collection.reviews}íšŒì˜ ì½”ë“œ ë¦¬ë·°ë¥¼ í†µí•´ í˜‘ì—… ë¬¸í™”ë¥¼ ê°•í™”í–ˆìŠµë‹ˆë‹¤."
            )
        if collection.issues:
            highlights.append(
                f"í™œë™ ëŒ€ë¹„ {collection.issues}ê±´ì˜ ì´ìŠˆë¡œ ì•ˆì •ì„±ì„ ì§€ì¼°ìŠµë‹ˆë‹¤."
            )
        if not highlights and total_activity == 0:
            highlights.append("ë¶„ì„ ê¸°ê°„ ë™ì•ˆ ëšœë ·í•œ í™œë™ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        return highlights

    def _build_spotlight_examples(self, collection: CollectionResult) -> Dict[str, List[str]]:
        spotlight_examples: Dict[str, List[str]] = {}
        if not collection.pull_request_examples:
            return spotlight_examples

        pr_lines = []
        for pr in collection.pull_request_examples[:3]:
            change_volume = pr.additions + pr.deletions
            scale_phrase = f"ë³€ê²½ {change_volume}ì¤„" if change_volume else "ê²½ëŸ‰ ë³€ê²½"
            merged_phrase = (
                f"{pr.merged_at.date().isoformat()} ë³‘í•©"
                if pr.merged_at
                else "ë¯¸ë³‘í•©"
            )
            pr_lines.append(
                f"PR #{pr.number} Â· {pr.title} â€” {pr.author} ({pr.created_at.date().isoformat()}, {merged_phrase}, {scale_phrase}) Â· {pr.html_url}"
            )
        spotlight_examples["pull_requests"] = pr_lines
        return spotlight_examples

    def _build_summary(
        self,
        period_label: str,
        total_activity: int,
        velocity_score: float,
        collaboration_score: float,
        stability_score: int,
    ) -> Dict[str, str]:
        return {
            "velocity": f"Average {velocity_score:.1f} commits per month",
            "collaboration": "{:.1f} combined PRs and reviews per month".format(collaboration_score),
            "stability": f"Net stability score of {stability_score}",
            "growth": f"{period_label} ë™ì•ˆ {total_activity}ê±´ì˜ í™œë™ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.",
        }

    def _build_story_beats(
        self,
        collection: CollectionResult,
        period_label: str,
        total_activity: int,
    ) -> List[str]:
        story_beats: List[str] = []
        if total_activity:
            story_beats.append(
                f"{period_label} ë™ì•ˆ {collection.repo} ì €ì¥ì†Œì—ì„œ ì´ {total_activity}ê±´ì˜ í™œë™ì„ í¼ì¹˜ë©° ì„±ì¥ ì—”ì§„ì„ ê°€ë™í–ˆìŠµë‹ˆë‹¤."
            )
        else:
            story_beats.append(
                f"{period_label}ì—ëŠ” ì ì‹œ ìˆ¨ì„ ê³ ë¥´ë©° ë‹¤ìŒ ë„ì•½ì„ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤."
            )

        contribution_domains = [
            ("ì»¤ë°‹", collection.commits, "ì§€ì†ì ì¸ ë¦¬íŒ©í„°ë§ê³¼ ê¸°ëŠ¥ í™•ì¥ì„ ì´ëŒì—ˆìŠµë‹ˆë‹¤."),
            ("Pull Request", collection.pull_requests, "í˜‘ì—… ë¦´ë¦¬ìŠ¤ë¥¼ ì£¼ë„í•˜ë©° ë°°í¬ íŒŒì´í”„ë¼ì¸ì„ ì§€ì¼°ìŠµë‹ˆë‹¤."),
            ("ë¦¬ë·°", collection.reviews, "íŒ€ ë™ë£Œë“¤ì˜ ì„±ì¥ì„ ë•ëŠ” ì´˜ì´˜í•œ í”¼ë“œë°±ì„ ì „ë‹¬í–ˆìŠµë‹ˆë‹¤."),
        ]
        top_domain = max(contribution_domains, key=lambda entry: entry[1])
        if top_domain[1]:
            story_beats.append(
                f"ê°€ì¥ ëˆˆì— ëˆ ì˜ì—­ì€ {top_domain[0]} {top_domain[1]}íšŒë¡œ, {top_domain[2]}"
            )

        if collection.pull_request_examples:
            exemplar = collection.pull_request_examples[0]
            merge_phrase = (
                f"{exemplar.merged_at.date().isoformat()} ë³‘í•©"
                if exemplar.merged_at
                else "ì•„ì§ ì§„í–‰ ì¤‘"
            )
            scale = exemplar.additions + exemplar.deletions
            scale_phrase = f"ë³€ê²½ {scale}ì¤„" if scale else "ê²½ëŸ‰ ë³€ê²½"
            story_beats.append(
                "ëŒ€í‘œì‘ìœ¼ë¡œëŠ” PR #{num} `{title}`({author})ê°€ ìˆìŠµë‹ˆë‹¤ â€” {created} ì‘ì„±, {merge} Â· {scale_phrase}.".format(
                    num=exemplar.number,
                    title=exemplar.title,
                    author=exemplar.author,
                    created=exemplar.created_at.date().isoformat(),
                    merge=merge_phrase,
                    scale_phrase=scale_phrase,
                )
            )

        return story_beats

    def _determine_awards(self, collection: CollectionResult) -> List[str]:
        """Determine awards based on collection metrics using data-driven tier system."""
        awards: List[str] = []
        month_span = max(collection.months, 1)

        # Apply tier-based awards
        self._add_tier_award(awards, "commits", collection.commits)
        self._add_tier_award(awards, "pull_requests", collection.pull_requests)
        self._add_tier_award(awards, "reviews", collection.reviews)
        self._add_tier_award(awards, "issues", collection.issues)

        # Velocity-based awards
        velocity_score = collection.commits / month_span
        self._add_tier_award(awards, "velocity", velocity_score)

        # Collaboration-based awards
        collaboration_score = (collection.pull_requests + collection.reviews) / month_span
        self._add_tier_award(awards, "collaboration", collaboration_score)

        # Activity consistency awards
        total_activity = collection.commits + collection.pull_requests + collection.reviews
        activity_per_month = total_activity / month_span
        for (threshold_activity, threshold_months), award_text in AWARD_TIERS["activity_consistency"]:
            if activity_per_month >= threshold_activity and collection.months >= threshold_months:
                awards.append(award_text)
                break

        # All-rounder award
        if (collection.commits >= 50 and
            collection.pull_requests >= 15 and
            collection.reviews >= 15):
            awards.append(
                "ğŸŒŸ ë‹¤ì¬ë‹¤ëŠ¥ ìƒ â€” ì»¤ë°‹, PR, ë¦¬ë·° ì „ ì˜ì—­ì—ì„œ ê· í˜•ì¡íŒ ê¸°ì—¬ë¥¼ ë³´ì—¬ì¤¬ìŠµë‹ˆë‹¤."
            )

        # Large-scale change awards
        if collection.pull_request_examples:
            max_change = max(
                (pr.additions + pr.deletions for pr in collection.pull_request_examples),
                default=0
            )
            self._add_tier_award(awards, "change_scale", max_change)

            # Micro-commit artist award (ë§ì€ ì‘ì€ PR)
            small_prs = sum(1 for pr in collection.pull_request_examples
                          if (pr.additions + pr.deletions) < 50)
            if small_prs >= 10:
                awards.append(
                    "ğŸ¨ ë¯¸ì„¸ ì¡°ìœ¨ ì¥ì¸ ìƒ â€” 10ê°œ ì´ìƒì˜ ì‘ì€ PRë¡œ ì ì§„ì  ê°œì„ ì˜ ë¯¸í•™ì„ ë³´ì—¬ì¤¬ìŠµë‹ˆë‹¤."
                )

            # Big bang award (í° PR)
            huge_prs = sum(1 for pr in collection.pull_request_examples
                         if (pr.additions + pr.deletions) > 1000)
            if huge_prs >= 3:
                awards.append(
                    "ğŸ’¥ ë¹…ë±… ìƒ â€” 3ê°œ ì´ìƒì˜ ëŒ€ê·œëª¨ PRë¡œ í˜ì‹ ì ì¸ ë³€í™”ë¥¼ ì£¼ë„í–ˆìŠµë‹ˆë‹¤."
                )

            # Quick merger award (ë¹ ë¥¸ ë³‘í•©)
            quick_merges = sum(1 for pr in collection.pull_request_examples
                             if pr.merged_at and pr.created_at and
                             (pr.merged_at - pr.created_at).total_seconds() < 3600)
            if quick_merges >= 5:
                awards.append(
                    "âš¡ ìŠ¤í”¼ë“œ ë¨¸ì € ìƒ â€” 5ê°œ ì´ìƒì˜ PRì„ 1ì‹œê°„ ë‚´ ë³‘í•©í•˜ëŠ” ë¯¼ì²©í•¨ì„ ë³´ì—¬ì¤¬ìŠµë‹ˆë‹¤."
                )

        # Review dedication awards
        if collection.pull_requests > 0:
            review_ratio = collection.reviews / collection.pull_requests
            self._add_tier_award(awards, "review_dedication", review_ratio)

        # Balanced contributor award
        if (collection.commits > 0 and collection.pull_requests > 0 and collection.reviews > 0):
            commit_ratio = collection.commits / total_activity
            pr_ratio = collection.pull_requests / total_activity
            review_ratio = collection.reviews / total_activity

            # Check if all three are balanced (each between 20% and 50%)
            if all(0.2 <= ratio <= 0.5 for ratio in [commit_ratio, pr_ratio, review_ratio]):
                awards.append(
                    "âš–ï¸ ê· í˜•ì¡íŒ ê¸°ì—¬ì ìƒ â€” ì»¤ë°‹, PR, ë¦¬ë·°ë¥¼ ì™„ë²½í•˜ê²Œ ê· í˜•ìˆê²Œ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤."
                )

        # High PR merge rate
        if collection.pull_requests >= 20 and collection.pull_request_examples:
            merged_count = sum(1 for pr in collection.pull_request_examples if pr.merged_at)
            merge_rate = merged_count / len(collection.pull_request_examples)
            if merge_rate >= 0.9:
                awards.append(
                    "âœ… ë¨¸ì§€ ë§ˆìŠ¤í„° ìƒ â€” 90% ì´ìƒì˜ ë†’ì€ PR ë³‘í•©ë¥ ë¡œ íƒì›”í•œ ì½”ë“œ í’ˆì§ˆì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤."
                )

        # Stability award
        if collection.issues and collection.issues <= max(collection.commits // 6, 1):
            awards.append(
                "ğŸ›¡ï¸ ì•ˆì • ì§€í‚´ì´ ìƒ â€” í™œë™ ëŒ€ë¹„ ì ì€ ì´ìŠˆë¡œ ì•ˆì •ì„±ì„ ì§€ì¼°ìŠµë‹ˆë‹¤."
            )

        # Issue warrior award
        if collection.issues > collection.commits and collection.issues >= 30:
            awards.append(
                "ğŸ› ï¸ ì´ìŠˆ ì „ì‚¬ ìƒ â€” ì»¤ë°‹ë³´ë‹¤ ë§ì€ ì´ìŠˆ ì²˜ë¦¬ë¡œ í”„ë¡œì íŠ¸ ì•ˆì •ì„±ì— ì§‘ì¤‘í–ˆìŠµë‹ˆë‹¤."
            )

        # Review champion (ë¦¬ë·°ê°€ ê°€ì¥ ë§ì€ ê²½ìš°)
        if (collection.reviews > collection.commits and
            collection.reviews > collection.pull_requests and
            collection.reviews >= 30):
            awards.append(
                "ğŸ‘¨â€ğŸ« ë¦¬ë·° ì±”í”¼ì–¸ ìƒ â€” ë‹¤ë¥¸ í™œë™ë³´ë‹¤ ë¦¬ë·°ì— ì§‘ì¤‘í•˜ë©° íŒ€ ì„±ì¥ì˜ ë©˜í† ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤."
            )

        # Commit machine (ì»¤ë°‹ì´ ì••ë„ì ìœ¼ë¡œ ë§ì€ ê²½ìš°)
        if (collection.commits > collection.pull_requests * 3 and
            collection.commits > collection.reviews * 3 and
            collection.commits >= 100):
            awards.append(
                "ğŸ”¥ ì»¤ë°‹ ë¨¸ì‹  ìƒ â€” ì••ë„ì ì¸ ì»¤ë°‹ ìˆ˜ë¡œ ì½”ë“œë² ì´ìŠ¤ì˜ í•µì‹¬ ë™ë ¥ì´ ë˜ì—ˆìŠµë‹ˆë‹¤."
            )

        # Renaissance developer (ëª¨ë“  ì§€í‘œê°€ ë†’ìŒ)
        if (collection.commits >= 100 and
            collection.pull_requests >= 30 and
            collection.reviews >= 50 and
            collection.issues >= 10):
            awards.append(
                "ğŸ­ ë¥´ë„¤ìƒìŠ¤ ê°œë°œì ìƒ â€” ëª¨ë“  ì˜ì—­ì—ì„œ ë›°ì–´ë‚œ í™œì•½ì„ í¼ì¹œ ì™„ë²½í•œ ì˜¬ë¼ìš´ë”ì…ë‹ˆë‹¤."
            )

        # Consistency king (ë§¤ìš° ê¾¸ì¤€í•œ í™œë™)
        if collection.months >= 6 and activity_per_month >= 20:
            variance_threshold = activity_per_month * 0.3
            if variance_threshold > 0:  # Assuming low variance
                awards.append(
                    "ğŸ‘‘ ì¼ê´€ì„±ì˜ ì™• ìƒ â€” 6ê°œì›” ì´ìƒ ì›” 20íšŒ ì´ìƒì˜ ê¾¸ì¤€í•œ í™œë™ì„ ìœ ì§€í–ˆìŠµë‹ˆë‹¤."
                )

        # Sprint finisher (ìµœê·¼ í™œë™ì´ ë§ì€ ê²½ìš° - ì¶”ì •)
        if collection.months >= 3 and velocity_score >= 30:
            awards.append(
                "ğŸ ìŠ¤í”„ë¦°íŠ¸ í”¼ë‹ˆì…” ìƒ â€” ë†’ì€ ì›”í‰ê·  ì†ë„ë¡œ í”„ë¡œì íŠ¸ë¥¼ ë¹ ë¥´ê²Œ ì „ì§„ì‹œì¼°ìŠµë‹ˆë‹¤."
            )

        # Quality guardian (ì´ìŠˆ ëŒ€ë¹„ ë†’ì€ ë¦¬ë·°)
        if collection.reviews >= 30 and collection.issues > 0:
            review_issue_ratio = collection.reviews / collection.issues
            if review_issue_ratio >= 3:
                awards.append(
                    "ğŸ¯ í’ˆì§ˆ ìˆ˜í˜¸ì ìƒ â€” ì´ìŠˆ ëŒ€ë¹„ 3ë°° ì´ìƒì˜ ë¦¬ë·°ë¡œ ì‚¬ì „ í’ˆì§ˆ ê´€ë¦¬ì— í˜ì¼ìŠµë‹ˆë‹¤."
                )

        # Documentation hero (READMEë‚˜ ë¬¸ì„œ ê¸°ì—¬ - ê°„ì ‘ ì¶”ì •)
        # Note: ì‹¤ì œë¡œëŠ” PR ì˜ˆì œë¥¼ í†µí•´ í™•ì¸í•´ì•¼ í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” PR ìˆ˜ì™€ ì»¤ë°‹ ë¹„ìœ¨ë¡œ ì¶”ì •
        if collection.pull_requests >= 20 and collection.pull_request_examples:
            # PR íƒ€ì´í‹€ì— docs, readme, documentation ë“±ì´ í¬í•¨ëœ ê²½ìš°ë¥¼ ì²´í¬
            doc_prs = sum(1 for pr in collection.pull_request_examples
                         if any(keyword in pr.title.lower()
                               for keyword in ['doc', 'readme', 'documentation', 'ë¬¸ì„œ']))
            if doc_prs >= 5:
                awards.append(
                    "ğŸ“š ë¬¸ì„œí™” ì˜ì›… ìƒ â€” 5ê°œ ì´ìƒì˜ ë¬¸ì„œ PRë¡œ ì§€ì‹ ê³µìœ ì— ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤."
                )

        # Test advocate (test ê´€ë ¨ PR)
        if collection.pull_request_examples:
            test_prs = sum(1 for pr in collection.pull_request_examples
                          if any(keyword in pr.title.lower()
                                for keyword in ['test', 'testing', 'í…ŒìŠ¤íŠ¸', 'spec']))
            if test_prs >= 5:
                awards.append(
                    "ğŸ§ª í…ŒìŠ¤íŠ¸ ì˜¹í˜¸ì ìƒ â€” 5ê°œ ì´ìƒì˜ í…ŒìŠ¤íŠ¸ PRë¡œ ì½”ë“œ ì•ˆì •ì„±ì„ ê°•í™”í–ˆìŠµë‹ˆë‹¤."
                )

        # Refactoring master (refactor ê´€ë ¨ PR)
        if collection.pull_request_examples:
            refactor_prs = sum(1 for pr in collection.pull_request_examples
                              if any(keyword in pr.title.lower()
                                    for keyword in ['refactor', 'refactoring', 'ë¦¬íŒ©í„°ë§', 'cleanup', 'clean']))
            if refactor_prs >= 5:
                awards.append(
                    "â™»ï¸ ë¦¬íŒ©í„°ë§ ë§ˆìŠ¤í„° ìƒ â€” 5ê°œ ì´ìƒì˜ ë¦¬íŒ©í„°ë§ PRë¡œ ì½”ë“œ í’ˆì§ˆì„ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤."
                )

        # Bug squasher (fix, bug ê´€ë ¨ PR)
        if collection.pull_request_examples:
            bug_prs = sum(1 for pr in collection.pull_request_examples
                         if any(keyword in pr.title.lower()
                               for keyword in ['fix', 'bug', 'hotfix', 'ë²„ê·¸', 'ìˆ˜ì •']))
            if bug_prs >= 10:
                awards.append(
                    "ğŸ› ë²„ê·¸ ìŠ¤ì¿¼ì…” ìƒ â€” 10ê°œ ì´ìƒì˜ ë²„ê·¸ ìˆ˜ì • PRë¡œ ì•ˆì •ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤."
                )

        # Feature factory (feature, feat ê´€ë ¨ PR)
        if collection.pull_request_examples:
            feature_prs = sum(1 for pr in collection.pull_request_examples
                             if any(keyword in pr.title.lower()
                                   for keyword in ['feature', 'feat', 'add', 'new', 'ì¶”ê°€', 'ê¸°ëŠ¥']))
            if feature_prs >= 10:
                awards.append(
                    "ğŸ­ ê¸°ëŠ¥ ê³µì¥ ìƒ â€” 10ê°œ ì´ìƒì˜ ê¸°ëŠ¥ ì¶”ê°€ PRë¡œ ì œí’ˆì„ í’ë¶€í•˜ê²Œ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤."
                )

        # Early bird / Night owl (ì‹œê°„ ê¸°ë°˜ì€ ë°ì´í„°ê°€ ì—†ì–´ ìƒëµ)

        # Default award if no other awards
        if not awards:
            awards.append(
                "ğŸŒ± ì„±ì¥ ì”¨ì•— ìƒ â€” ì‘ì€ ë°œê±¸ìŒë“¤ì´ ëª¨ì—¬ ë‚´ì¼ì˜ í° ì„±ì¥ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤."
            )

        return awards

    @staticmethod
    def _add_tier_award(awards: List[str], category: str, value: float) -> None:
        """Add tier-based award if value meets threshold.

        Args:
            awards: List to append awards to
            category: Award category key from AWARD_TIERS
            value: Metric value to check against thresholds
        """
        if category not in AWARD_TIERS:
            return

        for threshold, award_text in AWARD_TIERS[category]:
            if value >= threshold:
                awards.append(award_text)
                break

    def _build_stats(self, collection: CollectionResult, velocity_score: float) -> Dict[str, Dict[str, float]]:
        return {
            "commits": {
                "total": float(collection.commits),
                "per_month": velocity_score,
            },
            "pull_requests": {
                "total": float(collection.pull_requests),
            },
            "reviews": {
                "total": float(collection.reviews),
            },
            "issues": {
                "total": float(collection.issues),
            },
        }

    def _build_evidence(self, collection: CollectionResult) -> Dict[str, List[str]]:
        repo_root = f"{self.web_base_url.rstrip('/')}/{collection.repo}"
        return {
            "commits": [
                f"{repo_root}/commits",
            ],
            "pull_requests": [
                f"{repo_root}/pulls",
            ],
        }

    def build_detailed_feedback(
        self,
        commit_analysis: Optional[Dict] = None,
        pr_title_analysis: Optional[Dict] = None,
        review_tone_analysis: Optional[Dict] = None,
        issue_analysis: Optional[Dict] = None,
    ) -> DetailedFeedbackSnapshot:
        """Build detailed feedback snapshot from LLM analysis results."""

        commit_feedback = None
        if commit_analysis:
            commit_feedback = CommitMessageFeedback(
                total_commits=commit_analysis.get("good_messages", 0)
                + commit_analysis.get("poor_messages", 0),
                good_messages=commit_analysis.get("good_messages", 0),
                poor_messages=commit_analysis.get("poor_messages", 0),
                suggestions=commit_analysis.get("suggestions", []),
                examples_good=commit_analysis.get("examples_good", []),
                examples_poor=commit_analysis.get("examples_poor", []),
            )

        pr_title_feedback = None
        if pr_title_analysis:
            pr_title_feedback = PRTitleFeedback(
                total_prs=pr_title_analysis.get("clear_titles", 0)
                + pr_title_analysis.get("vague_titles", 0),
                clear_titles=pr_title_analysis.get("clear_titles", 0),
                vague_titles=pr_title_analysis.get("vague_titles", 0),
                suggestions=pr_title_analysis.get("suggestions", []),
                examples_good=pr_title_analysis.get("examples_good", []),
                examples_poor=pr_title_analysis.get("examples_poor", []),
            )

        review_tone_feedback = None
        if review_tone_analysis:
            review_tone_feedback = ReviewToneFeedback(
                total_reviews=review_tone_analysis.get("constructive_reviews", 0)
                + review_tone_analysis.get("harsh_reviews", 0)
                + review_tone_analysis.get("neutral_reviews", 0),
                constructive_reviews=review_tone_analysis.get("constructive_reviews", 0),
                harsh_reviews=review_tone_analysis.get("harsh_reviews", 0),
                neutral_reviews=review_tone_analysis.get("neutral_reviews", 0),
                suggestions=review_tone_analysis.get("suggestions", []),
                examples_good=review_tone_analysis.get("examples_good", []),
                examples_improve=review_tone_analysis.get("examples_improve", []),
            )

        issue_feedback = None
        if issue_analysis:
            issue_feedback = IssueFeedback(
                total_issues=issue_analysis.get("well_described", 0)
                + issue_analysis.get("poorly_described", 0),
                well_described=issue_analysis.get("well_described", 0),
                poorly_described=issue_analysis.get("poorly_described", 0),
                suggestions=issue_analysis.get("suggestions", []),
                examples_good=issue_analysis.get("examples_good", []),
                examples_poor=issue_analysis.get("examples_poor", []),
            )

        return DetailedFeedbackSnapshot(
            commit_feedback=commit_feedback,
            pr_title_feedback=pr_title_feedback,
            review_tone_feedback=review_tone_feedback,
            issue_feedback=issue_feedback,
        )

    def _build_monthly_trends(
        self, monthly_trends_data: Optional[List[Dict]]
    ) -> List[MonthlyTrend]:
        """Build monthly trend objects from raw data."""
        if not monthly_trends_data:
            return []

        trends = []
        for data in monthly_trends_data:
            trends.append(
                MonthlyTrend(
                    month=data.get("month", ""),
                    commits=data.get("commits", 0),
                    pull_requests=data.get("pull_requests", 0),
                    reviews=data.get("reviews", 0),
                    issues=data.get("issues", 0),
                )
            )
        return trends

    def _build_tech_stack_analysis(
        self, tech_stack_data: Optional[Dict[str, int]]
    ) -> Optional[TechStackAnalysis]:
        """Analyze technology stack from file changes."""
        if not tech_stack_data:
            return None

        # Calculate top languages
        sorted_languages = sorted(
            tech_stack_data.items(), key=lambda x: x[1], reverse=True
        )
        top_languages = [lang for lang, _ in sorted_languages[:5]]

        # Calculate diversity score (Shannon entropy normalized)
        total_files = sum(tech_stack_data.values())
        if total_files == 0:
            diversity_score = 0.0
        else:
            import math
            entropy = 0.0
            for count in tech_stack_data.values():
                if count > 0:
                    p = count / total_files
                    entropy -= p * math.log2(p)
            # Normalize to 0-1 range (max entropy is log2(n))
            max_entropy = math.log2(len(tech_stack_data)) if len(tech_stack_data) > 1 else 1
            diversity_score = entropy / max_entropy if max_entropy > 0 else 0.0

        return TechStackAnalysis(
            languages=tech_stack_data,
            top_languages=top_languages,
            diversity_score=diversity_score,
        )

    def _build_collaboration_network(
        self, collaboration_data: Optional[Dict[str, Any]]
    ) -> Optional[CollaborationNetwork]:
        """Build collaboration network from reviewer data."""
        if not collaboration_data:
            return None

        pr_reviewers = collaboration_data.get("pr_reviewers", {})
        sorted_reviewers = sorted(
            pr_reviewers.items(), key=lambda x: x[1], reverse=True
        )
        top_reviewers = [reviewer for reviewer, _ in sorted_reviewers[:5]]

        return CollaborationNetwork(
            pr_reviewers=pr_reviewers,
            top_reviewers=top_reviewers,
            review_received_count=collaboration_data.get("review_received_count", 0),
            unique_collaborators=collaboration_data.get("unique_collaborators", 0),
        )

    def _build_reflection_prompts(
        self, collection: CollectionResult
    ) -> ReflectionPrompts:
        """Generate self-reflection questions for year-end review."""
        questions = [
            "ì˜¬í•´ ë‚´ê°€ ê°€ì¥ ìë‘ìŠ¤ëŸ¬ì›Œí•˜ëŠ” ê¸°ìˆ ì  ì„±ì·¨ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
            "ê°€ì¥ ì–´ë ¤ì› ë˜ ê¸°ìˆ ì  ë„ì „ì€ ë¬´ì—‡ì´ì—ˆê³ , ì–´ë–»ê²Œ ê·¹ë³µí–ˆë‚˜ìš”?",
            "ì˜¬í•´ ìƒˆë¡­ê²Œ ë°°ìš´ ê¸°ìˆ ì´ë‚˜ ë„êµ¬ ì¤‘ ê°€ì¥ ìœ ìš©í–ˆë˜ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ì½”ë“œ ë¦¬ë·°ë¥¼ í†µí•´ ë°›ì€ í”¼ë“œë°± ì¤‘ ê°€ì¥ ê¸°ì–µì— ë‚¨ëŠ” ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "íŒ€ì›ë“¤ê³¼ì˜ í˜‘ì—…ì—ì„œ ê°€ì¥ ë¿Œë“¯í–ˆë˜ ìˆœê°„ì€ ì–¸ì œì˜€ë‚˜ìš”?",
            "ë‚´ ì½”ë“œê°€ íŒ€ì´ë‚˜ ì‚¬ìš©ìì—ê²Œ ê°€ì¥ í° ì˜í–¥ì„ ì¤€ ìˆœê°„ì€ ì–¸ì œì˜€ë‚˜ìš”?",
            "ì˜¬í•´ ë‚´ ê°œë°œ í”„ë¡œì„¸ìŠ¤ë‚˜ ìŠµê´€ì—ì„œ ê°œì„ ëœ ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ì•ìœ¼ë¡œ ë” ë°œì „ì‹œí‚¤ê³  ì‹¶ì€ ê¸°ìˆ  ì˜ì—­ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ë‚´ë…„ì— ë„ì „í•˜ê³  ì‹¶ì€ ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ë‚˜ ê¸°ìˆ ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ê°œë°œìë¡œì„œ ë‚´ë…„ì˜ ë‚˜ëŠ” ì–´ë–¤ ëª¨ìŠµì´ê¸¸ ë°”ë¼ë‚˜ìš”?",
        ]

        # Add context-specific questions based on activity
        if collection.commits > 100:
            questions.append(
                f"ì˜¬í•´ {collection.commits}íšŒì˜ ì»¤ë°‹ì„ ì‘ì„±í–ˆìŠµë‹ˆë‹¤. ì´ ì¤‘ ê°€ì¥ ì˜ë¯¸ìˆì—ˆë˜ ì»¤ë°‹ì€ ë¬´ì—‡ì´ì—ˆë‚˜ìš”?"
            )

        if collection.reviews > 50:
            questions.append(
                f"{collection.reviews}íšŒì˜ ì½”ë“œ ë¦¬ë·°ë¥¼ ì§„í–‰í–ˆìŠµë‹ˆë‹¤. ë¦¬ë·°ë¥¼ í†µí•´ ë°°ìš´ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?"
            )

        if collection.pull_requests > 30:
            questions.append(
                f"{collection.pull_requests}ê°œì˜ Pull Requestë¥¼ ì‘ì„±í–ˆìŠµë‹ˆë‹¤. ê°€ì¥ ë³µì¡í–ˆë˜ PRì€ ë¬´ì—‡ì´ì—ˆê³ , ì–´ë–¤ ì ì´ ì–´ë ¤ì› ë‚˜ìš”?"
            )

        return ReflectionPrompts(questions=questions)

    def _build_year_end_review(
        self,
        collection: CollectionResult,
        highlights: List[str],
        awards: List[str],
    ) -> YearEndReview:
        """Generate year-end specific review content."""

        # Proudest moments based on metrics
        proudest_moments = []
        if collection.commits > 200:
            proudest_moments.append(
                f"ì´ {collection.commits}íšŒì˜ ì»¤ë°‹ìœ¼ë¡œ ê¾¸ì¤€íˆ ì½”ë“œë² ì´ìŠ¤ë¥¼ ê°œì„ í–ˆìŠµë‹ˆë‹¤."
            )
        if collection.pull_requests > 50:
            proudest_moments.append(
                f"{collection.pull_requests}ê°œì˜ Pull Requestë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¨¸ì§€í–ˆìŠµë‹ˆë‹¤."
            )
        if collection.reviews > 50:
            proudest_moments.append(
                f"{collection.reviews}íšŒì˜ ì½”ë“œ ë¦¬ë·°ë¡œ íŒ€ì˜ ì½”ë“œ í’ˆì§ˆ í–¥ìƒì— ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤."
            )
        if not proudest_moments:
            proudest_moments.append(
                "ê¾¸ì¤€í•œ í™œë™ìœ¼ë¡œ í”„ë¡œì íŠ¸ ë°œì „ì— ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤."
            )

        # Challenges (generic, to be filled by user)
        biggest_challenges = [
            "ë³µì¡í•œ ê¸°ìˆ ì  ë¬¸ì œë¥¼ í•´ê²°í•˜ë©° ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ í‚¤ì› ìŠµë‹ˆë‹¤.",
            "ìƒˆë¡œìš´ ê¸°ìˆ  ìŠ¤íƒì„ í•™ìŠµí•˜ê³  í”„ë¡œì íŠ¸ì— ì ìš©í–ˆìŠµë‹ˆë‹¤.",
            "íŒ€ì›ë“¤ê³¼ì˜ í˜‘ì—…ì„ í†µí•´ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ìŠ¤í‚¬ì„ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.",
        ]

        # Lessons learned
        lessons_learned = [
            "ì‘ê³  ìì£¼ ì»¤ë°‹í•˜ëŠ” ê²ƒì´ ì½”ë“œ ë¦¬ë·°ì™€ í˜‘ì—…ì— ë” íš¨ê³¼ì ì…ë‹ˆë‹¤.",
            "ì½”ë“œ ë¦¬ë·°ëŠ” ë‹¨ìˆœí•œ ë²„ê·¸ ì°¾ê¸°ê°€ ì•„ë‹Œ ì§€ì‹ ê³µìœ ì˜ ì¥ì…ë‹ˆë‹¤.",
            "ì¢‹ì€ ì»¤ë°‹ ë©”ì‹œì§€ì™€ PR ì„¤ëª…ì€ ë¯¸ë˜ì˜ ë‚˜ì™€ íŒ€ì›ë“¤ì„ ìœ„í•œ íˆ¬ìì…ë‹ˆë‹¤.",
        ]

        # Next year goals
        next_year_goals = [
            "ìƒˆë¡œìš´ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë‚˜ í”„ë ˆì„ì›Œí¬ë¥¼ í•™ìŠµí•˜ì—¬ ê¸°ìˆ  ìŠ¤íƒ ë‹¤ë³€í™”",
            "ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ì— ê¸°ì—¬í•˜ì—¬ ì»¤ë®¤ë‹ˆí‹° ì°¸ì—¬ í™•ëŒ€",
            "ê¸°ìˆ  ë¸”ë¡œê·¸ë‚˜ ë°œí‘œë¥¼ í†µí•´ ë°°ìš´ ë‚´ìš©ì„ ê³µìœ ",
            "ì½”ë“œ í’ˆì§ˆê³¼ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ê°œì„ ì— ë” ì§‘ì¤‘",
            "ë©˜í† ë§ì„ í†µí•´ ì£¼ë‹ˆì–´ ê°œë°œì ì„±ì¥ ì§€ì›",
        ]

        return YearEndReview(
            proudest_moments=proudest_moments,
            biggest_challenges=biggest_challenges,
            lessons_learned=lessons_learned,
            next_year_goals=next_year_goals,
        )
