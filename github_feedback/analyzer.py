"""Metric calculation logic for GitHub feedback analysis."""

from __future__ import annotations

from dataclasses import dataclass
from datetime import datetime
from typing import Dict, List, Optional

from .console import Console
from .models import (
    AnalysisStatus,
    CollectionResult,
    MetricSnapshot,
    DetailedFeedbackSnapshot,
    CommitMessageFeedback,
    PRTitleFeedback,
    ReviewToneFeedback,
    IssueFeedback,
    MonthlyTrend,
    TechStackAnalysis,
    CollaborationNetwork,
    ReflectionPrompts,
    YearEndReview,
)

console = Console()


# Award tier configurations
AWARD_TIERS = {
    "commits": [
        (1000, "ğŸ’ ì½”ë“œ ì „ì„¤ ìƒ (ë‹¤ì´ì•„ëª¬ë“œ) â€” 1000íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ì €ì¥ì†Œì˜ ì‚´ì•„ìˆëŠ” ì—­ì‚¬ë¥¼ ì¼ìŠµë‹ˆë‹¤."),
        (500, "ğŸ† ì½”ë“œ ë§ˆìŠ¤í„° ìƒ (í”Œë˜í‹°ë„˜) â€” 500íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ì½”ë“œë² ì´ìŠ¤ì˜ ì¤‘ì¶”ë¥¼ ì™„ì„±í–ˆìŠµë‹ˆë‹¤."),
        (200, "ğŸ¥‡ ì½”ë“œ ëŒ€ì¥ì¥ì´ ìƒ (ê³¨ë“œ) â€” 200íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ì €ì¥ì†Œì˜ í•µì‹¬ì„ ë‹¨ë‹¨í•˜ê²Œ ë‹¤ì¡ŒìŠµë‹ˆë‹¤."),
        (100, "ğŸ¥ˆ ì½”ë“œ ì¥ì¸ ìƒ (ì‹¤ë²„) â€” 100íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ê¾¸ì¤€í•œ ê°œì„ ì„ ì´ì–´ê°”ìŠµë‹ˆë‹¤."),
        (50, "ğŸ¥‰ ì½”ë“œ ê²¬ìŠµìƒ ìƒ (ë¸Œë¡ ì¦ˆ) â€” 50íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ì„±ì¥ì˜ ë°œíŒì„ ë§ˆë ¨í–ˆìŠµë‹ˆë‹¤."),
    ],
    "pull_requests": [
        (200, "ğŸ’ ë¦´ë¦¬ìŠ¤ ì „ì„¤ ìƒ (ë‹¤ì´ì•„ëª¬ë“œ) â€” 200ê±´ ì´ìƒì˜ Pull Requestë¡œ ë°°í¬ì˜ ìƒˆ ì—­ì‚¬ë¥¼ ì—´ì—ˆìŠµë‹ˆë‹¤."),
        (100, "ğŸ† ë°°í¬ ì œë… ìƒ (í”Œë˜í‹°ë„˜) â€” 100ê±´ ì´ìƒì˜ Pull Requestë¡œ ë¦´ë¦¬ìŠ¤ í•¨ëŒ€ë¥¼ ì§€íœ˜í–ˆìŠµë‹ˆë‹¤."),
        (50, "ğŸ¥‡ ë¦´ë¦¬ìŠ¤ ì„ ì¥ ìƒ (ê³¨ë“œ) â€” 50ê±´ ì´ìƒì˜ Pull Requestë¡œ ì¶œì‹œ íë¦„ì„ ì´ëŒì—ˆìŠµë‹ˆë‹¤."),
        (25, "ğŸ¥ˆ ë¦´ë¦¬ìŠ¤ í•­í•´ì‚¬ ìƒ (ì‹¤ë²„) â€” 25ê±´ ì´ìƒì˜ Pull Requestë¡œ í˜‘ì—… ë¦´ë¦¬ìŠ¤ë¥¼ ì£¼ë„í–ˆìŠµë‹ˆë‹¤."),
        (10, "ğŸ¥‰ ë°°í¬ ì„ ì› ìƒ (ë¸Œë¡ ì¦ˆ) â€” 10ê±´ ì´ìƒì˜ Pull Requestë¡œ íŒ€ ë°°í¬ì— ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤."),
    ],
    "reviews": [
        (200, "ğŸ’ ì§€ì‹ ì „íŒŒì ìƒ (ë‹¤ì´ì•„ëª¬ë“œ) â€” 200íšŒ ì´ìƒì˜ ë¦¬ë·°ë¡œ íŒ€ ì „ì²´ì˜ ì„±ì¥ì„ ì´ëŒì—ˆìŠµë‹ˆë‹¤."),
        (100, "ğŸ† ë©˜í† ë§ ëŒ€ê°€ ìƒ (í”Œë˜í‹°ë„˜) â€” 100íšŒ ì´ìƒì˜ ë¦¬ë·°ë¡œ ì§€ì‹ ê³µìœ  ë¬¸í™”ë¥¼ ì •ì°©ì‹œì¼°ìŠµë‹ˆë‹¤."),
        (50, "ğŸ¥‡ ë¦¬ë·° ì „ë¬¸ê°€ ìƒ (ê³¨ë“œ) â€” 50íšŒ ì´ìƒì˜ ë¦¬ë·°ë¡œ ì½”ë“œ í’ˆì§ˆì„ í•œ ë‹¨ê³„ ëŒì–´ì˜¬ë ¸ìŠµë‹ˆë‹¤."),
        (20, "ğŸ¥ˆ ì„±ì¥ ë©˜í†  ìƒ (ì‹¤ë²„) â€” 20íšŒ ì´ìƒì˜ ë¦¬ë·°ë¡œ íŒ€ì˜ ì„±ì¥ì„ ë’·ë°›ì¹¨í–ˆìŠµë‹ˆë‹¤."),
        (10, "ğŸ¥‰ ì½”ë“œ ì§€ì›ì ìƒ (ë¸Œë¡ ì¦ˆ) â€” 10íšŒ ì´ìƒì˜ ë¦¬ë·°ë¡œ ë™ë£Œë¥¼ ë„ì™”ìŠµë‹ˆë‹¤."),
    ],
    "issues": [
        (50, "ğŸ”§ ë¬¸ì œ í•´ê²°ì‚¬ ìƒ â€” 50ê±´ ì´ìƒì˜ ì´ìŠˆë¥¼ ë‹¤ë£¨ë©° ì €ì¥ì†Œ í’ˆì§ˆì„ ê°œì„ í–ˆìŠµë‹ˆë‹¤."),
        (20, "ğŸ› ï¸ ë²„ê·¸ í—Œí„° ìƒ â€” 20ê±´ ì´ìƒì˜ ì´ìŠˆë¥¼ ì²˜ë¦¬í•˜ë©° ì•ˆì •ì„± í™•ë³´ì— ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤."),
    ],
    "velocity": [
        (50, "âš¡ ë²ˆê°œ ê°œë°œì ìƒ â€” ì›” í‰ê·  50íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ë†€ë¼ìš´ ì†ë„ë¥¼ ë³´ì—¬ì¤¬ìŠµë‹ˆë‹¤."),
        (20, "ğŸš€ ì†ë„ì™• ìƒ â€” ì›” í‰ê·  20íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ë¹ ë¥¸ ê°œë°œ í…œí¬ë¥¼ ìœ ì§€í–ˆìŠµë‹ˆë‹¤."),
    ],
    "collaboration": [
        (20, "ğŸ¤ í˜‘ì—… ë§ˆìŠ¤í„° ìƒ â€” ì›” í‰ê·  20íšŒ ì´ìƒì˜ PRê³¼ ë¦¬ë·°ë¡œ íŒ€ì›Œí¬ì˜ ì¤‘ì‹¬ì´ ë˜ì—ˆìŠµë‹ˆë‹¤."),
        (10, "ğŸ‘¥ í˜‘ì—… ì „ë¬¸ê°€ ìƒ â€” ì›” í‰ê·  10íšŒ ì´ìƒì˜ PRê³¼ ë¦¬ë·°ë¡œ íŒ€ ì‹œë„ˆì§€ë¥¼ ê°•í™”í–ˆìŠµë‹ˆë‹¤."),
    ],
    "activity_consistency": [
        ((30, 6), "ğŸ“… ê¾¸ì¤€í•¨ì˜ ë‹¬ì¸ ìƒ â€” 6ê°œì›” ì´ìƒ ì›” í‰ê·  30íšŒ ì´ìƒì˜ í™œë™ìœ¼ë¡œ ì¼ê´€ì„±ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤."),
        ((15, 3), "ğŸ”„ ì§€ì†ì„± ìƒ â€” ê¾¸ì¤€í•œ ì›”ë³„ í™œë™ìœ¼ë¡œ ì„±ì‹¤í•¨ì„ ë³´ì—¬ì¤¬ìŠµë‹ˆë‹¤."),
    ],
    "change_scale": [
        (5000, "ğŸ—ï¸ ëŒ€ê·œëª¨ ì•„í‚¤í…íŠ¸ ìƒ â€” 5000ì¤„ ì´ìƒì˜ ë³€ê²½ìœ¼ë¡œ ëŒ€ë‹´í•œ ë¦¬íŒ©í„°ë§ì„ ì™„ìˆ˜í–ˆìŠµë‹ˆë‹¤."),
        (2000, "ğŸ”¨ ëŒ€í˜• ë¹Œë” ìƒ â€” 2000ì¤„ ì´ìƒì˜ ë³€ê²½ìœ¼ë¡œ í° ê·œëª¨ì˜ ê°œì„ ì„ ì´ë¤„ëƒˆìŠµë‹ˆë‹¤."),
    ],
}


@dataclass(slots=True)
class Analyzer:
    """Transform collected data into actionable metrics."""

    web_base_url: str = "https://github.com"

    def compute_metrics(
        self,
        collection: CollectionResult,
        detailed_feedback: Optional[DetailedFeedbackSnapshot] = None,
        monthly_trends_data: Optional[List[Dict]] = None,
        tech_stack_data: Optional[Dict[str, int]] = None,
        collaboration_data: Optional[Dict[str, Any]] = None,
    ) -> MetricSnapshot:
        """Compute derived metrics from the collected artefacts."""

        console.log("Analyzing repository trends", f"repo={collection.repo}")

        (
            month_span,
            velocity_score,
            collaboration_score,
            stability_score,
            total_activity,
            period_label,
        ) = self._calculate_scores(collection)

        highlights = self._build_highlights(
            collection,
            period_label,
            month_span,
            velocity_score,
            total_activity,
        )
        spotlight_examples = self._build_spotlight_examples(collection)
        summary = self._build_summary(
            period_label,
            total_activity,
            velocity_score,
            collaboration_score,
            stability_score,
        )
        story_beats = self._build_story_beats(collection, period_label, total_activity)
        awards = self._determine_awards(collection)
        stats = self._build_stats(collection, velocity_score)
        evidence = self._build_evidence(collection)

        # Build year-end specific insights
        monthly_trends = self._build_monthly_trends(monthly_trends_data)
        tech_stack = self._build_tech_stack_analysis(tech_stack_data)
        collaboration = self._build_collaboration_network(collaboration_data)
        reflection_prompts = self._build_reflection_prompts(collection)
        year_end_review = self._build_year_end_review(collection, highlights, awards)

        return MetricSnapshot(
            repo=collection.repo,
            months=collection.months,
            generated_at=datetime.utcnow(),
            status=AnalysisStatus.ANALYSED,
            summary=summary,
            stats=stats,
            evidence=evidence,
            highlights=highlights,
            spotlight_examples=spotlight_examples,
            yearbook_story=story_beats,
            awards=awards,
            detailed_feedback=detailed_feedback,
            monthly_trends=monthly_trends,
            tech_stack=tech_stack,
            collaboration=collaboration,
            reflection_prompts=reflection_prompts,
            year_end_review=year_end_review,
        )

    def _calculate_scores(
        self, collection: CollectionResult
    ) -> tuple[int, float, float, int, int, str]:
        month_span = max(collection.months, 1)
        velocity_score = collection.commits / month_span
        collaboration_score = (collection.pull_requests + collection.reviews) / month_span
        stability_score = max(collection.commits - collection.issues, 0)
        total_activity = collection.commits + collection.pull_requests + collection.reviews
        period_label = "ì˜¬í•´" if collection.months >= 12 else f"ì§€ë‚œ {collection.months}ê°œì›”"

        return (
            month_span,
            velocity_score,
            collaboration_score,
            stability_score,
            total_activity,
            period_label,
        )

    def _build_highlights(
        self,
        collection: CollectionResult,
        period_label: str,
        month_span: int,
        velocity_score: float,
        total_activity: int,
    ) -> List[str]:
        highlights: List[str] = []
        if collection.commits:
            highlights.append(
                f"{period_label}ì— ì´ {collection.commits}íšŒì˜ ì»¤ë°‹ìœ¼ë¡œ ì½”ë“œë¥¼ ë‹¤ë“¬ê³  ì›” í‰ê·  {velocity_score:.1f}íšŒì˜ ê°œì„ ì„ ì´ì–´ê°”ìŠµë‹ˆë‹¤."
            )
        if collection.pull_requests:
            highlights.append(
                f"{collection.pull_requests}ê±´ì˜ Pull Requestë¥¼ ë³‘í•©í•˜ë©° íŒ€ ë°°í¬ ì£¼ê¸°ë¥¼ ì•ˆì •í™”í–ˆê³  ì›” {collection.pull_requests / month_span:.1f}ê±´ì˜ ë¦´ë¦¬ìŠ¤ë¥¼ ìœ ì§€í–ˆìŠµë‹ˆë‹¤."
            )
        if collection.reviews:
            highlights.append(
                f"{collection.reviews}íšŒì˜ ì½”ë“œ ë¦¬ë·°ë¥¼ í†µí•´ í˜‘ì—… ë¬¸í™”ë¥¼ ê°•í™”í–ˆìŠµë‹ˆë‹¤."
            )
        if collection.issues:
            highlights.append(
                f"í™œë™ ëŒ€ë¹„ {collection.issues}ê±´ì˜ ì´ìŠˆë¡œ ì•ˆì •ì„±ì„ ì§€ì¼°ìŠµë‹ˆë‹¤."
            )
        if not highlights and total_activity == 0:
            highlights.append("ë¶„ì„ ê¸°ê°„ ë™ì•ˆ ëšœë ·í•œ í™œë™ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        return highlights

    def _build_spotlight_examples(self, collection: CollectionResult) -> Dict[str, List[str]]:
        spotlight_examples: Dict[str, List[str]] = {}
        if not collection.pull_request_examples:
            return spotlight_examples

        # Sort PRs by change volume (largest first) to show most significant contributions
        sorted_prs = sorted(
            collection.pull_request_examples,
            key=lambda pr: pr.additions + pr.deletions,
            reverse=True
        )

        pr_lines = []
        for idx, pr in enumerate(sorted_prs[:5], 1):
            change_volume = pr.additions + pr.deletions
            scale_phrase = f"ë³€ê²½ {change_volume:,}ì¤„" if change_volume else "ê²½ëŸ‰ ë³€ê²½"
            merged_phrase = (
                f"{pr.merged_at.date().isoformat()} ë³‘í•©"
                if pr.merged_at
                else "ë¯¸ë³‘í•©"
            )

            # Add reason for showing this PR
            if idx == 1:
                reason = "ìµœëŒ€ ë³€ê²½ëŸ‰"
            elif idx == 2:
                reason = "2ë²ˆì§¸ í° ë³€ê²½"
            elif idx == 3:
                reason = "3ë²ˆì§¸ í° ë³€ê²½"
            elif change_volume > 500:
                reason = "ëŒ€ê·œëª¨ ë³€ê²½"
            else:
                reason = "ì£¼ìš” ê¸°ì—¬"

            pr_lines.append(
                f"PR #{pr.number} Â· {pr.title} â€” {pr.author} ({pr.created_at.date().isoformat()}, {merged_phrase}, {scale_phrase}) Â· [{reason}] Â· {pr.html_url}"
            )
        spotlight_examples["pull_requests"] = pr_lines
        return spotlight_examples

    def _build_summary(
        self,
        period_label: str,
        total_activity: int,
        velocity_score: float,
        collaboration_score: float,
        stability_score: int,
    ) -> Dict[str, str]:
        return {
            "velocity": f"Average {velocity_score:.1f} commits per month",
            "collaboration": "{:.1f} combined PRs and reviews per month".format(collaboration_score),
            "stability": f"Net stability score of {stability_score}",
            "growth": f"{period_label} ë™ì•ˆ {total_activity}ê±´ì˜ í™œë™ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.",
        }

    def _build_story_beats(
        self,
        collection: CollectionResult,
        period_label: str,
        total_activity: int,
    ) -> List[str]:
        story_beats: List[str] = []
        if total_activity:
            story_beats.append(
                f"{period_label} ë™ì•ˆ {collection.repo} ì €ì¥ì†Œì—ì„œ ì´ {total_activity}ê±´ì˜ í™œë™ì„ í¼ì¹˜ë©° ì„±ì¥ ì—”ì§„ì„ ê°€ë™í–ˆìŠµë‹ˆë‹¤."
            )
        else:
            story_beats.append(
                f"{period_label}ì—ëŠ” ì ì‹œ ìˆ¨ì„ ê³ ë¥´ë©° ë‹¤ìŒ ë„ì•½ì„ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤."
            )

        contribution_domains = [
            ("ì»¤ë°‹", collection.commits, "ì§€ì†ì ì¸ ë¦¬íŒ©í„°ë§ê³¼ ê¸°ëŠ¥ í™•ì¥ì„ ì´ëŒì—ˆìŠµë‹ˆë‹¤."),
            ("Pull Request", collection.pull_requests, "í˜‘ì—… ë¦´ë¦¬ìŠ¤ë¥¼ ì£¼ë„í•˜ë©° ë°°í¬ íŒŒì´í”„ë¼ì¸ì„ ì§€ì¼°ìŠµë‹ˆë‹¤."),
            ("ë¦¬ë·°", collection.reviews, "íŒ€ ë™ë£Œë“¤ì˜ ì„±ì¥ì„ ë•ëŠ” ì´˜ì´˜í•œ í”¼ë“œë°±ì„ ì „ë‹¬í–ˆìŠµë‹ˆë‹¤."),
        ]
        top_domain = max(contribution_domains, key=lambda entry: entry[1])
        if top_domain[1]:
            story_beats.append(
                f"ê°€ì¥ ëˆˆì— ëˆ ì˜ì—­ì€ {top_domain[0]} {top_domain[1]}íšŒë¡œ, {top_domain[2]}"
            )

        if collection.pull_request_examples:
            exemplar = collection.pull_request_examples[0]
            merge_phrase = (
                f"{exemplar.merged_at.date().isoformat()} ë³‘í•©"
                if exemplar.merged_at
                else "ì•„ì§ ì§„í–‰ ì¤‘"
            )
            scale = exemplar.additions + exemplar.deletions
            scale_phrase = f"ë³€ê²½ {scale}ì¤„" if scale else "ê²½ëŸ‰ ë³€ê²½"
            story_beats.append(
                "ëŒ€í‘œì‘ìœ¼ë¡œëŠ” PR #{num} `{title}`({author})ê°€ ìˆìŠµë‹ˆë‹¤ â€” {created} ì‘ì„±, {merge} Â· {scale_phrase}.".format(
                    num=exemplar.number,
                    title=exemplar.title,
                    author=exemplar.author,
                    created=exemplar.created_at.date().isoformat(),
                    merge=merge_phrase,
                    scale_phrase=scale_phrase,
                )
            )

        return story_beats

    def _determine_awards(self, collection: CollectionResult) -> List[str]:
        """Determine awards based on collection metrics using data-driven tier system."""
        awards: List[str] = []
        month_span = max(collection.months, 1)

        # Apply tier-based awards
        self._add_tier_award(awards, "commits", collection.commits)
        self._add_tier_award(awards, "pull_requests", collection.pull_requests)
        self._add_tier_award(awards, "reviews", collection.reviews)
        self._add_tier_award(awards, "issues", collection.issues)

        # Velocity-based awards
        velocity_score = collection.commits / month_span
        self._add_tier_award(awards, "velocity", velocity_score)

        # Collaboration-based awards
        collaboration_score = (collection.pull_requests + collection.reviews) / month_span
        self._add_tier_award(awards, "collaboration", collaboration_score)

        # Activity consistency awards
        total_activity = collection.commits + collection.pull_requests + collection.reviews
        activity_per_month = total_activity / month_span
        for (threshold_activity, threshold_months), award_text in AWARD_TIERS["activity_consistency"]:
            if activity_per_month >= threshold_activity and collection.months >= threshold_months:
                awards.append(award_text)
                break

        # All-rounder award
        if (collection.commits >= 50 and
            collection.pull_requests >= 15 and
            collection.reviews >= 15):
            awards.append(
                "ğŸŒŸ ë‹¤ì¬ë‹¤ëŠ¥ ìƒ â€” ì»¤ë°‹, PR, ë¦¬ë·° ì „ ì˜ì—­ì—ì„œ ê· í˜•ì¡íŒ ê¸°ì—¬ë¥¼ ë³´ì—¬ì¤¬ìŠµë‹ˆë‹¤."
            )

        # Large-scale change awards
        if collection.pull_request_examples:
            max_change = max(
                (pr.additions + pr.deletions for pr in collection.pull_request_examples),
                default=0
            )
            self._add_tier_award(awards, "change_scale", max_change)

        # Stability award
        if collection.issues and collection.issues <= max(collection.commits // 6, 1):
            awards.append(
                "ğŸ›¡ï¸ ì•ˆì • ì§€í‚´ì´ ìƒ â€” í™œë™ ëŒ€ë¹„ ì ì€ ì´ìŠˆë¡œ ì•ˆì •ì„±ì„ ì§€ì¼°ìŠµë‹ˆë‹¤."
            )

        # Default award if no other awards
        if not awards:
            awards.append(
                "ğŸŒ± ì„±ì¥ ì”¨ì•— ìƒ â€” ì‘ì€ ë°œê±¸ìŒë“¤ì´ ëª¨ì—¬ ë‚´ì¼ì˜ í° ì„±ì¥ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤."
            )

        return awards

    @staticmethod
    def _add_tier_award(awards: List[str], category: str, value: float) -> None:
        """Add tier-based award if value meets threshold.

        Args:
            awards: List to append awards to
            category: Award category key from AWARD_TIERS
            value: Metric value to check against thresholds
        """
        if category not in AWARD_TIERS:
            return

        for threshold, award_text in AWARD_TIERS[category]:
            if value >= threshold:
                awards.append(award_text)
                break

    def _build_stats(self, collection: CollectionResult, velocity_score: float) -> Dict[str, Dict[str, float]]:
        return {
            "commits": {
                "total": float(collection.commits),
                "per_month": velocity_score,
            },
            "pull_requests": {
                "total": float(collection.pull_requests),
            },
            "reviews": {
                "total": float(collection.reviews),
            },
            "issues": {
                "total": float(collection.issues),
            },
        }

    def _build_evidence(self, collection: CollectionResult) -> Dict[str, List[str]]:
        repo_root = f"{self.web_base_url.rstrip('/')}/{collection.repo}"
        return {
            "commits": [
                f"{repo_root}/commits",
            ],
            "pull_requests": [
                f"{repo_root}/pulls",
            ],
        }

    def build_detailed_feedback(
        self,
        commit_analysis: Optional[Dict] = None,
        pr_title_analysis: Optional[Dict] = None,
        review_tone_analysis: Optional[Dict] = None,
        issue_analysis: Optional[Dict] = None,
    ) -> DetailedFeedbackSnapshot:
        """Build detailed feedback snapshot from LLM analysis results."""

        commit_feedback = None
        if commit_analysis:
            commit_feedback = CommitMessageFeedback(
                total_commits=commit_analysis.get("good_messages", 0)
                + commit_analysis.get("poor_messages", 0),
                good_messages=commit_analysis.get("good_messages", 0),
                poor_messages=commit_analysis.get("poor_messages", 0),
                suggestions=commit_analysis.get("suggestions", []),
                examples_good=commit_analysis.get("examples_good", []),
                examples_poor=commit_analysis.get("examples_poor", []),
            )

        pr_title_feedback = None
        if pr_title_analysis:
            pr_title_feedback = PRTitleFeedback(
                total_prs=pr_title_analysis.get("clear_titles", 0)
                + pr_title_analysis.get("vague_titles", 0),
                clear_titles=pr_title_analysis.get("clear_titles", 0),
                vague_titles=pr_title_analysis.get("vague_titles", 0),
                suggestions=pr_title_analysis.get("suggestions", []),
                examples_good=pr_title_analysis.get("examples_good", []),
                examples_poor=pr_title_analysis.get("examples_poor", []),
            )

        review_tone_feedback = None
        if review_tone_analysis:
            review_tone_feedback = ReviewToneFeedback(
                total_reviews=review_tone_analysis.get("constructive_reviews", 0)
                + review_tone_analysis.get("harsh_reviews", 0)
                + review_tone_analysis.get("neutral_reviews", 0),
                constructive_reviews=review_tone_analysis.get("constructive_reviews", 0),
                harsh_reviews=review_tone_analysis.get("harsh_reviews", 0),
                neutral_reviews=review_tone_analysis.get("neutral_reviews", 0),
                suggestions=review_tone_analysis.get("suggestions", []),
                examples_good=review_tone_analysis.get("examples_good", []),
                examples_improve=review_tone_analysis.get("examples_improve", []),
            )

        issue_feedback = None
        if issue_analysis:
            issue_feedback = IssueFeedback(
                total_issues=issue_analysis.get("well_described", 0)
                + issue_analysis.get("poorly_described", 0),
                well_described=issue_analysis.get("well_described", 0),
                poorly_described=issue_analysis.get("poorly_described", 0),
                suggestions=issue_analysis.get("suggestions", []),
                examples_good=issue_analysis.get("examples_good", []),
                examples_poor=issue_analysis.get("examples_poor", []),
            )

        return DetailedFeedbackSnapshot(
            commit_feedback=commit_feedback,
            pr_title_feedback=pr_title_feedback,
            review_tone_feedback=review_tone_feedback,
            issue_feedback=issue_feedback,
        )

    def _build_monthly_trends(
        self, monthly_trends_data: Optional[List[Dict]]
    ) -> List[MonthlyTrend]:
        """Build monthly trend objects from raw data."""
        if not monthly_trends_data:
            return []

        trends = []
        for data in monthly_trends_data:
            trends.append(
                MonthlyTrend(
                    month=data.get("month", ""),
                    commits=data.get("commits", 0),
                    pull_requests=data.get("pull_requests", 0),
                    reviews=data.get("reviews", 0),
                    issues=data.get("issues", 0),
                )
            )
        return trends

    def _build_tech_stack_analysis(
        self, tech_stack_data: Optional[Dict[str, int]]
    ) -> Optional[TechStackAnalysis]:
        """Analyze technology stack from file changes."""
        if not tech_stack_data:
            return None

        # Calculate top languages
        sorted_languages = sorted(
            tech_stack_data.items(), key=lambda x: x[1], reverse=True
        )
        top_languages = [lang for lang, _ in sorted_languages[:5]]

        # Calculate diversity score (Shannon entropy normalized)
        total_files = sum(tech_stack_data.values())
        if total_files == 0:
            diversity_score = 0.0
        else:
            import math
            entropy = 0.0
            for count in tech_stack_data.values():
                if count > 0:
                    p = count / total_files
                    entropy -= p * math.log2(p)
            # Normalize to 0-1 range (max entropy is log2(n))
            max_entropy = math.log2(len(tech_stack_data)) if len(tech_stack_data) > 1 else 1
            diversity_score = entropy / max_entropy if max_entropy > 0 else 0.0

        return TechStackAnalysis(
            languages=tech_stack_data,
            top_languages=top_languages,
            diversity_score=diversity_score,
        )

    def _build_collaboration_network(
        self, collaboration_data: Optional[Dict[str, Any]]
    ) -> Optional[CollaborationNetwork]:
        """Build collaboration network from reviewer data."""
        if not collaboration_data:
            return None

        pr_reviewers = collaboration_data.get("pr_reviewers", {})
        sorted_reviewers = sorted(
            pr_reviewers.items(), key=lambda x: x[1], reverse=True
        )
        top_reviewers = [reviewer for reviewer, _ in sorted_reviewers[:5]]

        return CollaborationNetwork(
            pr_reviewers=pr_reviewers,
            top_reviewers=top_reviewers,
            review_received_count=collaboration_data.get("review_received_count", 0),
            unique_collaborators=collaboration_data.get("unique_collaborators", 0),
        )

    def _build_reflection_prompts(
        self, collection: CollectionResult
    ) -> ReflectionPrompts:
        """Generate self-reflection questions for year-end review."""
        questions = [
            "ì˜¬í•´ ë‚´ê°€ ê°€ì¥ ìë‘ìŠ¤ëŸ¬ì›Œí•˜ëŠ” ê¸°ìˆ ì  ì„±ì·¨ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
            "ê°€ì¥ ì–´ë ¤ì› ë˜ ê¸°ìˆ ì  ë„ì „ì€ ë¬´ì—‡ì´ì—ˆê³ , ì–´ë–»ê²Œ ê·¹ë³µí–ˆë‚˜ìš”?",
            "ì˜¬í•´ ìƒˆë¡­ê²Œ ë°°ìš´ ê¸°ìˆ ì´ë‚˜ ë„êµ¬ ì¤‘ ê°€ì¥ ìœ ìš©í–ˆë˜ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ì½”ë“œ ë¦¬ë·°ë¥¼ í†µí•´ ë°›ì€ í”¼ë“œë°± ì¤‘ ê°€ì¥ ê¸°ì–µì— ë‚¨ëŠ” ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "íŒ€ì›ë“¤ê³¼ì˜ í˜‘ì—…ì—ì„œ ê°€ì¥ ë¿Œë“¯í–ˆë˜ ìˆœê°„ì€ ì–¸ì œì˜€ë‚˜ìš”?",
            "ë‚´ ì½”ë“œê°€ íŒ€ì´ë‚˜ ì‚¬ìš©ìì—ê²Œ ê°€ì¥ í° ì˜í–¥ì„ ì¤€ ìˆœê°„ì€ ì–¸ì œì˜€ë‚˜ìš”?",
            "ì˜¬í•´ ë‚´ ê°œë°œ í”„ë¡œì„¸ìŠ¤ë‚˜ ìŠµê´€ì—ì„œ ê°œì„ ëœ ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ì•ìœ¼ë¡œ ë” ë°œì „ì‹œí‚¤ê³  ì‹¶ì€ ê¸°ìˆ  ì˜ì—­ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ë‚´ë…„ì— ë„ì „í•˜ê³  ì‹¶ì€ ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ë‚˜ ê¸°ìˆ ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ê°œë°œìë¡œì„œ ë‚´ë…„ì˜ ë‚˜ëŠ” ì–´ë–¤ ëª¨ìŠµì´ê¸¸ ë°”ë¼ë‚˜ìš”?",
        ]

        # Add context-specific questions based on activity
        if collection.commits > 100:
            questions.append(
                f"ì˜¬í•´ {collection.commits}íšŒì˜ ì»¤ë°‹ì„ ì‘ì„±í–ˆìŠµë‹ˆë‹¤. ì´ ì¤‘ ê°€ì¥ ì˜ë¯¸ìˆì—ˆë˜ ì»¤ë°‹ì€ ë¬´ì—‡ì´ì—ˆë‚˜ìš”?"
            )

        if collection.reviews > 50:
            questions.append(
                f"{collection.reviews}íšŒì˜ ì½”ë“œ ë¦¬ë·°ë¥¼ ì§„í–‰í–ˆìŠµë‹ˆë‹¤. ë¦¬ë·°ë¥¼ í†µí•´ ë°°ìš´ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?"
            )

        if collection.pull_requests > 30:
            questions.append(
                f"{collection.pull_requests}ê°œì˜ Pull Requestë¥¼ ì‘ì„±í–ˆìŠµë‹ˆë‹¤. ê°€ì¥ ë³µì¡í–ˆë˜ PRì€ ë¬´ì—‡ì´ì—ˆê³ , ì–´ë–¤ ì ì´ ì–´ë ¤ì› ë‚˜ìš”?"
            )

        return ReflectionPrompts(questions=questions)

    def _build_year_end_review(
        self,
        collection: CollectionResult,
        highlights: List[str],
        awards: List[str],
    ) -> YearEndReview:
        """Generate year-end specific review content."""

        # Proudest moments based on metrics
        proudest_moments = []
        if collection.commits > 200:
            proudest_moments.append(
                f"ì´ {collection.commits}íšŒì˜ ì»¤ë°‹ìœ¼ë¡œ ê¾¸ì¤€íˆ ì½”ë“œë² ì´ìŠ¤ë¥¼ ê°œì„ í–ˆìŠµë‹ˆë‹¤."
            )
        if collection.pull_requests > 50:
            proudest_moments.append(
                f"{collection.pull_requests}ê°œì˜ Pull Requestë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¨¸ì§€í–ˆìŠµë‹ˆë‹¤."
            )
        if collection.reviews > 50:
            proudest_moments.append(
                f"{collection.reviews}íšŒì˜ ì½”ë“œ ë¦¬ë·°ë¡œ íŒ€ì˜ ì½”ë“œ í’ˆì§ˆ í–¥ìƒì— ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤."
            )
        if not proudest_moments:
            proudest_moments.append(
                "ê¾¸ì¤€í•œ í™œë™ìœ¼ë¡œ í”„ë¡œì íŠ¸ ë°œì „ì— ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤."
            )

        # Challenges (generic, to be filled by user)
        biggest_challenges = [
            "ë³µì¡í•œ ê¸°ìˆ ì  ë¬¸ì œë¥¼ í•´ê²°í•˜ë©° ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ í‚¤ì› ìŠµë‹ˆë‹¤.",
            "ìƒˆë¡œìš´ ê¸°ìˆ  ìŠ¤íƒì„ í•™ìŠµí•˜ê³  í”„ë¡œì íŠ¸ì— ì ìš©í–ˆìŠµë‹ˆë‹¤.",
            "íŒ€ì›ë“¤ê³¼ì˜ í˜‘ì—…ì„ í†µí•´ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ìŠ¤í‚¬ì„ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.",
        ]

        # Lessons learned
        lessons_learned = [
            "ì‘ê³  ìì£¼ ì»¤ë°‹í•˜ëŠ” ê²ƒì´ ì½”ë“œ ë¦¬ë·°ì™€ í˜‘ì—…ì— ë” íš¨ê³¼ì ì…ë‹ˆë‹¤.",
            "ì½”ë“œ ë¦¬ë·°ëŠ” ë‹¨ìˆœí•œ ë²„ê·¸ ì°¾ê¸°ê°€ ì•„ë‹Œ ì§€ì‹ ê³µìœ ì˜ ì¥ì…ë‹ˆë‹¤.",
            "ì¢‹ì€ ì»¤ë°‹ ë©”ì‹œì§€ì™€ PR ì„¤ëª…ì€ ë¯¸ë˜ì˜ ë‚˜ì™€ íŒ€ì›ë“¤ì„ ìœ„í•œ íˆ¬ìì…ë‹ˆë‹¤.",
        ]

        # Next year goals
        next_year_goals = [
            "ìƒˆë¡œìš´ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë‚˜ í”„ë ˆì„ì›Œí¬ë¥¼ í•™ìŠµí•˜ì—¬ ê¸°ìˆ  ìŠ¤íƒ ë‹¤ë³€í™”",
            "ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ì— ê¸°ì—¬í•˜ì—¬ ì»¤ë®¤ë‹ˆí‹° ì°¸ì—¬ í™•ëŒ€",
            "ê¸°ìˆ  ë¸”ë¡œê·¸ë‚˜ ë°œí‘œë¥¼ í†µí•´ ë°°ìš´ ë‚´ìš©ì„ ê³µìœ ",
            "ì½”ë“œ í’ˆì§ˆê³¼ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ê°œì„ ì— ë” ì§‘ì¤‘",
            "ë©˜í† ë§ì„ í†µí•´ ì£¼ë‹ˆì–´ ê°œë°œì ì„±ì¥ ì§€ì›",
        ]

        return YearEndReview(
            proudest_moments=proudest_moments,
            biggest_challenges=biggest_challenges,
            lessons_learned=lessons_learned,
            next_year_goals=next_year_goals,
        )
