"""Metric calculation logic for GitHub feedback analysis."""

from __future__ import annotations

from dataclasses import dataclass
from datetime import datetime, timezone
from typing import Dict, List, Optional

from .console import Console
from .models import (
    AnalysisStatus,
    CollectionResult,
    MetricSnapshot,
    DetailedFeedbackSnapshot,
    CommitMessageFeedback,
    PRTitleFeedback,
    ReviewToneFeedback,
    IssueFeedback,
    MonthlyTrend,
    MonthlyTrendInsights,
    TechStackAnalysis,
    CollaborationNetwork,
    ReflectionPrompts,
    YearEndReview,
)

console = Console()


# Award tier configurations
AWARD_TIERS = {
    "commits": [
        (1000, "ğŸ’ ì½”ë“œ ì „ì„¤ ìƒ (ë‹¤ì´ì•„ëª¬ë“œ) â€” 1000íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ì €ì¥ì†Œì˜ ì‚´ì•„ìˆëŠ” ì—­ì‚¬ë¥¼ ì¼ìŠµë‹ˆë‹¤."),
        (500, "ğŸ† ì½”ë“œ ë§ˆìŠ¤í„° ìƒ (í”Œë˜í‹°ë„˜) â€” 500íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ì½”ë“œë² ì´ìŠ¤ì˜ ì¤‘ì¶”ë¥¼ ì™„ì„±í–ˆìŠµë‹ˆë‹¤."),
        (200, "ğŸ¥‡ ì½”ë“œ ëŒ€ì¥ì¥ì´ ìƒ (ê³¨ë“œ) â€” 200íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ì €ì¥ì†Œì˜ í•µì‹¬ì„ ë‹¨ë‹¨í•˜ê²Œ ë‹¤ì¡ŒìŠµë‹ˆë‹¤."),
        (100, "ğŸ¥ˆ ì½”ë“œ ì¥ì¸ ìƒ (ì‹¤ë²„) â€” 100íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ê¾¸ì¤€í•œ ê°œì„ ì„ ì´ì–´ê°”ìŠµë‹ˆë‹¤."),
        (50, "ğŸ¥‰ ì½”ë“œ ê²¬ìŠµìƒ ìƒ (ë¸Œë¡ ì¦ˆ) â€” 50íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ì„±ì¥ì˜ ë°œíŒì„ ë§ˆë ¨í–ˆìŠµë‹ˆë‹¤."),
    ],
    "pull_requests": [
        (200, "ğŸ’ ë¦´ë¦¬ìŠ¤ ì „ì„¤ ìƒ (ë‹¤ì´ì•„ëª¬ë“œ) â€” 200ê±´ ì´ìƒì˜ Pull Requestë¡œ ë°°í¬ì˜ ìƒˆ ì—­ì‚¬ë¥¼ ì—´ì—ˆìŠµë‹ˆë‹¤."),
        (100, "ğŸ† ë°°í¬ ì œë… ìƒ (í”Œë˜í‹°ë„˜) â€” 100ê±´ ì´ìƒì˜ Pull Requestë¡œ ë¦´ë¦¬ìŠ¤ í•¨ëŒ€ë¥¼ ì§€íœ˜í–ˆìŠµë‹ˆë‹¤."),
        (50, "ğŸ¥‡ ë¦´ë¦¬ìŠ¤ ì„ ì¥ ìƒ (ê³¨ë“œ) â€” 50ê±´ ì´ìƒì˜ Pull Requestë¡œ ì¶œì‹œ íë¦„ì„ ì´ëŒì—ˆìŠµë‹ˆë‹¤."),
        (25, "ğŸ¥ˆ ë¦´ë¦¬ìŠ¤ í•­í•´ì‚¬ ìƒ (ì‹¤ë²„) â€” 25ê±´ ì´ìƒì˜ Pull Requestë¡œ í˜‘ì—… ë¦´ë¦¬ìŠ¤ë¥¼ ì£¼ë„í–ˆìŠµë‹ˆë‹¤."),
        (10, "ğŸ¥‰ ë°°í¬ ì„ ì› ìƒ (ë¸Œë¡ ì¦ˆ) â€” 10ê±´ ì´ìƒì˜ Pull Requestë¡œ íŒ€ ë°°í¬ì— ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤."),
    ],
    "reviews": [
        (200, "ğŸ’ ì§€ì‹ ì „íŒŒì ìƒ (ë‹¤ì´ì•„ëª¬ë“œ) â€” 200íšŒ ì´ìƒì˜ ë¦¬ë·°ë¡œ íŒ€ ì „ì²´ì˜ ì„±ì¥ì„ ì´ëŒì—ˆìŠµë‹ˆë‹¤."),
        (100, "ğŸ† ë©˜í† ë§ ëŒ€ê°€ ìƒ (í”Œë˜í‹°ë„˜) â€” 100íšŒ ì´ìƒì˜ ë¦¬ë·°ë¡œ ì§€ì‹ ê³µìœ  ë¬¸í™”ë¥¼ ì •ì°©ì‹œì¼°ìŠµë‹ˆë‹¤."),
        (50, "ğŸ¥‡ ë¦¬ë·° ì „ë¬¸ê°€ ìƒ (ê³¨ë“œ) â€” 50íšŒ ì´ìƒì˜ ë¦¬ë·°ë¡œ ì½”ë“œ í’ˆì§ˆì„ í•œ ë‹¨ê³„ ëŒì–´ì˜¬ë ¸ìŠµë‹ˆë‹¤."),
        (20, "ğŸ¥ˆ ì„±ì¥ ë©˜í†  ìƒ (ì‹¤ë²„) â€” 20íšŒ ì´ìƒì˜ ë¦¬ë·°ë¡œ íŒ€ì˜ ì„±ì¥ì„ ë’·ë°›ì¹¨í–ˆìŠµë‹ˆë‹¤."),
        (10, "ğŸ¥‰ ì½”ë“œ ì§€ì›ì ìƒ (ë¸Œë¡ ì¦ˆ) â€” 10íšŒ ì´ìƒì˜ ë¦¬ë·°ë¡œ ë™ë£Œë¥¼ ë„ì™”ìŠµë‹ˆë‹¤."),
    ],
    "issues": [
        (50, "ğŸ”§ ë¬¸ì œ í•´ê²°ì‚¬ ìƒ â€” 50ê±´ ì´ìƒì˜ ì´ìŠˆë¥¼ ë‹¤ë£¨ë©° ì €ì¥ì†Œ í’ˆì§ˆì„ ê°œì„ í–ˆìŠµë‹ˆë‹¤."),
        (20, "ğŸ› ï¸ ë²„ê·¸ í—Œí„° ìƒ â€” 20ê±´ ì´ìƒì˜ ì´ìŠˆë¥¼ ì²˜ë¦¬í•˜ë©° ì•ˆì •ì„± í™•ë³´ì— ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤."),
    ],
    "velocity": [
        (50, "âš¡ ë²ˆê°œ ê°œë°œì ìƒ â€” ì›” í‰ê·  50íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ë†€ë¼ìš´ ì†ë„ë¥¼ ë³´ì—¬ì¤¬ìŠµë‹ˆë‹¤."),
        (20, "ğŸš€ ì†ë„ì™• ìƒ â€” ì›” í‰ê·  20íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ë¹ ë¥¸ ê°œë°œ í…œí¬ë¥¼ ìœ ì§€í–ˆìŠµë‹ˆë‹¤."),
        (10, "ğŸƒ ìŠ¤í”„ë¦°í„° ìƒ â€” ì›” í‰ê·  10íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ê¾¸ì¤€í•œ ì§„ì „ì„ ì´ë¤˜ìŠµë‹ˆë‹¤."),
    ],
    "collaboration": [
        (20, "ğŸ¤ í˜‘ì—… ë§ˆìŠ¤í„° ìƒ â€” ì›” í‰ê·  20íšŒ ì´ìƒì˜ PRê³¼ ë¦¬ë·°ë¡œ íŒ€ì›Œí¬ì˜ ì¤‘ì‹¬ì´ ë˜ì—ˆìŠµë‹ˆë‹¤."),
        (10, "ğŸ‘¥ í˜‘ì—… ì „ë¬¸ê°€ ìƒ â€” ì›” í‰ê·  10íšŒ ì´ìƒì˜ PRê³¼ ë¦¬ë·°ë¡œ íŒ€ ì‹œë„ˆì§€ë¥¼ ê°•í™”í–ˆìŠµë‹ˆë‹¤."),
        (5, "ğŸ¤— íŒ€ í”Œë ˆì´ì–´ ìƒ â€” ì›” í‰ê·  5íšŒ ì´ìƒì˜ PRê³¼ ë¦¬ë·°ë¡œ í˜‘ì—… ë¬¸í™”ì— ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤."),
    ],
    "activity_consistency": [
        ((30, 6), "ğŸ“… ê¾¸ì¤€í•¨ì˜ ë‹¬ì¸ ìƒ â€” 6ê°œì›” ì´ìƒ ì›” í‰ê·  30íšŒ ì´ìƒì˜ í™œë™ìœ¼ë¡œ ì¼ê´€ì„±ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤."),
        ((15, 3), "ğŸ”„ ì§€ì†ì„± ìƒ â€” ê¾¸ì¤€í•œ ì›”ë³„ í™œë™ìœ¼ë¡œ ì„±ì‹¤í•¨ì„ ë³´ì—¬ì¤¬ìŠµë‹ˆë‹¤."),
    ],
    "change_scale": [
        (10000, "ğŸŒ‹ ì½”ë“œ í™”ì‚° ìƒ â€” 10000ì¤„ ì´ìƒì˜ í­ë°œì ì¸ ë³€ê²½ìœ¼ë¡œ ìƒˆë¡œìš´ ì‹œëŒ€ë¥¼ ì—´ì—ˆìŠµë‹ˆë‹¤."),
        (5000, "ğŸ—ï¸ ëŒ€ê·œëª¨ ì•„í‚¤í…íŠ¸ ìƒ â€” 5000ì¤„ ì´ìƒì˜ ë³€ê²½ìœ¼ë¡œ ëŒ€ë‹´í•œ ë¦¬íŒ©í„°ë§ì„ ì™„ìˆ˜í–ˆìŠµë‹ˆë‹¤."),
        (2000, "ğŸ”¨ ëŒ€í˜• ë¹Œë” ìƒ â€” 2000ì¤„ ì´ìƒì˜ ë³€ê²½ìœ¼ë¡œ í° ê·œëª¨ì˜ ê°œì„ ì„ ì´ë¤„ëƒˆìŠµë‹ˆë‹¤."),
        (1000, "ğŸ  ì¤‘í˜• ê±´ì¶•ê°€ ìƒ â€” 1000ì¤„ ì´ìƒì˜ ë³€ê²½ìœ¼ë¡œ ì˜ë¯¸ìˆëŠ” ê°œì„ ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤."),
    ],
    "review_dedication": [
        (3.0, "ğŸ” ë¦¬ë·° ë§¤ë‹ˆì•„ ìƒ â€” ìì‹ ì˜ PRë³´ë‹¤ 3ë°° ì´ìƒ ë§ì€ ë¦¬ë·°ë¡œ íŒ€ ì„±ì¥ì— í—Œì‹ í–ˆìŠµë‹ˆë‹¤."),
        (2.0, "ğŸ‘ï¸ ì½”ë“œ ê°ì‹œì ìƒ â€” ìì‹ ì˜ PRë³´ë‹¤ 2ë°° ì´ìƒ ë§ì€ ë¦¬ë·°ë¡œ í’ˆì§ˆ ê´€ë¦¬ì— ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤."),
    ],
}


@dataclass(slots=True)
class Analyzer:
    """Transform collected data into actionable metrics."""

    web_base_url: str = "https://github.com"

    def compute_metrics(
        self,
        collection: CollectionResult,
        detailed_feedback: Optional[DetailedFeedbackSnapshot] = None,
        monthly_trends_data: Optional[List[Dict]] = None,
        tech_stack_data: Optional[Dict[str, int]] = None,
        collaboration_data: Optional[Dict[str, Any]] = None,
    ) -> MetricSnapshot:
        """Compute derived metrics from the collected artefacts."""

        console.log("Analyzing repository trends", f"repo={collection.repo}")

        (
            month_span,
            velocity_score,
            collaboration_score,
            stability_score,
            total_activity,
            period_label,
        ) = self._calculate_scores(collection)

        highlights = self._build_highlights(
            collection,
            period_label,
            month_span,
            velocity_score,
            total_activity,
        )
        spotlight_examples = self._build_spotlight_examples(collection)
        summary = self._build_summary(
            period_label,
            total_activity,
            velocity_score,
            collaboration_score,
            stability_score,
        )
        story_beats = self._build_story_beats(collection, period_label, total_activity)
        awards = self._determine_awards(collection)
        stats = self._build_stats(collection, velocity_score)
        evidence = self._build_evidence(collection)

        # Build year-end specific insights
        monthly_trends = self._build_monthly_trends(monthly_trends_data)
        monthly_insights = self._build_monthly_insights(monthly_trends)
        tech_stack = self._build_tech_stack_analysis(tech_stack_data)
        collaboration = self._build_collaboration_network(collaboration_data)
        reflection_prompts = self._build_reflection_prompts(collection)
        year_end_review = self._build_year_end_review(collection, highlights, awards)

        return MetricSnapshot(
            repo=collection.repo,
            months=collection.months,
            generated_at=datetime.now(timezone.utc),
            status=AnalysisStatus.ANALYSED,
            summary=summary,
            stats=stats,
            evidence=evidence,
            highlights=highlights,
            spotlight_examples=spotlight_examples,
            yearbook_story=story_beats,
            awards=awards,
            detailed_feedback=detailed_feedback,
            monthly_trends=monthly_trends,
            monthly_insights=monthly_insights,
            tech_stack=tech_stack,
            collaboration=collaboration,
            reflection_prompts=reflection_prompts,
            year_end_review=year_end_review,
            since_date=collection.since_date,
            until_date=collection.until_date,
        )

    def _calculate_scores(
        self, collection: CollectionResult
    ) -> tuple[int, float, float, int, int, str]:
        month_span = max(collection.months, 1)
        velocity_score = collection.commits / month_span
        collaboration_score = (collection.pull_requests + collection.reviews) / month_span
        stability_score = max(collection.commits - collection.issues, 0)
        total_activity = collection.commits + collection.pull_requests + collection.reviews

        # More accurate period label
        if collection.months == 12:
            period_label = "ìµœê·¼ 1ë…„"
        elif collection.months == 6:
            period_label = "ìµœê·¼ 6ê°œì›”"
        elif collection.months == 3:
            period_label = "ìµœê·¼ 3ê°œì›”"
        elif collection.months >= 24:
            years = collection.months // 12
            remaining_months = collection.months % 12
            if remaining_months == 0:
                period_label = f"ìµœê·¼ {years}ë…„"
            else:
                period_label = f"ìµœê·¼ {years}ë…„ {remaining_months}ê°œì›”"
        else:
            period_label = f"ìµœê·¼ {collection.months}ê°œì›”"

        return (
            month_span,
            velocity_score,
            collaboration_score,
            stability_score,
            total_activity,
            period_label,
        )

    def _build_highlights(
        self,
        collection: CollectionResult,
        period_label: str,
        month_span: int,
        velocity_score: float,
        total_activity: int,
    ) -> List[str]:
        highlights: List[str] = []
        if collection.commits:
            highlights.append(
                f"{period_label}ì— ì´ {collection.commits}íšŒì˜ ì»¤ë°‹ìœ¼ë¡œ ì½”ë“œë¥¼ ë‹¤ë“¬ê³  ì›” í‰ê·  {velocity_score:.1f}íšŒì˜ ê°œì„ ì„ ì´ì–´ê°”ìŠµë‹ˆë‹¤."
            )
        if collection.pull_requests:
            highlights.append(
                f"{collection.pull_requests}ê±´ì˜ Pull Requestë¥¼ ë³‘í•©í•˜ë©° íŒ€ ë°°í¬ ì£¼ê¸°ë¥¼ ì•ˆì •í™”í–ˆê³  ì›” {collection.pull_requests / month_span:.1f}ê±´ì˜ ë¦´ë¦¬ìŠ¤ë¥¼ ìœ ì§€í–ˆìŠµë‹ˆë‹¤."
            )
        if collection.reviews:
            highlights.append(
                f"{collection.reviews}íšŒì˜ ì½”ë“œ ë¦¬ë·°ë¥¼ í†µí•´ í˜‘ì—… ë¬¸í™”ë¥¼ ê°•í™”í–ˆìŠµë‹ˆë‹¤."
            )
        if collection.issues:
            highlights.append(
                f"í™œë™ ëŒ€ë¹„ {collection.issues}ê±´ì˜ ì´ìŠˆë¡œ ì•ˆì •ì„±ì„ ì§€ì¼°ìŠµë‹ˆë‹¤."
            )
        if not highlights and total_activity == 0:
            highlights.append("ë¶„ì„ ê¸°ê°„ ë™ì•ˆ ëšœë ·í•œ í™œë™ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        return highlights

    def _build_spotlight_examples(self, collection: CollectionResult) -> Dict[str, List[str]]:
        spotlight_examples: Dict[str, List[str]] = {}
        if not collection.pull_request_examples:
            return spotlight_examples

        pr_lines = []
        for pr in collection.pull_request_examples[:3]:
            change_volume = pr.additions + pr.deletions
            scale_phrase = f"ë³€ê²½ {change_volume}ì¤„" if change_volume else "ê²½ëŸ‰ ë³€ê²½"
            merged_phrase = (
                f"{pr.merged_at.date().isoformat()} ë³‘í•©"
                if pr.merged_at
                else "ë¯¸ë³‘í•©"
            )
            pr_lines.append(
                f"PR #{pr.number} Â· {pr.title} â€” {pr.author} ({pr.created_at.date().isoformat()}, {merged_phrase}, {scale_phrase}) Â· {pr.html_url}"
            )
        spotlight_examples["pull_requests"] = pr_lines
        return spotlight_examples

    def _build_summary(
        self,
        period_label: str,
        total_activity: int,
        velocity_score: float,
        collaboration_score: float,
        stability_score: int,
    ) -> Dict[str, str]:
        return {
            "velocity": f"Average {velocity_score:.1f} commits per month",
            "collaboration": "{:.1f} combined PRs and reviews per month".format(collaboration_score),
            "stability": f"Net stability score of {stability_score}",
            "growth": f"{period_label} ë™ì•ˆ {total_activity}ê±´ì˜ í™œë™ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.",
        }

    def _build_story_beats(
        self,
        collection: CollectionResult,
        period_label: str,
        total_activity: int,
    ) -> List[str]:
        story_beats: List[str] = []
        if total_activity:
            story_beats.append(
                f"{period_label} ë™ì•ˆ {collection.repo} ì €ì¥ì†Œì—ì„œ ì´ {total_activity}ê±´ì˜ í™œë™ì„ í¼ì¹˜ë©° ì„±ì¥ ì—”ì§„ì„ ê°€ë™í–ˆìŠµë‹ˆë‹¤."
            )
        else:
            story_beats.append(
                f"{period_label}ì—ëŠ” ì ì‹œ ìˆ¨ì„ ê³ ë¥´ë©° ë‹¤ìŒ ë„ì•½ì„ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤."
            )

        contribution_domains = [
            ("ì»¤ë°‹", collection.commits, "ì§€ì†ì ì¸ ë¦¬íŒ©í„°ë§ê³¼ ê¸°ëŠ¥ í™•ì¥ì„ ì´ëŒì—ˆìŠµë‹ˆë‹¤."),
            ("Pull Request", collection.pull_requests, "í˜‘ì—… ë¦´ë¦¬ìŠ¤ë¥¼ ì£¼ë„í•˜ë©° ë°°í¬ íŒŒì´í”„ë¼ì¸ì„ ì§€ì¼°ìŠµë‹ˆë‹¤."),
            ("ë¦¬ë·°", collection.reviews, "íŒ€ ë™ë£Œë“¤ì˜ ì„±ì¥ì„ ë•ëŠ” ì´˜ì´˜í•œ í”¼ë“œë°±ì„ ì „ë‹¬í–ˆìŠµë‹ˆë‹¤."),
        ]
        top_domain = max(contribution_domains, key=lambda entry: entry[1])
        if top_domain[1]:
            story_beats.append(
                f"ê°€ì¥ ëˆˆì— ëˆ ì˜ì—­ì€ {top_domain[0]} {top_domain[1]}íšŒë¡œ, {top_domain[2]}"
            )

        if collection.pull_request_examples:
            exemplar = collection.pull_request_examples[0]
            merge_phrase = (
                f"{exemplar.merged_at.date().isoformat()} ë³‘í•©"
                if exemplar.merged_at
                else "ì•„ì§ ì§„í–‰ ì¤‘"
            )
            scale = exemplar.additions + exemplar.deletions
            scale_phrase = f"ë³€ê²½ {scale}ì¤„" if scale else "ê²½ëŸ‰ ë³€ê²½"
            story_beats.append(
                "ëŒ€í‘œì‘ìœ¼ë¡œëŠ” PR #{num} `{title}`({author})ê°€ ìˆìŠµë‹ˆë‹¤ â€” {created} ì‘ì„±, {merge} Â· {scale_phrase}.".format(
                    num=exemplar.number,
                    title=exemplar.title,
                    author=exemplar.author,
                    created=exemplar.created_at.date().isoformat(),
                    merge=merge_phrase,
                    scale_phrase=scale_phrase,
                )
            )

        return story_beats

    def _determine_awards(self, collection: CollectionResult) -> List[str]:
        """Determine awards based on collection metrics using data-driven tier system."""
        awards: List[str] = []
        month_span = max(collection.months, 1)

        # Apply tier-based awards
        self._add_tier_award(awards, "commits", collection.commits)
        self._add_tier_award(awards, "pull_requests", collection.pull_requests)
        self._add_tier_award(awards, "reviews", collection.reviews)
        self._add_tier_award(awards, "issues", collection.issues)

        # Velocity-based awards
        velocity_score = collection.commits / month_span
        self._add_tier_award(awards, "velocity", velocity_score)

        # Collaboration-based awards
        collaboration_score = (collection.pull_requests + collection.reviews) / month_span
        self._add_tier_award(awards, "collaboration", collaboration_score)

        # Activity consistency awards
        total_activity = collection.commits + collection.pull_requests + collection.reviews
        activity_per_month = total_activity / month_span
        for (threshold_activity, threshold_months), award_text in AWARD_TIERS["activity_consistency"]:
            if activity_per_month >= threshold_activity and collection.months >= threshold_months:
                awards.append(award_text)
                break

        # All-rounder award
        if (collection.commits >= 50 and
            collection.pull_requests >= 15 and
            collection.reviews >= 15):
            awards.append(
                "ğŸŒŸ ë‹¤ì¬ë‹¤ëŠ¥ ìƒ â€” ì»¤ë°‹, PR, ë¦¬ë·° ì „ ì˜ì—­ì—ì„œ ê· í˜•ì¡íŒ ê¸°ì—¬ë¥¼ ë³´ì—¬ì¤¬ìŠµë‹ˆë‹¤."
            )

        # Large-scale change awards
        if collection.pull_request_examples:
            max_change = max(
                (pr.additions + pr.deletions for pr in collection.pull_request_examples),
                default=0
            )
            self._add_tier_award(awards, "change_scale", max_change)

            # Micro-commit artist award (ë§ì€ ì‘ì€ PR)
            small_prs = sum(1 for pr in collection.pull_request_examples
                          if (pr.additions + pr.deletions) < 50)
            if small_prs >= 10:
                awards.append(
                    "ğŸ¨ ë¯¸ì„¸ ì¡°ìœ¨ ì¥ì¸ ìƒ â€” 10ê°œ ì´ìƒì˜ ì‘ì€ PRë¡œ ì ì§„ì  ê°œì„ ì˜ ë¯¸í•™ì„ ë³´ì—¬ì¤¬ìŠµë‹ˆë‹¤."
                )

            # Big bang award (í° PR)
            huge_prs = sum(1 for pr in collection.pull_request_examples
                         if (pr.additions + pr.deletions) > 1000)
            if huge_prs >= 3:
                awards.append(
                    "ğŸ’¥ ë¹…ë±… ìƒ â€” 3ê°œ ì´ìƒì˜ ëŒ€ê·œëª¨ PRë¡œ í˜ì‹ ì ì¸ ë³€í™”ë¥¼ ì£¼ë„í–ˆìŠµë‹ˆë‹¤."
                )

            # Quick merger award (ë¹ ë¥¸ ë³‘í•©)
            quick_merges = sum(1 for pr in collection.pull_request_examples
                             if pr.merged_at and pr.created_at and
                             (pr.merged_at - pr.created_at).total_seconds() < 3600)
            if quick_merges >= 5:
                awards.append(
                    "âš¡ ìŠ¤í”¼ë“œ ë¨¸ì € ìƒ â€” 5ê°œ ì´ìƒì˜ PRì„ 1ì‹œê°„ ë‚´ ë³‘í•©í•˜ëŠ” ë¯¼ì²©í•¨ì„ ë³´ì—¬ì¤¬ìŠµë‹ˆë‹¤."
                )

        # Review dedication awards
        if collection.pull_requests > 0:
            review_ratio = collection.reviews / collection.pull_requests
            self._add_tier_award(awards, "review_dedication", review_ratio)

        # Balanced contributor award
        if (collection.commits > 0 and collection.pull_requests > 0 and collection.reviews > 0):
            commit_ratio = collection.commits / total_activity
            pr_ratio = collection.pull_requests / total_activity
            review_ratio = collection.reviews / total_activity

            # Check if all three are balanced (each between 20% and 50%)
            if all(0.2 <= ratio <= 0.5 for ratio in [commit_ratio, pr_ratio, review_ratio]):
                awards.append(
                    "âš–ï¸ ê· í˜•ì¡íŒ ê¸°ì—¬ì ìƒ â€” ì»¤ë°‹, PR, ë¦¬ë·°ë¥¼ ì™„ë²½í•˜ê²Œ ê· í˜•ìˆê²Œ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤."
                )

        # High PR merge rate
        if collection.pull_requests >= 20 and collection.pull_request_examples:
            merged_count = sum(1 for pr in collection.pull_request_examples if pr.merged_at)
            merge_rate = merged_count / len(collection.pull_request_examples)
            if merge_rate >= 0.9:
                awards.append(
                    "âœ… ë¨¸ì§€ ë§ˆìŠ¤í„° ìƒ â€” 90% ì´ìƒì˜ ë†’ì€ PR ë³‘í•©ë¥ ë¡œ íƒì›”í•œ ì½”ë“œ í’ˆì§ˆì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤."
                )

        # Stability award
        if collection.issues and collection.issues <= max(collection.commits // 6, 1):
            awards.append(
                "ğŸ›¡ï¸ ì•ˆì • ì§€í‚´ì´ ìƒ â€” í™œë™ ëŒ€ë¹„ ì ì€ ì´ìŠˆë¡œ ì•ˆì •ì„±ì„ ì§€ì¼°ìŠµë‹ˆë‹¤."
            )

        # Issue warrior award
        if collection.issues > collection.commits and collection.issues >= 30:
            awards.append(
                "ğŸ› ï¸ ì´ìŠˆ ì „ì‚¬ ìƒ â€” ì»¤ë°‹ë³´ë‹¤ ë§ì€ ì´ìŠˆ ì²˜ë¦¬ë¡œ í”„ë¡œì íŠ¸ ì•ˆì •ì„±ì— ì§‘ì¤‘í–ˆìŠµë‹ˆë‹¤."
            )

        # Review champion (ë¦¬ë·°ê°€ ê°€ì¥ ë§ì€ ê²½ìš°)
        if (collection.reviews > collection.commits and
            collection.reviews > collection.pull_requests and
            collection.reviews >= 30):
            awards.append(
                "ğŸ‘¨â€ğŸ« ë¦¬ë·° ì±”í”¼ì–¸ ìƒ â€” ë‹¤ë¥¸ í™œë™ë³´ë‹¤ ë¦¬ë·°ì— ì§‘ì¤‘í•˜ë©° íŒ€ ì„±ì¥ì˜ ë©˜í† ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤."
            )

        # Commit machine (ì»¤ë°‹ì´ ì••ë„ì ìœ¼ë¡œ ë§ì€ ê²½ìš°)
        if (collection.commits > collection.pull_requests * 3 and
            collection.commits > collection.reviews * 3 and
            collection.commits >= 100):
            awards.append(
                "ğŸ”¥ ì»¤ë°‹ ë¨¸ì‹  ìƒ â€” ì••ë„ì ì¸ ì»¤ë°‹ ìˆ˜ë¡œ ì½”ë“œë² ì´ìŠ¤ì˜ í•µì‹¬ ë™ë ¥ì´ ë˜ì—ˆìŠµë‹ˆë‹¤."
            )

        # Renaissance developer (ëª¨ë“  ì§€í‘œê°€ ë†’ìŒ)
        if (collection.commits >= 100 and
            collection.pull_requests >= 30 and
            collection.reviews >= 50 and
            collection.issues >= 10):
            awards.append(
                "ğŸ­ ë¥´ë„¤ìƒìŠ¤ ê°œë°œì ìƒ â€” ëª¨ë“  ì˜ì—­ì—ì„œ ë›°ì–´ë‚œ í™œì•½ì„ í¼ì¹œ ì™„ë²½í•œ ì˜¬ë¼ìš´ë”ì…ë‹ˆë‹¤."
            )

        # Consistency king (ë§¤ìš° ê¾¸ì¤€í•œ í™œë™)
        if collection.months >= 6 and activity_per_month >= 20:
            variance_threshold = activity_per_month * 0.3
            if variance_threshold > 0:  # Assuming low variance
                awards.append(
                    "ğŸ‘‘ ì¼ê´€ì„±ì˜ ì™• ìƒ â€” 6ê°œì›” ì´ìƒ ì›” 20íšŒ ì´ìƒì˜ ê¾¸ì¤€í•œ í™œë™ì„ ìœ ì§€í–ˆìŠµë‹ˆë‹¤."
                )

        # Sprint finisher (ìµœê·¼ í™œë™ì´ ë§ì€ ê²½ìš° - ì¶”ì •)
        if collection.months >= 3 and velocity_score >= 30:
            awards.append(
                "ğŸ ìŠ¤í”„ë¦°íŠ¸ í”¼ë‹ˆì…” ìƒ â€” ë†’ì€ ì›”í‰ê·  ì†ë„ë¡œ í”„ë¡œì íŠ¸ë¥¼ ë¹ ë¥´ê²Œ ì „ì§„ì‹œì¼°ìŠµë‹ˆë‹¤."
            )

        # Quality guardian (ì´ìŠˆ ëŒ€ë¹„ ë†’ì€ ë¦¬ë·°)
        if collection.reviews >= 30 and collection.issues > 0:
            review_issue_ratio = collection.reviews / collection.issues
            if review_issue_ratio >= 3:
                awards.append(
                    "ğŸ¯ í’ˆì§ˆ ìˆ˜í˜¸ì ìƒ â€” ì´ìŠˆ ëŒ€ë¹„ 3ë°° ì´ìƒì˜ ë¦¬ë·°ë¡œ ì‚¬ì „ í’ˆì§ˆ ê´€ë¦¬ì— í˜ì¼ìŠµë‹ˆë‹¤."
                )

        # Documentation hero (READMEë‚˜ ë¬¸ì„œ ê¸°ì—¬ - ê°„ì ‘ ì¶”ì •)
        # Note: ì‹¤ì œë¡œëŠ” PR ì˜ˆì œë¥¼ í†µí•´ í™•ì¸í•´ì•¼ í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” PR ìˆ˜ì™€ ì»¤ë°‹ ë¹„ìœ¨ë¡œ ì¶”ì •
        if collection.pull_requests >= 20 and collection.pull_request_examples:
            # PR íƒ€ì´í‹€ì— docs, readme, documentation ë“±ì´ í¬í•¨ëœ ê²½ìš°ë¥¼ ì²´í¬
            doc_prs = sum(1 for pr in collection.pull_request_examples
                         if any(keyword in pr.title.lower()
                               for keyword in ['doc', 'readme', 'documentation', 'ë¬¸ì„œ']))
            if doc_prs >= 5:
                awards.append(
                    "ğŸ“š ë¬¸ì„œí™” ì˜ì›… ìƒ â€” 5ê°œ ì´ìƒì˜ ë¬¸ì„œ PRë¡œ ì§€ì‹ ê³µìœ ì— ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤."
                )

        # Test advocate (test ê´€ë ¨ PR)
        if collection.pull_request_examples:
            test_prs = sum(1 for pr in collection.pull_request_examples
                          if any(keyword in pr.title.lower()
                                for keyword in ['test', 'testing', 'í…ŒìŠ¤íŠ¸', 'spec']))
            if test_prs >= 5:
                awards.append(
                    "ğŸ§ª í…ŒìŠ¤íŠ¸ ì˜¹í˜¸ì ìƒ â€” 5ê°œ ì´ìƒì˜ í…ŒìŠ¤íŠ¸ PRë¡œ ì½”ë“œ ì•ˆì •ì„±ì„ ê°•í™”í–ˆìŠµë‹ˆë‹¤."
                )

        # Refactoring master (refactor ê´€ë ¨ PR)
        if collection.pull_request_examples:
            refactor_prs = sum(1 for pr in collection.pull_request_examples
                              if any(keyword in pr.title.lower()
                                    for keyword in ['refactor', 'refactoring', 'ë¦¬íŒ©í„°ë§', 'cleanup', 'clean']))
            if refactor_prs >= 5:
                awards.append(
                    "â™»ï¸ ë¦¬íŒ©í„°ë§ ë§ˆìŠ¤í„° ìƒ â€” 5ê°œ ì´ìƒì˜ ë¦¬íŒ©í„°ë§ PRë¡œ ì½”ë“œ í’ˆì§ˆì„ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤."
                )

        # Bug squasher (fix, bug ê´€ë ¨ PR)
        if collection.pull_request_examples:
            bug_prs = sum(1 for pr in collection.pull_request_examples
                         if any(keyword in pr.title.lower()
                               for keyword in ['fix', 'bug', 'hotfix', 'ë²„ê·¸', 'ìˆ˜ì •']))
            if bug_prs >= 10:
                awards.append(
                    "ğŸ› ë²„ê·¸ ìŠ¤ì¿¼ì…” ìƒ â€” 10ê°œ ì´ìƒì˜ ë²„ê·¸ ìˆ˜ì • PRë¡œ ì•ˆì •ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤."
                )

        # Feature factory (feature, feat ê´€ë ¨ PR)
        if collection.pull_request_examples:
            feature_prs = sum(1 for pr in collection.pull_request_examples
                             if any(keyword in pr.title.lower()
                                   for keyword in ['feature', 'feat', 'add', 'new', 'ì¶”ê°€', 'ê¸°ëŠ¥']))
            if feature_prs >= 10:
                awards.append(
                    "ğŸ­ ê¸°ëŠ¥ ê³µì¥ ìƒ â€” 10ê°œ ì´ìƒì˜ ê¸°ëŠ¥ ì¶”ê°€ PRë¡œ ì œí’ˆì„ í’ë¶€í•˜ê²Œ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤."
                )

        # Early bird / Night owl (ì‹œê°„ ê¸°ë°˜ì€ ë°ì´í„°ê°€ ì—†ì–´ ìƒëµ)

        # Default award if no other awards
        if not awards:
            awards.append(
                "ğŸŒ± ì„±ì¥ ì”¨ì•— ìƒ â€” ì‘ì€ ë°œê±¸ìŒë“¤ì´ ëª¨ì—¬ ë‚´ì¼ì˜ í° ì„±ì¥ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤."
            )

        return awards

    @staticmethod
    def _add_tier_award(awards: List[str], category: str, value: float) -> None:
        """Add tier-based award if value meets threshold.

        Args:
            awards: List to append awards to
            category: Award category key from AWARD_TIERS
            value: Metric value to check against thresholds
        """
        if category not in AWARD_TIERS:
            return

        for threshold, award_text in AWARD_TIERS[category]:
            if value >= threshold:
                awards.append(award_text)
                break

    def _build_stats(self, collection: CollectionResult, velocity_score: float) -> Dict[str, Dict[str, float]]:
        return {
            "commits": {
                "total": float(collection.commits),
                "per_month": velocity_score,
            },
            "pull_requests": {
                "total": float(collection.pull_requests),
            },
            "reviews": {
                "total": float(collection.reviews),
            },
            "issues": {
                "total": float(collection.issues),
            },
        }

    def _build_evidence(self, collection: CollectionResult) -> Dict[str, List[str]]:
        repo_root = f"{self.web_base_url.rstrip('/')}/{collection.repo}"
        return {
            "commits": [
                f"{repo_root}/commits",
            ],
            "pull_requests": [
                f"{repo_root}/pulls",
            ],
        }

    def build_detailed_feedback(
        self,
        commit_analysis: Optional[Dict] = None,
        pr_title_analysis: Optional[Dict] = None,
        review_tone_analysis: Optional[Dict] = None,
        issue_analysis: Optional[Dict] = None,
    ) -> DetailedFeedbackSnapshot:
        """Build detailed feedback snapshot from LLM analysis results."""

        commit_feedback = None
        if commit_analysis:
            commit_feedback = CommitMessageFeedback(
                total_commits=commit_analysis.get("good_messages", 0)
                + commit_analysis.get("poor_messages", 0),
                good_messages=commit_analysis.get("good_messages", 0),
                poor_messages=commit_analysis.get("poor_messages", 0),
                suggestions=commit_analysis.get("suggestions", []),
                examples_good=commit_analysis.get("examples_good", []),
                examples_poor=commit_analysis.get("examples_poor", []),
            )

        pr_title_feedback = None
        if pr_title_analysis:
            pr_title_feedback = PRTitleFeedback(
                total_prs=pr_title_analysis.get("clear_titles", 0)
                + pr_title_analysis.get("vague_titles", 0),
                clear_titles=pr_title_analysis.get("clear_titles", 0),
                vague_titles=pr_title_analysis.get("vague_titles", 0),
                suggestions=pr_title_analysis.get("suggestions", []),
                examples_good=pr_title_analysis.get("examples_good", []),
                examples_poor=pr_title_analysis.get("examples_poor", []),
            )

        review_tone_feedback = None
        if review_tone_analysis:
            review_tone_feedback = ReviewToneFeedback(
                total_reviews=review_tone_analysis.get("constructive_reviews", 0)
                + review_tone_analysis.get("harsh_reviews", 0)
                + review_tone_analysis.get("neutral_reviews", 0),
                constructive_reviews=review_tone_analysis.get("constructive_reviews", 0),
                harsh_reviews=review_tone_analysis.get("harsh_reviews", 0),
                neutral_reviews=review_tone_analysis.get("neutral_reviews", 0),
                suggestions=review_tone_analysis.get("suggestions", []),
                examples_good=review_tone_analysis.get("examples_good", []),
                examples_improve=review_tone_analysis.get("examples_improve", []),
            )

        issue_feedback = None
        if issue_analysis:
            issue_feedback = IssueFeedback(
                total_issues=issue_analysis.get("well_described", 0)
                + issue_analysis.get("poorly_described", 0),
                well_described=issue_analysis.get("well_described", 0),
                poorly_described=issue_analysis.get("poorly_described", 0),
                suggestions=issue_analysis.get("suggestions", []),
                examples_good=issue_analysis.get("examples_good", []),
                examples_poor=issue_analysis.get("examples_poor", []),
            )

        return DetailedFeedbackSnapshot(
            commit_feedback=commit_feedback,
            pr_title_feedback=pr_title_feedback,
            review_tone_feedback=review_tone_feedback,
            issue_feedback=issue_feedback,
        )

    def _build_monthly_trends(
        self, monthly_trends_data: Optional[List[Dict]]
    ) -> List[MonthlyTrend]:
        """Build monthly trend objects from raw data."""
        if not monthly_trends_data:
            return []

        trends = []
        for data in monthly_trends_data:
            trends.append(
                MonthlyTrend(
                    month=data.get("month", ""),
                    commits=data.get("commits", 0),
                    pull_requests=data.get("pull_requests", 0),
                    reviews=data.get("reviews", 0),
                    issues=data.get("issues", 0),
                )
            )
        return trends

    def _build_monthly_insights(
        self, monthly_trends: List[MonthlyTrend]
    ) -> Optional[MonthlyTrendInsights]:
        """Analyze monthly trends and generate insights."""
        if not monthly_trends or len(monthly_trends) < 2:
            return None

        # Calculate total activity per month
        monthly_activities = [
            (trend.month, trend.commits + trend.pull_requests + trend.reviews + trend.issues)
            for trend in monthly_trends
        ]

        # Find peak and quiet months
        peak_month_data = max(monthly_activities, key=lambda x: x[1])
        peak_month = peak_month_data[0] if peak_month_data[1] > 0 else None

        non_zero_activities = [(month, activity) for month, activity in monthly_activities if activity > 0]
        quiet_month = None
        if non_zero_activities:
            quiet_month_data = min(non_zero_activities, key=lambda x: x[1])
            quiet_month = quiet_month_data[0]

        # Calculate active months
        total_active_months = sum(1 for _, activity in monthly_activities if activity > 0)

        # Calculate trend direction (simple linear regression approach)
        if len(monthly_trends) >= 3:
            recent_half = monthly_activities[len(monthly_activities)//2:]
            early_half = monthly_activities[:len(monthly_activities)//2]

            recent_avg = sum(act for _, act in recent_half) / len(recent_half) if recent_half else 0
            early_avg = sum(act for _, act in early_half) / len(early_half) if early_half else 0

            if recent_avg > early_avg * 1.2:
                trend_direction = "increasing"
            elif recent_avg < early_avg * 0.8:
                trend_direction = "decreasing"
            else:
                trend_direction = "stable"
        else:
            trend_direction = "stable"

        # Calculate consistency score (coefficient of variation)
        activities = [act for _, act in monthly_activities if act > 0]
        if activities and len(activities) >= 2:
            import math
            mean_activity = sum(activities) / len(activities)
            variance = sum((act - mean_activity) ** 2 for act in activities) / len(activities)
            std_dev = math.sqrt(variance)

            # Coefficient of variation (lower is more consistent)
            cv = std_dev / mean_activity if mean_activity > 0 else 1.0
            # Convert to 0-1 score (1 = perfect consistency, 0 = highly variable)
            # Cap cv at 1.0 for scoring purposes
            consistency_score = max(0.0, 1.0 - min(cv, 1.0))
        else:
            consistency_score = 0.0

        # Generate human-readable insights
        insights = []

        if peak_month:
            peak_activity = peak_month_data[1]
            insights.append(
                f"{peak_month}ì— ê°€ì¥ í™œë°œí–ˆìŠµë‹ˆë‹¤ (ì´ {peak_activity}ê±´ì˜ í™œë™)"
            )

        if quiet_month and quiet_month != peak_month:
            quiet_activity = next((act for month, act in monthly_activities if month == quiet_month), 0)
            insights.append(
                f"{quiet_month}ì—ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ì¡°ìš©í–ˆìŠµë‹ˆë‹¤ (ì´ {quiet_activity}ê±´ì˜ í™œë™)"
            )

        if trend_direction == "increasing":
            insights.append(
                "ì‹œê°„ì´ ì§€ë‚ ìˆ˜ë¡ í™œë™ëŸ‰ì´ ì¦ê°€í•˜ëŠ” ì„±ì¥ ì¶”ì„¸ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤"
            )
        elif trend_direction == "decreasing":
            insights.append(
                "ìµœê·¼ í™œë™ëŸ‰ì´ ê°ì†Œí•˜ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ë™ê¸° ë¶€ì—¬ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
            )
        else:
            insights.append(
                "ê¾¸ì¤€í•œ í™œë™ ìˆ˜ì¤€ì„ ìœ ì§€í–ˆìŠµë‹ˆë‹¤"
            )

        if consistency_score > 0.7:
            insights.append(
                f"ë§¤ìš° ì¼ê´€ëœ í™œë™ íŒ¨í„´ì„ ë³´ì˜€ìŠµë‹ˆë‹¤ (ì¼ê´€ì„± ì ìˆ˜: {consistency_score:.1%})"
            )
        elif consistency_score < 0.3:
            insights.append(
                f"í™œë™ëŸ‰ì˜ ë³€ë™ì´ í° í¸ì…ë‹ˆë‹¤ (ì¼ê´€ì„± ì ìˆ˜: {consistency_score:.1%}). "
                "ë” ê· í˜•ì¡íŒ ê¸°ì—¬ ë¦¬ë“¬ì„ ë§Œë“¤ì–´ë³´ì„¸ìš”"
            )

        # Analyze specific activity types
        commits_trend = [trend.commits for trend in monthly_trends]
        prs_trend = [trend.pull_requests for trend in monthly_trends]
        reviews_trend = [trend.reviews for trend in monthly_trends]

        if commits_trend and max(commits_trend) > 0:
            peak_commit_month = monthly_trends[commits_trend.index(max(commits_trend))].month
            insights.append(
                f"ì»¤ë°‹ í™œë™ì€ {peak_commit_month}ì— ì •ì ì„ ì°ì—ˆìŠµë‹ˆë‹¤ ({max(commits_trend)}íšŒ)"
            )

        if prs_trend and max(prs_trend) > 0:
            peak_pr_month = monthly_trends[prs_trend.index(max(prs_trend))].month
            if max(prs_trend) >= 10:
                insights.append(
                    f"PR í™œë™ì€ {peak_pr_month}ì— ê°€ì¥ ì™•ì„±í–ˆìŠµë‹ˆë‹¤ ({max(prs_trend)}ê°œ)"
                )

        return MonthlyTrendInsights(
            peak_month=peak_month,
            quiet_month=quiet_month,
            trend_direction=trend_direction,
            total_active_months=total_active_months,
            consistency_score=consistency_score,
            insights=insights,
        )

    def _build_tech_stack_analysis(
        self, tech_stack_data: Optional[Dict[str, int]]
    ) -> Optional[TechStackAnalysis]:
        """Analyze technology stack from file changes."""
        if not tech_stack_data:
            return None

        # Calculate top languages
        sorted_languages = sorted(
            tech_stack_data.items(), key=lambda x: x[1], reverse=True
        )
        top_languages = [lang for lang, _ in sorted_languages[:5]]

        # Calculate diversity score (Shannon entropy normalized)
        total_files = sum(tech_stack_data.values())
        if total_files == 0:
            diversity_score = 0.0
        else:
            import math
            entropy = 0.0
            for count in tech_stack_data.values():
                if count > 0:
                    p = count / total_files
                    entropy -= p * math.log2(p)
            # Normalize to 0-1 range (max entropy is log2(n))
            max_entropy = math.log2(len(tech_stack_data)) if len(tech_stack_data) > 1 else 1
            diversity_score = entropy / max_entropy if max_entropy > 0 else 0.0

        return TechStackAnalysis(
            languages=tech_stack_data,
            top_languages=top_languages,
            diversity_score=diversity_score,
        )

    def _build_collaboration_network(
        self, collaboration_data: Optional[Dict[str, Any]]
    ) -> Optional[CollaborationNetwork]:
        """Build collaboration network from reviewer data."""
        if not collaboration_data:
            return None

        pr_reviewers = collaboration_data.get("pr_reviewers", {})
        sorted_reviewers = sorted(
            pr_reviewers.items(), key=lambda x: x[1], reverse=True
        )
        top_reviewers = [reviewer for reviewer, _ in sorted_reviewers[:5]]

        return CollaborationNetwork(
            pr_reviewers=pr_reviewers,
            top_reviewers=top_reviewers,
            review_received_count=collaboration_data.get("review_received_count", 0),
            unique_collaborators=collaboration_data.get("unique_collaborators", 0),
        )

    def _build_reflection_prompts(
        self, collection: CollectionResult
    ) -> ReflectionPrompts:
        """Generate self-reflection questions for year-end review."""
        questions = [
            "ì˜¬í•´ ë‚´ê°€ ê°€ì¥ ìë‘ìŠ¤ëŸ¬ì›Œí•˜ëŠ” ê¸°ìˆ ì  ì„±ì·¨ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
            "ê°€ì¥ ì–´ë ¤ì› ë˜ ê¸°ìˆ ì  ë„ì „ì€ ë¬´ì—‡ì´ì—ˆê³ , ì–´ë–»ê²Œ ê·¹ë³µí–ˆë‚˜ìš”?",
            "ì˜¬í•´ ìƒˆë¡­ê²Œ ë°°ìš´ ê¸°ìˆ ì´ë‚˜ ë„êµ¬ ì¤‘ ê°€ì¥ ìœ ìš©í–ˆë˜ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ì½”ë“œ ë¦¬ë·°ë¥¼ í†µí•´ ë°›ì€ í”¼ë“œë°± ì¤‘ ê°€ì¥ ê¸°ì–µì— ë‚¨ëŠ” ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "íŒ€ì›ë“¤ê³¼ì˜ í˜‘ì—…ì—ì„œ ê°€ì¥ ë¿Œë“¯í–ˆë˜ ìˆœê°„ì€ ì–¸ì œì˜€ë‚˜ìš”?",
            "ë‚´ ì½”ë“œê°€ íŒ€ì´ë‚˜ ì‚¬ìš©ìì—ê²Œ ê°€ì¥ í° ì˜í–¥ì„ ì¤€ ìˆœê°„ì€ ì–¸ì œì˜€ë‚˜ìš”?",
            "ì˜¬í•´ ë‚´ ê°œë°œ í”„ë¡œì„¸ìŠ¤ë‚˜ ìŠµê´€ì—ì„œ ê°œì„ ëœ ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ì•ìœ¼ë¡œ ë” ë°œì „ì‹œí‚¤ê³  ì‹¶ì€ ê¸°ìˆ  ì˜ì—­ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ë‚´ë…„ì— ë„ì „í•˜ê³  ì‹¶ì€ ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ë‚˜ ê¸°ìˆ ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ê°œë°œìë¡œì„œ ë‚´ë…„ì˜ ë‚˜ëŠ” ì–´ë–¤ ëª¨ìŠµì´ê¸¸ ë°”ë¼ë‚˜ìš”?",
        ]

        # Add context-specific questions based on activity
        if collection.commits > 100:
            questions.append(
                f"ì˜¬í•´ {collection.commits}íšŒì˜ ì»¤ë°‹ì„ ì‘ì„±í–ˆìŠµë‹ˆë‹¤. ì´ ì¤‘ ê°€ì¥ ì˜ë¯¸ìˆì—ˆë˜ ì»¤ë°‹ì€ ë¬´ì—‡ì´ì—ˆë‚˜ìš”?"
            )

        if collection.reviews > 50:
            questions.append(
                f"{collection.reviews}íšŒì˜ ì½”ë“œ ë¦¬ë·°ë¥¼ ì§„í–‰í–ˆìŠµë‹ˆë‹¤. ë¦¬ë·°ë¥¼ í†µí•´ ë°°ìš´ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?"
            )

        if collection.pull_requests > 30:
            questions.append(
                f"{collection.pull_requests}ê°œì˜ Pull Requestë¥¼ ì‘ì„±í–ˆìŠµë‹ˆë‹¤. ê°€ì¥ ë³µì¡í–ˆë˜ PRì€ ë¬´ì—‡ì´ì—ˆê³ , ì–´ë–¤ ì ì´ ì–´ë ¤ì› ë‚˜ìš”?"
            )

        return ReflectionPrompts(questions=questions)

    def _build_year_end_review(
        self,
        collection: CollectionResult,
        highlights: List[str],
        awards: List[str],
    ) -> YearEndReview:
        """Generate year-end specific review content based on actual data."""

        # Proudest moments based on actual metrics
        proudest_moments = []
        if collection.commits > 200:
            proudest_moments.append(
                f"ì´ {collection.commits}íšŒì˜ ì»¤ë°‹ìœ¼ë¡œ ê¾¸ì¤€íˆ ì½”ë“œë² ì´ìŠ¤ë¥¼ ê°œì„ í–ˆìŠµë‹ˆë‹¤."
            )
        if collection.pull_requests > 50:
            proudest_moments.append(
                f"{collection.pull_requests}ê°œì˜ Pull Requestë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¨¸ì§€í–ˆìŠµë‹ˆë‹¤."
            )
        if collection.reviews > 50:
            proudest_moments.append(
                f"{collection.reviews}íšŒì˜ ì½”ë“œ ë¦¬ë·°ë¡œ íŒ€ì˜ ì½”ë“œ í’ˆì§ˆ í–¥ìƒì— ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤."
            )

        # Add insights from PR examples
        if collection.pull_request_examples:
            total_changes = sum(pr.additions + pr.deletions for pr in collection.pull_request_examples)
            avg_changes = total_changes // len(collection.pull_request_examples) if collection.pull_request_examples else 0
            if total_changes > 10000:
                proudest_moments.append(
                    f"ì´ {total_changes:,}ì¤„ì˜ ì½”ë“œ ë³€ê²½ìœ¼ë¡œ ëŒ€ê·œëª¨ ê°œì„ ì„ ì£¼ë„í–ˆìŠµë‹ˆë‹¤."
                )

            # Find largest PR
            largest_pr = max(collection.pull_request_examples,
                           key=lambda pr: pr.additions + pr.deletions)
            if (largest_pr.additions + largest_pr.deletions) > 1000:
                proudest_moments.append(
                    f"ê°€ì¥ í° PR(#{largest_pr.number}: {largest_pr.title})ì—ì„œ "
                    f"{largest_pr.additions + largest_pr.deletions:,}ì¤„ì˜ ë³€ê²½ìœ¼ë¡œ ë„ì „ì ì¸ ì‘ì—…ì„ ì™„ìˆ˜í–ˆìŠµë‹ˆë‹¤."
                )

        if not proudest_moments:
            proudest_moments.append(
                "ê¾¸ì¤€í•œ í™œë™ìœ¼ë¡œ í”„ë¡œì íŠ¸ ë°œì „ì— ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤."
            )

        # Data-driven challenges based on activity patterns
        biggest_challenges = []
        month_span = max(collection.months, 1)

        if collection.pull_requests > 30:
            avg_pr_per_month = collection.pull_requests / month_span
            biggest_challenges.append(
                f"ì›”í‰ê·  {avg_pr_per_month:.1f}ê°œì˜ PRì„ ê´€ë¦¬í•˜ë©° ì§€ì†ì ì¸ ë°°í¬ ë¦¬ë“¬ì„ ìœ ì§€í•˜ëŠ” ë„ì „ì„ í•´ëƒˆìŠµë‹ˆë‹¤."
            )

        if collection.reviews > 20:
            biggest_challenges.append(
                f"{collection.reviews}íšŒì˜ ì½”ë“œ ë¦¬ë·°ë¥¼ ì§„í–‰í•˜ë©° íŒ€ì›ë“¤ì˜ ë‹¤ì–‘í•œ ê´€ì ì„ ì´í•´í•˜ê³  ì¡°ìœ¨í–ˆìŠµë‹ˆë‹¤."
            )

        if collection.issues > 0:
            biggest_challenges.append(
                f"{collection.issues}ê±´ì˜ ì´ìŠˆë¥¼ ì²˜ë¦¬í•˜ë©° ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ê³¼ ìš°ì„ ìˆœìœ„ íŒë‹¨ ëŠ¥ë ¥ì„ í‚¤ì› ìŠµë‹ˆë‹¤."
            )

        # Add PR-specific challenges
        if collection.pull_request_examples:
            feature_prs = [pr for pr in collection.pull_request_examples
                         if any(kw in pr.title.lower() for kw in ['feature', 'feat', 'ê¸°ëŠ¥', 'add'])]
            if len(feature_prs) > 5:
                biggest_challenges.append(
                    f"{len(feature_prs)}ê°œì˜ ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ ê°œë°œí•˜ë©° ìš”êµ¬ì‚¬í•­ ë¶„ì„ê³¼ ì„¤ê³„ ëŠ¥ë ¥ì„ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤."
                )

        if not biggest_challenges:
            biggest_challenges = [
                "ë³µì¡í•œ ê¸°ìˆ ì  ë¬¸ì œë¥¼ í•´ê²°í•˜ë©° ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ í‚¤ì› ìŠµë‹ˆë‹¤.",
                "íŒ€ì›ë“¤ê³¼ì˜ í˜‘ì—…ì„ í†µí•´ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ìŠ¤í‚¬ì„ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.",
            ]

        # Data-driven lessons learned
        lessons_learned = []

        if collection.commits > 0 and collection.pull_requests > 0:
            commits_per_pr = collection.commits / collection.pull_requests
            if commits_per_pr > 5:
                lessons_learned.append(
                    f"PRë‹¹ í‰ê·  {commits_per_pr:.1f}ê°œì˜ ì»¤ë°‹ì„ ì‘ì„±í–ˆìŠµë‹ˆë‹¤. "
                    "ì‘ì€ ë‹¨ìœ„ë¡œ ìì£¼ ì»¤ë°‹í•˜ê³  ë¦¬ë·°ë°›ëŠ” ê²ƒì´ ë” íš¨ê³¼ì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                )
            else:
                lessons_learned.append(
                    f"PRë‹¹ í‰ê·  {commits_per_pr:.1f}ê°œì˜ ì»¤ë°‹ìœ¼ë¡œ ì ì ˆí•œ í¬ê¸°ì˜ ë³€ê²½ì„ ìœ ì§€í–ˆìŠµë‹ˆë‹¤. "
                    "ì‘ê³  ì§‘ì¤‘ëœ PRì´ ë¦¬ë·°ì™€ ë³‘í•©ì„ ë” ì‰½ê²Œ ë§Œë“­ë‹ˆë‹¤."
                )

        if collection.reviews > 0 and collection.pull_requests > 0:
            review_ratio = collection.reviews / collection.pull_requests
            if review_ratio > 2:
                lessons_learned.append(
                    f"ë‚´ PRë³´ë‹¤ {review_ratio:.1f}ë°° ë§ì€ ë¦¬ë·°ë¥¼ ì§„í–‰í–ˆìŠµë‹ˆë‹¤. "
                    "ì½”ë“œ ë¦¬ë·°ëŠ” íŒ€ì˜ ì½”ë“œ í’ˆì§ˆì„ ë†’ì´ê³  ì§€ì‹ì„ ê³µìœ í•˜ëŠ” í•µì‹¬ í™œë™ì…ë‹ˆë‹¤."
                )
            else:
                lessons_learned.append(
                    "ì½”ë“œ ë¦¬ë·°ë¥¼ í†µí•´ ë‹¤ë¥¸ íŒ€ì›ë“¤ì˜ ì ‘ê·¼ ë°©ì‹ì„ ë°°ìš°ê³  ì‹œì•¼ë¥¼ ë„“í ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤."
                )

        if collection.pull_request_examples:
            merged_prs = [pr for pr in collection.pull_request_examples if pr.merged_at]
            if merged_prs:
                merge_rate = len(merged_prs) / len(collection.pull_request_examples)
                if merge_rate > 0.8:
                    lessons_learned.append(
                        f"{merge_rate*100:.0f}%ì˜ ë†’ì€ PR ë¨¸ì§€ìœ¨ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. "
                        "ëª…í™•í•œ ëª©ì ê³¼ ì¶©ë¶„í•œ ì„¤ëª…ì´ ìˆëŠ” PRì´ ì„±ê³µë¥ ì„ ë†’ì…ë‹ˆë‹¤."
                    )

        if not lessons_learned:
            lessons_learned = [
                "ì‘ê³  ìì£¼ ì»¤ë°‹í•˜ëŠ” ê²ƒì´ ì½”ë“œ ë¦¬ë·°ì™€ í˜‘ì—…ì— ë” íš¨ê³¼ì ì…ë‹ˆë‹¤.",
                "ì½”ë“œ ë¦¬ë·°ëŠ” ë‹¨ìˆœí•œ ë²„ê·¸ ì°¾ê¸°ê°€ ì•„ë‹Œ ì§€ì‹ ê³µìœ ì˜ ì¥ì…ë‹ˆë‹¤.",
            ]

        # Data-informed next year goals
        next_year_goals = []

        # Goals based on current weak points
        if collection.reviews < collection.pull_requests:
            next_year_goals.append(
                "ì½”ë“œ ë¦¬ë·° ì°¸ì—¬ë¥¼ ëŠ˜ë ¤ íŒ€ì˜ ì½”ë“œ í’ˆì§ˆ í–¥ìƒì— ë”ìš± ê¸°ì—¬í•˜ê¸°"
            )

        if collection.pull_request_examples:
            doc_prs = [pr for pr in collection.pull_request_examples
                      if any(kw in pr.title.lower() for kw in ['doc', 'readme', 'ë¬¸ì„œ'])]
            if len(doc_prs) < 3:
                next_year_goals.append(
                    "ë¬¸ì„œí™”ì— ë” ì‹ ê²½ì¨ì„œ í”„ë¡œì íŠ¸ì˜ ì ‘ê·¼ì„±ê³¼ ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒí•˜ê¸°"
                )

            test_prs = [pr for pr in collection.pull_request_examples
                       if any(kw in pr.title.lower() for kw in ['test', 'í…ŒìŠ¤íŠ¸'])]
            if len(test_prs) < 5:
                next_year_goals.append(
                    "í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ë¥¼ ë†’ì—¬ ì½”ë“œì˜ ì•ˆì •ì„±ê³¼ ì‹ ë¢°ë„ ê°•í™”í•˜ê¸°"
                )

        # Always include growth goals
        next_year_goals.append(
            "ìƒˆë¡œìš´ ê¸°ìˆ ì´ë‚˜ í”„ë ˆì„ì›Œí¬ë¥¼ í•™ìŠµí•˜ì—¬ ê¸°ìˆ  ìŠ¤íƒ í™•ì¥í•˜ê¸°"
        )
        next_year_goals.append(
            "ì˜¤í”ˆì†ŒìŠ¤ ê¸°ì—¬ë‚˜ ê¸°ìˆ  ê³µìœ ë¥¼ í†µí•´ ê°œë°œ ì»¤ë®¤ë‹ˆí‹°ì— í™˜ì›í•˜ê¸°"
        )

        # Limit to 5 goals
        next_year_goals = next_year_goals[:5]

        return YearEndReview(
            proudest_moments=proudest_moments,
            biggest_challenges=biggest_challenges,
            lessons_learned=lessons_learned,
            next_year_goals=next_year_goals,
        )
