"""Metric calculation logic for GitHub feedback analysis."""

from __future__ import annotations

from dataclasses import dataclass
from datetime import datetime
from typing import Dict, List, Optional

from .console import Console
from .models import (
    AnalysisStatus,
    CollectionResult,
    MetricSnapshot,
    DetailedFeedbackSnapshot,
    CommitMessageFeedback,
    PRTitleFeedback,
    ReviewToneFeedback,
    IssueFeedback,
)

console = Console()


# Award tier configurations
AWARD_TIERS = {
    "commits": [
        (1000, "üíé ÏΩîÎìú Ï†ÑÏÑ§ ÏÉÅ (Îã§Ïù¥ÏïÑÎ™¨Îìú) ‚Äî 1000Ìöå Ïù¥ÏÉÅÏùò Ïª§Î∞ãÏúºÎ°ú Ï†ÄÏû•ÏÜåÏùò ÏÇ¥ÏïÑÏûàÎäî Ïó≠ÏÇ¨Î•º ÏçºÏäµÎãàÎã§."),
        (500, "üèÜ ÏΩîÎìú ÎßàÏä§ÌÑ∞ ÏÉÅ (ÌîåÎûòÌã∞ÎÑò) ‚Äî 500Ìöå Ïù¥ÏÉÅÏùò Ïª§Î∞ãÏúºÎ°ú ÏΩîÎìúÎ≤†Ïù¥Ïä§Ïùò Ï§ëÏ∂îÎ•º ÏôÑÏÑ±ÌñàÏäµÎãàÎã§."),
        (200, "ü•á ÏΩîÎìú ÎåÄÏû•Ïû•Ïù¥ ÏÉÅ (Í≥®Îìú) ‚Äî 200Ìöå Ïù¥ÏÉÅÏùò Ïª§Î∞ãÏúºÎ°ú Ï†ÄÏû•ÏÜåÏùò ÌïµÏã¨ÏùÑ Îã®Îã®ÌïòÍ≤å Îã§Ï°åÏäµÎãàÎã§."),
        (100, "ü•à ÏΩîÎìú Ïû•Ïù∏ ÏÉÅ (Ïã§Î≤Ñ) ‚Äî 100Ìöå Ïù¥ÏÉÅÏùò Ïª§Î∞ãÏúºÎ°ú Íæ∏Ï§ÄÌïú Í∞úÏÑ†ÏùÑ Ïù¥Ïñ¥Í∞îÏäµÎãàÎã§."),
        (50, "ü•â ÏΩîÎìú Í≤¨ÏäµÏÉù ÏÉÅ (Î∏åÎ°†Ï¶à) ‚Äî 50Ìöå Ïù¥ÏÉÅÏùò Ïª§Î∞ãÏúºÎ°ú ÏÑ±Ïû•Ïùò Î∞úÌåêÏùÑ ÎßàÎ†®ÌñàÏäµÎãàÎã§."),
    ],
    "pull_requests": [
        (200, "üíé Î¶¥Î¶¨Ïä§ Ï†ÑÏÑ§ ÏÉÅ (Îã§Ïù¥ÏïÑÎ™¨Îìú) ‚Äî 200Í±¥ Ïù¥ÏÉÅÏùò Pull RequestÎ°ú Î∞∞Ìè¨Ïùò ÏÉà Ïó≠ÏÇ¨Î•º Ïó¥ÏóàÏäµÎãàÎã§."),
        (100, "üèÜ Î∞∞Ìè¨ Ï†úÎèÖ ÏÉÅ (ÌîåÎûòÌã∞ÎÑò) ‚Äî 100Í±¥ Ïù¥ÏÉÅÏùò Pull RequestÎ°ú Î¶¥Î¶¨Ïä§ Ìï®ÎåÄÎ•º ÏßÄÌúòÌñàÏäµÎãàÎã§."),
        (50, "ü•á Î¶¥Î¶¨Ïä§ ÏÑ†Ïû• ÏÉÅ (Í≥®Îìú) ‚Äî 50Í±¥ Ïù¥ÏÉÅÏùò Pull RequestÎ°ú Ï∂úÏãú ÌùêÎ¶ÑÏùÑ Ïù¥ÎÅåÏóàÏäµÎãàÎã§."),
        (25, "ü•à Î¶¥Î¶¨Ïä§ Ìï≠Ìï¥ÏÇ¨ ÏÉÅ (Ïã§Î≤Ñ) ‚Äî 25Í±¥ Ïù¥ÏÉÅÏùò Pull RequestÎ°ú ÌòëÏóÖ Î¶¥Î¶¨Ïä§Î•º Ï£ºÎèÑÌñàÏäµÎãàÎã§."),
        (10, "ü•â Î∞∞Ìè¨ ÏÑ†Ïõê ÏÉÅ (Î∏åÎ°†Ï¶à) ‚Äî 10Í±¥ Ïù¥ÏÉÅÏùò Pull RequestÎ°ú ÌåÄ Î∞∞Ìè¨Ïóê Í∏∞Ïó¨ÌñàÏäµÎãàÎã§."),
    ],
    "reviews": [
        (200, "üíé ÏßÄÏãù Ï†ÑÌååÏûê ÏÉÅ (Îã§Ïù¥ÏïÑÎ™¨Îìú) ‚Äî 200Ìöå Ïù¥ÏÉÅÏùò Î¶¨Î∑∞Î°ú ÌåÄ Ï†ÑÏ≤¥Ïùò ÏÑ±Ïû•ÏùÑ Ïù¥ÎÅåÏóàÏäµÎãàÎã§."),
        (100, "üèÜ Î©òÌÜ†ÎßÅ ÎåÄÍ∞Ä ÏÉÅ (ÌîåÎûòÌã∞ÎÑò) ‚Äî 100Ìöå Ïù¥ÏÉÅÏùò Î¶¨Î∑∞Î°ú ÏßÄÏãù Í≥µÏú† Î¨∏ÌôîÎ•º Ï†ïÏ∞©ÏãúÏº∞ÏäµÎãàÎã§."),
        (50, "ü•á Î¶¨Î∑∞ Ï†ÑÎ¨∏Í∞Ä ÏÉÅ (Í≥®Îìú) ‚Äî 50Ìöå Ïù¥ÏÉÅÏùò Î¶¨Î∑∞Î°ú ÏΩîÎìú ÌíàÏßàÏùÑ Ìïú Îã®Í≥Ñ ÎÅåÏñ¥Ïò¨Î†∏ÏäµÎãàÎã§."),
        (20, "ü•à ÏÑ±Ïû• Î©òÌÜ† ÏÉÅ (Ïã§Î≤Ñ) ‚Äî 20Ìöå Ïù¥ÏÉÅÏùò Î¶¨Î∑∞Î°ú ÌåÄÏùò ÏÑ±Ïû•ÏùÑ Îí∑Î∞õÏπ®ÌñàÏäµÎãàÎã§."),
        (10, "ü•â ÏΩîÎìú ÏßÄÏõêÏûê ÏÉÅ (Î∏åÎ°†Ï¶à) ‚Äî 10Ìöå Ïù¥ÏÉÅÏùò Î¶¨Î∑∞Î°ú ÎèôÎ£åÎ•º ÎèÑÏôîÏäµÎãàÎã§."),
    ],
    "issues": [
        (50, "üîß Î¨∏Ï†ú Ìï¥Í≤∞ÏÇ¨ ÏÉÅ ‚Äî 50Í±¥ Ïù¥ÏÉÅÏùò Ïù¥ÏäàÎ•º Îã§Î£®Î©∞ Ï†ÄÏû•ÏÜå ÌíàÏßàÏùÑ Í∞úÏÑ†ÌñàÏäµÎãàÎã§."),
        (20, "üõ†Ô∏è Î≤ÑÍ∑∏ ÌóåÌÑ∞ ÏÉÅ ‚Äî 20Í±¥ Ïù¥ÏÉÅÏùò Ïù¥ÏäàÎ•º Ï≤òÎ¶¨ÌïòÎ©∞ ÏïàÏ†ïÏÑ± ÌôïÎ≥¥Ïóê Í∏∞Ïó¨ÌñàÏäµÎãàÎã§."),
    ],
    "velocity": [
        (50, "‚ö° Î≤àÍ∞ú Í∞úÎ∞úÏûê ÏÉÅ ‚Äî Ïõî ÌèâÍ∑† 50Ìöå Ïù¥ÏÉÅÏùò Ïª§Î∞ãÏúºÎ°ú ÎÜÄÎùºÏö¥ ÏÜçÎèÑÎ•º Î≥¥Ïó¨Ï§¨ÏäµÎãàÎã§."),
        (20, "üöÄ ÏÜçÎèÑÏôï ÏÉÅ ‚Äî Ïõî ÌèâÍ∑† 20Ìöå Ïù¥ÏÉÅÏùò Ïª§Î∞ãÏúºÎ°ú Îπ†Î•∏ Í∞úÎ∞ú ÌÖúÌè¨Î•º Ïú†ÏßÄÌñàÏäµÎãàÎã§."),
    ],
    "collaboration": [
        (20, "ü§ù ÌòëÏóÖ ÎßàÏä§ÌÑ∞ ÏÉÅ ‚Äî Ïõî ÌèâÍ∑† 20Ìöå Ïù¥ÏÉÅÏùò PRÍ≥º Î¶¨Î∑∞Î°ú ÌåÄÏõåÌÅ¨Ïùò Ï§ëÏã¨Ïù¥ ÎêòÏóàÏäµÎãàÎã§."),
        (10, "üë• ÌòëÏóÖ Ï†ÑÎ¨∏Í∞Ä ÏÉÅ ‚Äî Ïõî ÌèâÍ∑† 10Ìöå Ïù¥ÏÉÅÏùò PRÍ≥º Î¶¨Î∑∞Î°ú ÌåÄ ÏãúÎÑàÏßÄÎ•º Í∞ïÌôîÌñàÏäµÎãàÎã§."),
    ],
    "activity_consistency": [
        ((30, 6), "üìÖ Íæ∏Ï§ÄÌï®Ïùò Îã¨Ïù∏ ÏÉÅ ‚Äî 6Í∞úÏõî Ïù¥ÏÉÅ Ïõî ÌèâÍ∑† 30Ìöå Ïù¥ÏÉÅÏùò ÌôúÎèôÏúºÎ°ú ÏùºÍ¥ÄÏÑ±ÏùÑ ÏûÖÏ¶ùÌñàÏäµÎãàÎã§."),
        ((15, 3), "üîÑ ÏßÄÏÜçÏÑ± ÏÉÅ ‚Äî Íæ∏Ï§ÄÌïú ÏõîÎ≥Ñ ÌôúÎèôÏúºÎ°ú ÏÑ±Ïã§Ìï®ÏùÑ Î≥¥Ïó¨Ï§¨ÏäµÎãàÎã§."),
    ],
    "change_scale": [
        (5000, "üèóÔ∏è ÎåÄÍ∑úÎ™® ÏïÑÌÇ§ÌÖçÌä∏ ÏÉÅ ‚Äî 5000Ï§Ñ Ïù¥ÏÉÅÏùò Î≥ÄÍ≤ΩÏúºÎ°ú ÎåÄÎã¥Ìïú Î¶¨Ìå©ÌÑ∞ÎßÅÏùÑ ÏôÑÏàòÌñàÏäµÎãàÎã§."),
        (2000, "üî® ÎåÄÌòï ÎπåÎçî ÏÉÅ ‚Äî 2000Ï§Ñ Ïù¥ÏÉÅÏùò Î≥ÄÍ≤ΩÏúºÎ°ú ÌÅ∞ Í∑úÎ™®Ïùò Í∞úÏÑ†ÏùÑ Ïù¥Î§ÑÎÉàÏäµÎãàÎã§."),
    ],
}


@dataclass(slots=True)
class Analyzer:
    """Transform collected data into actionable metrics."""

    web_base_url: str = "https://github.com"

    def compute_metrics(
        self,
        collection: CollectionResult,
        detailed_feedback: Optional[DetailedFeedbackSnapshot] = None,
    ) -> MetricSnapshot:
        """Compute derived metrics from the collected artefacts."""

        console.log("Analyzing repository trends", f"repo={collection.repo}")

        (
            month_span,
            velocity_score,
            collaboration_score,
            stability_score,
            total_activity,
            period_label,
        ) = self._calculate_scores(collection)

        highlights = self._build_highlights(
            collection,
            period_label,
            month_span,
            velocity_score,
            total_activity,
        )
        spotlight_examples = self._build_spotlight_examples(collection)
        summary = self._build_summary(
            period_label,
            total_activity,
            velocity_score,
            collaboration_score,
            stability_score,
        )
        story_beats = self._build_story_beats(collection, period_label, total_activity)
        awards = self._determine_awards(collection)
        stats = self._build_stats(collection, velocity_score)
        evidence = self._build_evidence(collection)

        return MetricSnapshot(
            repo=collection.repo,
            months=collection.months,
            generated_at=datetime.utcnow(),
            status=AnalysisStatus.ANALYSED,
            summary=summary,
            stats=stats,
            evidence=evidence,
            highlights=highlights,
            spotlight_examples=spotlight_examples,
            yearbook_story=story_beats,
            awards=awards,
            detailed_feedback=detailed_feedback,
        )

    def _calculate_scores(
        self, collection: CollectionResult
    ) -> tuple[int, float, float, int, int, str]:
        month_span = max(collection.months, 1)
        velocity_score = collection.commits / month_span
        collaboration_score = (collection.pull_requests + collection.reviews) / month_span
        stability_score = max(collection.commits - collection.issues, 0)
        total_activity = collection.commits + collection.pull_requests + collection.reviews
        period_label = "Ïò¨Ìï¥" if collection.months >= 12 else f"ÏßÄÎÇú {collection.months}Í∞úÏõî"

        return (
            month_span,
            velocity_score,
            collaboration_score,
            stability_score,
            total_activity,
            period_label,
        )

    def _build_highlights(
        self,
        collection: CollectionResult,
        period_label: str,
        month_span: int,
        velocity_score: float,
        total_activity: int,
    ) -> List[str]:
        highlights: List[str] = []
        if collection.commits:
            highlights.append(
                f"{period_label}Ïóê Ï¥ù {collection.commits}ÌöåÏùò Ïª§Î∞ãÏúºÎ°ú ÏΩîÎìúÎ•º Îã§Îì¨Í≥† Ïõî ÌèâÍ∑† {velocity_score:.1f}ÌöåÏùò Í∞úÏÑ†ÏùÑ Ïù¥Ïñ¥Í∞îÏäµÎãàÎã§."
            )
        if collection.pull_requests:
            highlights.append(
                f"{collection.pull_requests}Í±¥Ïùò Pull RequestÎ•º Î≥ëÌï©ÌïòÎ©∞ ÌåÄ Î∞∞Ìè¨ Ï£ºÍ∏∞Î•º ÏïàÏ†ïÌôîÌñàÍ≥† Ïõî {collection.pull_requests / month_span:.1f}Í±¥Ïùò Î¶¥Î¶¨Ïä§Î•º Ïú†ÏßÄÌñàÏäµÎãàÎã§."
            )
        if collection.reviews:
            highlights.append(
                f"{collection.reviews}ÌöåÏùò ÏΩîÎìú Î¶¨Î∑∞Î•º ÌÜµÌï¥ ÌòëÏóÖ Î¨∏ÌôîÎ•º Í∞ïÌôîÌñàÏäµÎãàÎã§."
            )
        if collection.issues:
            highlights.append(
                f"ÌôúÎèô ÎåÄÎπÑ {collection.issues}Í±¥Ïùò Ïù¥ÏäàÎ°ú ÏïàÏ†ïÏÑ±ÏùÑ ÏßÄÏº∞ÏäµÎãàÎã§."
            )
        if not highlights and total_activity == 0:
            highlights.append("Î∂ÑÏÑù Í∏∞Í∞Ñ ÎèôÏïà ÎöúÎ†∑Ìïú ÌôúÎèôÏù¥ Í∞êÏßÄÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.")

        return highlights

    def _build_spotlight_examples(self, collection: CollectionResult) -> Dict[str, List[str]]:
        spotlight_examples: Dict[str, List[str]] = {}
        if not collection.pull_request_examples:
            return spotlight_examples

        pr_lines = []
        for pr in collection.pull_request_examples[:3]:
            change_volume = pr.additions + pr.deletions
            scale_phrase = f"Î≥ÄÍ≤Ω {change_volume}Ï§Ñ" if change_volume else "Í≤ΩÎüâ Î≥ÄÍ≤Ω"
            merged_phrase = (
                f"{pr.merged_at.date().isoformat()} Î≥ëÌï©"
                if pr.merged_at
                else "ÎØ∏Î≥ëÌï©"
            )
            pr_lines.append(
                f"PR #{pr.number} ¬∑ {pr.title} ‚Äî {pr.author} ({pr.created_at.date().isoformat()}, {merged_phrase}, {scale_phrase}) ¬∑ {pr.html_url}"
            )
        spotlight_examples["pull_requests"] = pr_lines
        return spotlight_examples

    def _build_summary(
        self,
        period_label: str,
        total_activity: int,
        velocity_score: float,
        collaboration_score: float,
        stability_score: int,
    ) -> Dict[str, str]:
        return {
            "velocity": f"Average {velocity_score:.1f} commits per month",
            "collaboration": "{:.1f} combined PRs and reviews per month".format(collaboration_score),
            "stability": f"Net stability score of {stability_score}",
            "growth": f"{period_label} ÎèôÏïà {total_activity}Í±¥Ïùò ÌôúÎèôÏùÑ Í∏∞Î°ùÌñàÏäµÎãàÎã§.",
        }

    def _build_story_beats(
        self,
        collection: CollectionResult,
        period_label: str,
        total_activity: int,
    ) -> List[str]:
        story_beats: List[str] = []
        if total_activity:
            story_beats.append(
                f"{period_label} ÎèôÏïà {collection.repo} Ï†ÄÏû•ÏÜåÏóêÏÑú Ï¥ù {total_activity}Í±¥Ïùò ÌôúÎèôÏùÑ ÌéºÏπòÎ©∞ ÏÑ±Ïû• ÏóîÏßÑÏùÑ Í∞ÄÎèôÌñàÏäµÎãàÎã§."
            )
        else:
            story_beats.append(
                f"{period_label}ÏóêÎäî Ïû†Ïãú Ïà®ÏùÑ Í≥†Î•¥Î©∞ Îã§Ïùå ÎèÑÏïΩÏùÑ Ï§ÄÎπÑÌñàÏäµÎãàÎã§."
            )

        contribution_domains = [
            ("Ïª§Î∞ã", collection.commits, "ÏßÄÏÜçÏ†ÅÏù∏ Î¶¨Ìå©ÌÑ∞ÎßÅÍ≥º Í∏∞Îä• ÌôïÏû•ÏùÑ Ïù¥ÎÅåÏóàÏäµÎãàÎã§."),
            ("Pull Request", collection.pull_requests, "ÌòëÏóÖ Î¶¥Î¶¨Ïä§Î•º Ï£ºÎèÑÌïòÎ©∞ Î∞∞Ìè¨ ÌååÏù¥ÌîÑÎùºÏù∏ÏùÑ ÏßÄÏº∞ÏäµÎãàÎã§."),
            ("Î¶¨Î∑∞", collection.reviews, "ÌåÄ ÎèôÎ£åÎì§Ïùò ÏÑ±Ïû•ÏùÑ ÎèïÎäî Ï¥òÏ¥òÌïú ÌîºÎìúÎ∞±ÏùÑ Ï†ÑÎã¨ÌñàÏäµÎãàÎã§."),
        ]
        top_domain = max(contribution_domains, key=lambda entry: entry[1])
        if top_domain[1]:
            story_beats.append(
                f"Í∞ÄÏû• ÎààÏóê Îùà ÏòÅÏó≠ÏùÄ {top_domain[0]} {top_domain[1]}ÌöåÎ°ú, {top_domain[2]}"
            )

        if collection.pull_request_examples:
            exemplar = collection.pull_request_examples[0]
            merge_phrase = (
                f"{exemplar.merged_at.date().isoformat()} Î≥ëÌï©"
                if exemplar.merged_at
                else "ÏïÑÏßÅ ÏßÑÌñâ Ï§ë"
            )
            scale = exemplar.additions + exemplar.deletions
            scale_phrase = f"Î≥ÄÍ≤Ω {scale}Ï§Ñ" if scale else "Í≤ΩÎüâ Î≥ÄÍ≤Ω"
            story_beats.append(
                "ÎåÄÌëúÏûëÏúºÎ°úÎäî PR #{num} `{title}`({author})Í∞Ä ÏûàÏäµÎãàÎã§ ‚Äî {created} ÏûëÏÑ±, {merge} ¬∑ {scale_phrase}.".format(
                    num=exemplar.number,
                    title=exemplar.title,
                    author=exemplar.author,
                    created=exemplar.created_at.date().isoformat(),
                    merge=merge_phrase,
                    scale_phrase=scale_phrase,
                )
            )

        return story_beats

    def _determine_awards(self, collection: CollectionResult) -> List[str]:
        """Determine awards based on collection metrics using data-driven tier system."""
        awards: List[str] = []
        month_span = max(collection.months, 1)

        # Apply tier-based awards
        self._add_tier_award(awards, "commits", collection.commits)
        self._add_tier_award(awards, "pull_requests", collection.pull_requests)
        self._add_tier_award(awards, "reviews", collection.reviews)
        self._add_tier_award(awards, "issues", collection.issues)

        # Velocity-based awards
        velocity_score = collection.commits / month_span
        self._add_tier_award(awards, "velocity", velocity_score)

        # Collaboration-based awards
        collaboration_score = (collection.pull_requests + collection.reviews) / month_span
        self._add_tier_award(awards, "collaboration", collaboration_score)

        # Activity consistency awards
        total_activity = collection.commits + collection.pull_requests + collection.reviews
        activity_per_month = total_activity / month_span
        for (threshold_activity, threshold_months), award_text in AWARD_TIERS["activity_consistency"]:
            if activity_per_month >= threshold_activity and collection.months >= threshold_months:
                awards.append(award_text)
                break

        # All-rounder award
        if (collection.commits >= 50 and
            collection.pull_requests >= 15 and
            collection.reviews >= 15):
            awards.append(
                "üåü Îã§Ïû¨Îã§Îä• ÏÉÅ ‚Äî Ïª§Î∞ã, PR, Î¶¨Î∑∞ Ï†Ñ ÏòÅÏó≠ÏóêÏÑú Í∑†ÌòïÏû°Ìûå Í∏∞Ïó¨Î•º Î≥¥Ïó¨Ï§¨ÏäµÎãàÎã§."
            )

        # Large-scale change awards
        if collection.pull_request_examples:
            max_change = max(
                (pr.additions + pr.deletions for pr in collection.pull_request_examples),
                default=0
            )
            self._add_tier_award(awards, "change_scale", max_change)

        # Stability award
        if collection.issues and collection.issues <= max(collection.commits // 6, 1):
            awards.append(
                "üõ°Ô∏è ÏïàÏ†ï ÏßÄÌÇ¥Ïù¥ ÏÉÅ ‚Äî ÌôúÎèô ÎåÄÎπÑ Ï†ÅÏùÄ Ïù¥ÏäàÎ°ú ÏïàÏ†ïÏÑ±ÏùÑ ÏßÄÏº∞ÏäµÎãàÎã§."
            )

        # Default award if no other awards
        if not awards:
            awards.append(
                "üå± ÏÑ±Ïû• Ïî®Ïïó ÏÉÅ ‚Äî ÏûëÏùÄ Î∞úÍ±∏ÏùåÎì§Ïù¥ Î™®Ïó¨ ÎÇ¥ÏùºÏùò ÌÅ∞ ÏÑ±Ïû•ÏùÑ Ï§ÄÎπÑÌïòÍ≥† ÏûàÏäµÎãàÎã§."
            )

        return awards

    @staticmethod
    def _add_tier_award(awards: List[str], category: str, value: float) -> None:
        """Add tier-based award if value meets threshold.

        Args:
            awards: List to append awards to
            category: Award category key from AWARD_TIERS
            value: Metric value to check against thresholds
        """
        if category not in AWARD_TIERS:
            return

        for threshold, award_text in AWARD_TIERS[category]:
            if value >= threshold:
                awards.append(award_text)
                break

    def _build_stats(self, collection: CollectionResult, velocity_score: float) -> Dict[str, Dict[str, float]]:
        return {
            "commits": {
                "total": float(collection.commits),
                "per_month": velocity_score,
            },
            "pull_requests": {
                "total": float(collection.pull_requests),
            },
            "reviews": {
                "total": float(collection.reviews),
            },
            "issues": {
                "total": float(collection.issues),
            },
        }

    def _build_evidence(self, collection: CollectionResult) -> Dict[str, List[str]]:
        repo_root = f"{self.web_base_url.rstrip('/')}/{collection.repo}"
        return {
            "commits": [
                f"{repo_root}/commits",
            ],
            "pull_requests": [
                f"{repo_root}/pulls",
            ],
        }

    def build_detailed_feedback(
        self,
        commit_analysis: Optional[Dict] = None,
        pr_title_analysis: Optional[Dict] = None,
        review_tone_analysis: Optional[Dict] = None,
        issue_analysis: Optional[Dict] = None,
    ) -> DetailedFeedbackSnapshot:
        """Build detailed feedback snapshot from LLM analysis results."""

        commit_feedback = None
        if commit_analysis:
            commit_feedback = CommitMessageFeedback(
                total_commits=commit_analysis.get("good_messages", 0)
                + commit_analysis.get("poor_messages", 0),
                good_messages=commit_analysis.get("good_messages", 0),
                poor_messages=commit_analysis.get("poor_messages", 0),
                suggestions=commit_analysis.get("suggestions", []),
                examples_good=commit_analysis.get("examples_good", []),
                examples_poor=commit_analysis.get("examples_poor", []),
            )

        pr_title_feedback = None
        if pr_title_analysis:
            pr_title_feedback = PRTitleFeedback(
                total_prs=pr_title_analysis.get("clear_titles", 0)
                + pr_title_analysis.get("vague_titles", 0),
                clear_titles=pr_title_analysis.get("clear_titles", 0),
                vague_titles=pr_title_analysis.get("vague_titles", 0),
                suggestions=pr_title_analysis.get("suggestions", []),
                examples_good=pr_title_analysis.get("examples_good", []),
                examples_poor=pr_title_analysis.get("examples_poor", []),
            )

        review_tone_feedback = None
        if review_tone_analysis:
            review_tone_feedback = ReviewToneFeedback(
                total_reviews=review_tone_analysis.get("constructive_reviews", 0)
                + review_tone_analysis.get("harsh_reviews", 0)
                + review_tone_analysis.get("neutral_reviews", 0),
                constructive_reviews=review_tone_analysis.get("constructive_reviews", 0),
                harsh_reviews=review_tone_analysis.get("harsh_reviews", 0),
                neutral_reviews=review_tone_analysis.get("neutral_reviews", 0),
                suggestions=review_tone_analysis.get("suggestions", []),
                examples_good=review_tone_analysis.get("examples_good", []),
                examples_improve=review_tone_analysis.get("examples_improve", []),
            )

        issue_feedback = None
        if issue_analysis:
            issue_feedback = IssueFeedback(
                total_issues=issue_analysis.get("well_described", 0)
                + issue_analysis.get("poorly_described", 0),
                well_described=issue_analysis.get("well_described", 0),
                poorly_described=issue_analysis.get("poorly_described", 0),
                suggestions=issue_analysis.get("suggestions", []),
                examples_good=issue_analysis.get("examples_good", []),
                examples_poor=issue_analysis.get("examples_poor", []),
            )

        return DetailedFeedbackSnapshot(
            commit_feedback=commit_feedback,
            pr_title_feedback=pr_title_feedback,
            review_tone_feedback=review_tone_feedback,
            issue_feedback=issue_feedback,
        )
