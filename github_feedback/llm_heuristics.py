"""Heuristic-based analysis utilities for fallback when LLM is unavailable."""

from __future__ import annotations

import re
from typing import Any, Callable

from .constants import HEURISTIC_THRESHOLDS, TEXT_LIMITS, REGEX_PATTERNS


class HeuristicAnalyzer:
    """Base class for heuristic-based analysis with common scoring patterns."""

    @staticmethod
    def classify_by_score(
        score: int,
        threshold: int,
        examples_good: list,
        examples_poor: list,
        item: dict,
        good_reason: str,
        poor_reason: str,
        max_examples: int = 3
    ) -> tuple[bool, int, int]:
        """Classify item by score and update example lists.

        Args:
            score: Calculated score for the item
            threshold: Threshold for classification
            examples_good: List to append good examples
            examples_poor: List to append poor examples
            item: Item to classify
            good_reason: Reason for good classification
            poor_reason: Reason for poor classification
            max_examples: Maximum examples to collect

        Returns:
            Tuple of (is_good, good_count_delta, poor_count_delta)
        """
        is_good = score >= threshold

        if is_good:
            if len(examples_good) < max_examples:
                examples_good.append({**item, "reason": good_reason})
            return True, 1, 0
        else:
            if len(examples_poor) < max_examples:
                examples_poor.append({**item, "reason": poor_reason})
            return False, 0, 1

    @staticmethod
    def check_length_score(text: str, min_len: int, max_len: int) -> tuple[int, list[str]]:
        """Check text length and return score and issues.

        Args:
            text: Text to check
            min_len: Minimum acceptable length
            max_len: Maximum acceptable length

        Returns:
            Tuple of (score, issues_list)
        """
        issues = []
        length = len(text)

        if min_len <= length <= max_len:
            return 1, issues

        if length < min_len:
            issues.append("í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤")
        else:
            issues.append("í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤")

        return 0, issues

    @staticmethod
    def check_patterns(text: str, patterns: list[str], flags: int = 0) -> bool:
        """Check if text matches any of the given regex patterns.

        Args:
            text: Text to check
            patterns: List of regex patterns
            flags: Regex flags (e.g., re.IGNORECASE)

        Returns:
            True if any pattern matches, False otherwise
        """
        return any(re.match(pattern, text, flags) for pattern in patterns)

    @staticmethod
    def search_patterns(text: str, patterns: list[str], flags: int = 0) -> bool:
        """Check if text contains any of the given regex patterns.

        Args:
            text: Text to check
            patterns: List of regex patterns
            flags: Regex flags (e.g., re.IGNORECASE)

        Returns:
            True if any pattern is found, False otherwise
        """
        return any(re.search(pattern, text, flags) for pattern in patterns)

    @staticmethod
    def analyze_with_scoring(
        items: list[dict],
        score_fn: Callable[[dict], tuple[int, Any]],
        threshold: int,
        good_example_fn: Callable[[dict, Any], dict],
        poor_example_fn: Callable[[dict, Any], dict],
        max_examples: int = 3
    ) -> tuple[int, int, list[dict], list[dict]]:
        """Generic analysis using a scoring function.

        Args:
            items: List of items to analyze
            score_fn: Function that scores an item and returns (score, metadata)
            threshold: Score threshold for good classification
            good_example_fn: Function to format good examples
            poor_example_fn: Function to format poor examples
            max_examples: Maximum examples to collect

        Returns:
            Tuple of (good_count, poor_count, examples_good, examples_poor)
        """
        good_count = 0
        poor_count = 0
        examples_good = []
        examples_poor = []

        for item in items:
            score, metadata = score_fn(item)

            if score >= threshold:
                good_count += 1
                if len(examples_good) < max_examples:
                    examples_good.append(good_example_fn(item, metadata))
            else:
                poor_count += 1
                if len(examples_poor) < max_examples:
                    examples_poor.append(poor_example_fn(item, metadata))

        return good_count, poor_count, examples_good, examples_poor


class CommitMessageAnalyzer:
    """Heuristic analyzer for commit messages."""

    @staticmethod
    def score_commit_message(
        first_line: str,
        lines: list[str],
        good_patterns: list[str],
        poor_patterns: list[str],
        min_len: int,
        max_len: int,
        too_long: int,
        min_body_len: int
    ) -> tuple[int, list[str]]:
        """Score a commit message and return score with issues list.

        Args:
            first_line: First line of commit message
            lines: All lines of commit message
            good_patterns: Regex patterns for good messages
            poor_patterns: Regex patterns for poor messages
            min_len: Minimum length threshold
            max_len: Maximum length threshold
            too_long: Too long threshold
            min_body_len: Minimum body length

        Returns:
            Tuple of (score, issues_list)
        """
        score = 0
        issues = []

        # Check length
        if min_len <= len(first_line) <= max_len:
            score += 1
        elif len(first_line) < min_len:
            issues.append("ë©”ì‹œì§€ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤")
        elif len(first_line) > too_long:
            issues.append("ì²« ì¤„ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤")

        # Check for good patterns
        if HeuristicAnalyzer.check_patterns(first_line, good_patterns, re.IGNORECASE):
            score += 2

        # Check for poor patterns
        if HeuristicAnalyzer.check_patterns(first_line.lower(), poor_patterns):
            score -= 2
            issues.append("ëª¨í˜¸í•˜ê±°ë‚˜ ì„ì‹œ ë©”ì‹œì§€ì…ë‹ˆë‹¤")

        # Check for body
        if len(lines) > 2 and len(lines[2].strip()) > min_body_len:
            score += 1

        return score, issues

    @staticmethod
    def analyze(commits: list[dict[str, str]]) -> dict[str, Any]:
        """Enhanced heuristic-based commit message analysis.

        Args:
            commits: List of commit dictionaries with 'sha' and 'message' keys

        Returns:
            Analysis results dictionary
        """
        # Patterns for classification
        good_patterns = [
            r'^(feat|fix|docs|style|refactor|test|chore|perf|ci|build|revert)(\(.+\))?: .+',
            r'^(Add|Fix|Update|Refactor|Remove|Implement|Improve|Optimize) [A-Z].+',
            r'^[A-Z][a-z]+ .+ (#\d+|issue|pr)',
        ]
        poor_patterns = [
            r'^(wip|tmp|test|debug|asdf|aaa|zzz)',
            r'^fix$|^update$|^bug$',
            r'^.{1,5}$',
            r'^.{150,}',
        ]

        # Thresholds
        min_len = HEURISTIC_THRESHOLDS['commit_min_length']
        max_len = HEURISTIC_THRESHOLDS['commit_max_length']
        too_long = HEURISTIC_THRESHOLDS['commit_too_long']
        min_body_len = HEURISTIC_THRESHOLDS['commit_min_body_length']
        good_score_threshold = HEURISTIC_THRESHOLDS['review_good_score']

        # Define scoring function
        def score_fn(commit):
            message = commit["message"].strip()
            lines = message.split("\n")
            first_line = lines[0] if lines else ""
            score, issues = CommitMessageAnalyzer.score_commit_message(
                first_line, lines, good_patterns, poor_patterns,
                min_len, max_len, too_long, min_body_len
            )
            return score, (first_line, issues)

        # Define example formatters
        def good_example_fn(commit, metadata):
            first_line, _ = metadata
            reasons = []
            reasons.append(f"ì ì ˆí•œ ê¸¸ì´({len(first_line)}ì)ë¡œ ê°€ë…ì„±ì´ ì¢‹ìŠµë‹ˆë‹¤.")
            if REGEX_PATTERNS['conventional_commit'].match(first_line):
                reasons.append("Conventional Commits í˜•ì‹ì„ ë”°ë¼ íƒ€ì…ì´ ëª…í™•í•©ë‹ˆë‹¤.")
            if REGEX_PATTERNS['imperative_commit'].match(first_line):
                reasons.append("ëª…ë ¹í˜• ë™ì‚¬ë¡œ ì‹œì‘í•˜ì—¬ ì¼ê´€ëœ ìŠ¤íƒ€ì¼ì„ ìœ ì§€í•©ë‹ˆë‹¤.")
            if '#' in first_line or 'issue' in first_line.lower() or 'pr' in first_line.lower():
                reasons.append("Issue/PR ì°¸ì¡°ë¥¼ í¬í•¨í•˜ì—¬ ë§¥ë½ì„ ì œê³µí•©ë‹ˆë‹¤.")

            reason = " ".join(reasons) if reasons else "ì ì ˆí•œ í˜•ì‹ì˜ ì»¤ë°‹ ë©”ì‹œì§€ì…ë‹ˆë‹¤."

            return {
                "message": first_line,
                "sha": commit["sha"],
                "reason": reason
            }

        def poor_example_fn(commit, metadata):
            first_line, issues = metadata
            reason_parts = []
            if "ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤" in ", ".join(issues):
                reason_parts.append(f"ë©”ì‹œì§€ê°€ ë„ˆë¬´ ì§§ì•„({len(first_line)}ì) ë³€ê²½ ë‚´ìš©ì„ ì¶©ë¶„íˆ ì„¤ëª…í•˜ì§€ ëª»í•©ë‹ˆë‹¤.")
            if "ë„ˆë¬´ ê¹ë‹ˆë‹¤" in ", ".join(issues):
                reason_parts.append(f"ì²« ì¤„ì´ ë„ˆë¬´ ê¸¸ì–´({len(first_line)}ì) ê°€ë…ì„±ì´ ë–¨ì–´ì§‘ë‹ˆë‹¤. 50-72ì ì´ë‚´ë¡œ ì‘ì„±í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.")
            if "ëª¨í˜¸í•˜ê±°ë‚˜ ì„ì‹œ ë©”ì‹œì§€ì…ë‹ˆë‹¤" in ", ".join(issues):
                reason_parts.append("'wip', 'fix', 'tmp' ê°™ì€ ëª¨í˜¸í•œ ë‹¨ì–´ë§Œ ì‚¬ìš©í•˜ì—¬ ë³€ê²½ ì˜ë„ë¥¼ ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            if not reason_parts and issues:
                reason_parts.append(", ".join(issues))

            reason = " ".join(reason_parts) if reason_parts else "ì»¤ë°‹ ë©”ì‹œì§€ ì‘ì„± ê·œì¹™ì„ ë”°ë¥´ì§€ ì•Šì•„ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤."

            suggestions = []
            if len(first_line) < min_len:
                suggestions.append(f"ë©”ì‹œì§€ë¥¼ ë” êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš” (ì˜ˆ: 'feat: ì‚¬ìš©ì ì¸ì¦ ê¸°ëŠ¥ ì¶”ê°€')")
            elif len(first_line) > max_len:
                suggestions.append("ì²« ì¤„ì„ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ê³ , ìì„¸í•œ ë‚´ìš©ì€ ë³¸ë¬¸ì— ì‘ì„±í•˜ì„¸ìš”")
            else:
                suggestions.append("Conventional Commits í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš” (ì˜ˆ: feat(auth): ë¡œê·¸ì¸ ê¸°ëŠ¥ êµ¬í˜„)")

            return {
                "message": first_line,
                "sha": commit["sha"],
                "reason": reason,
                "suggestion": " ".join(suggestions)
            }

        # Use generic analyzer
        good_count, poor_count, examples_good, examples_poor = HeuristicAnalyzer.analyze_with_scoring(
            commits, score_fn, good_score_threshold, good_example_fn, poor_example_fn,
            max_examples=TEXT_LIMITS['example_display_limit']
        )

        return {
            "good_messages": good_count,
            "poor_messages": poor_count,
            "suggestions": [
                "ì»¤ë°‹ ë©”ì‹œì§€ì˜ ì²« ì¤„ì€ 50-72ì ì´ë‚´ë¡œ ì‘ì„±í•˜ì„¸ìš”.",
                "Conventional Commits í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”: type(scope): subject",
                "ëª…ë ¹í˜• ë™ì‚¬ë¡œ ì‹œì‘í•˜ì„¸ìš” (Add, Fix, Update, Refactor ë“±).",
                "ë³¸ë¬¸ì— ë³€ê²½ ì´ìœ ë¥¼ ìƒì„¸íˆ ì„¤ëª…í•˜ì„¸ìš” (ë¬´ì—‡ë³´ë‹¤ ì™œê°€ ì¤‘ìš”).",
                "ì´ìŠˆë‚˜ PR ë²ˆí˜¸ë¥¼ ì°¸ì¡°í•˜ì„¸ìš” (#123, closes #456 ë“±).",
            ],
            "examples_good": examples_good,
            "examples_poor": examples_poor,
        }


class PRTitleAnalyzer:
    """Heuristic analyzer for PR titles."""

    @staticmethod
    def score_pr_title(
        title: str,
        clear_patterns: list[str],
        vague_keywords: set[str],
        min_len: int,
        max_len: int,
        min_words: int
    ) -> tuple[int, list[str]]:
        """Score a PR title and return score with reasons list.

        Args:
            title: PR title to score
            clear_patterns: Regex patterns for clear titles
            vague_keywords: Set of vague keywords
            min_len: Minimum length
            max_len: Maximum length
            min_words: Minimum word count

        Returns:
            Tuple of (score, reasons_list)
        """
        score = 0
        reasons = []

        # Check length
        if min_len <= len(title) <= max_len:
            score += 1
        elif len(title) < min_len:
            reasons.append("ì œëª©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤")
        else:
            reasons.append("ì œëª©ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤")

        # Check for clear patterns
        has_clear_pattern = HeuristicAnalyzer.check_patterns(title, clear_patterns, re.IGNORECASE)
        if has_clear_pattern:
            score += 2

        # Check for vague keywords
        first_word = title.split()[0].lower() if title.split() else ""
        if first_word in vague_keywords and not has_clear_pattern:
            score -= 1
            reasons.append("ë„ˆë¬´ ì¼ë°˜ì ì¸ ë‹¨ì–´ë¡œ ì‹œì‘í•©ë‹ˆë‹¤")

        # Check for specificity
        if len(title.split()) >= min_words:
            score += 1

        return score, reasons

    @staticmethod
    def analyze(prs: list[dict[str, str]]) -> dict[str, Any]:
        """Enhanced heuristic-based PR title analysis.

        Args:
            prs: List of PR dictionaries with 'number' and 'title' keys

        Returns:
            Analysis results dictionary
        """
        # Patterns and configuration
        clear_patterns = [
            r'^\[(feat|fix|docs|style|refactor|test|chore|perf|ci|build)\].+',
            r'^(feat|fix|docs|style|refactor|test|chore|perf|ci|build):.+',
            r'^(Add|Fix|Update|Refactor|Remove|Implement|Improve) .+',
        ]
        vague_keywords = {'update', 'fix', 'change', 'modify', 'edit', 'misc', 'various', 'stuff', 'things', 'code', 'work'}

        min_len = HEURISTIC_THRESHOLDS['pr_title_min_length']
        max_len = HEURISTIC_THRESHOLDS['pr_title_max_length']
        min_words = HEURISTIC_THRESHOLDS['pr_title_min_words']
        good_score = HEURISTIC_THRESHOLDS['review_good_score']

        # Define scoring function
        def score_fn(pr):
            title = pr["title"].strip()
            score, reasons = PRTitleAnalyzer.score_pr_title(
                title, clear_patterns, vague_keywords, min_len, max_len, min_words
            )
            return score, (title, reasons)

        # Define example formatters
        def good_example_fn(pr, metadata):
            title, _ = metadata
            return {
                "number": pr["number"],
                "title": title,
                "reason": "ëª…í™•í•˜ê³  ì„¤ëª…ì ì¸ ì œëª©ì…ë‹ˆë‹¤",
                "score": min(10, score_fn(pr)[0] * 3)
            }

        def poor_example_fn(pr, metadata):
            title, reasons = metadata
            first_word = title.split()[0].lower() if title.split() else "feat"
            suggestion_type = first_word if first_word in {'feat', 'fix', 'docs'} else 'feat'
            return {
                "number": pr["number"],
                "title": title,
                "reason": ", ".join(reasons) if reasons else "ì œëª©ì´ ëª¨í˜¸í•©ë‹ˆë‹¤",
                "suggestion": f"[{suggestion_type}] {title if len(title) > 10 else title + ' - êµ¬ì²´ì ì¸ ë³€ê²½ ë‚´ìš© ì„¤ëª…'}"
            }

        # Use generic analyzer
        clear_count, vague_count, examples_good, examples_poor = HeuristicAnalyzer.analyze_with_scoring(
            prs, score_fn, good_score, good_example_fn, poor_example_fn,
            max_examples=3
        )

        return {
            "clear_titles": clear_count,
            "vague_titles": vague_count,
            "suggestions": [
                "PR ì œëª©ì€ 15-80ì ì‚¬ì´ë¡œ ì‘ì„±í•˜ì„¸ìš”.",
                "íƒ€ì…ì„ ëª…ì‹œí•˜ì„¸ìš”: [feat], [fix], [docs], [refactor] ë“±.",
                "'update', 'fix' ê°™ì€ ì¼ë°˜ì  ë‹¨ì–´ë§Œ ì‚¬ìš©í•˜ì§€ ë§ê³  êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.",
                "ëª…ë ¹í˜• ë™ì‚¬ë¡œ ì‹œì‘í•˜ì„¸ìš”: Add, Fix, Implement, Refactor ë“±.",
                "ë³€ê²½ì˜ ë²”ìœ„ì™€ ì˜í–¥ì„ ì œëª©ì— í¬í•¨í•˜ì„¸ìš”.",
            ],
            "examples_good": examples_good,
            "examples_poor": examples_poor,
        }


class ReviewToneAnalyzer:
    """Heuristic analyzer for review tone."""

    @staticmethod
    def analyze(reviews: list[dict[str, str]]) -> dict[str, Any]:
        """Enhanced heuristic-based review tone analysis.

        Args:
            reviews: List of review dictionaries with 'body' key

        Returns:
            Analysis results dictionary
        """
        # Patterns for classification
        constructive_patterns = [
            r'ì–´ë–¨ê¹Œìš”|ê³ ë ¤í•´|ì œì•ˆ|ì¶”ì²œ|ìƒê°í•´ë³´',
            r'ê°™ì•„ìš”|ê²ƒ ê°™|ë³´ì…ë‹ˆë‹¤',
            r'í•´ë³´ë©´|ì‹œë„í•´|ì‹œí—˜í•´',
            r'\?',
            r'ì¢‹ì„ ê²ƒ|ë‚˜ì„ ê²ƒ|ë” ì¢‹',
            r'ì˜ˆì‹œ|ì˜ˆë¥¼ ë“¤ì–´|ì´ë ‡ê²Œ|ë‹¤ìŒê³¼ ê°™ì´',
            r'ğŸ‘|âœ…|ğŸ’¯|ğŸ‰|ğŸ˜Š|ğŸ‘',
        ]

        harsh_patterns = [
            r'ì˜ëª»|í‹€ë ¸|ì˜¤ë¥˜|ì—ëŸ¬(?!:)|ë¬¸ì œ(?!ë¥¼ í•´ê²°)',
            r'ë‹¤ì‹œ|ë°˜ë“œì‹œ|ê¼­|ì ˆëŒ€|í•„ìˆ˜',
            r'ì™œ|ì´ìœ (?! ì—†)',
            r'(?<!ë” )ë‚˜ì¨|í˜•í¸ì—†|ìµœì•…',
            r'ì´í•´(?! ê°€ëŠ¥|í•  ìˆ˜)',
        ]

        positive_indicators = [
            r'ì¢‹|í›Œë¥­|ë©‹|ì˜|ê°ì‚¬|ê³ ë§ˆ|ìˆ˜ê³ ',
            r'ëª…í™•|ê¹”ë”|ê°„ê²°|íš¨ìœ¨|íš¨ê³¼',
            r'LGTM|looks good|nice|great|excellent',
        ]

        constructive_count = 0
        harsh_count = 0
        neutral_count = 0
        examples_good = []
        examples_improve = []

        for review in reviews:
            body = review.get("body", "").strip()
            if not body:
                continue

            # Score the review
            score = 0
            strengths = []
            issues = []

            # Check for constructive patterns
            constructive_matches = sum(1 for p in constructive_patterns if re.search(p, body, re.IGNORECASE))
            if constructive_matches > 0:
                score += constructive_matches
                if REGEX_PATTERNS['suggestion_markers'].search(body):
                    strengths.append("ì œì•ˆí˜• í‘œí˜„ì„ ì‚¬ìš©í•˜ì—¬ ì¡´ì¤‘í•˜ëŠ” í†¤ì„ ìœ ì§€í•©ë‹ˆë‹¤")
                if REGEX_PATTERNS['example_markers'].search(body):
                    strengths.append("êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ ì œê³µí•˜ì—¬ ì´í•´ë¥¼ ë•ìŠµë‹ˆë‹¤")
                if REGEX_PATTERNS['positive_emojis'].search(body):
                    strengths.append("ì´ëª¨ì§€ë¥¼ í™œìš©í•˜ì—¬ ê¸ì •ì ì¸ ë¶„ìœ„ê¸°ë¥¼ ì¡°ì„±í•©ë‹ˆë‹¤")

            # Check for harsh patterns
            harsh_matches = sum(1 for p in harsh_patterns if re.search(p, body, re.IGNORECASE))
            if harsh_matches > 0:
                score -= harsh_matches * 2
                if REGEX_PATTERNS['harsh_words'].search(body):
                    issues.append("ë¶€ì •ì ì¸ ì§ì ‘ ì§€ì ìœ¼ë¡œ ìƒëŒ€ë°©ì˜ ê°ì •ì„ ìƒí•˜ê²Œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
                if REGEX_PATTERNS['demanding_words'].search(body):
                    issues.append("ëª…ë ¹í˜• í‘œí˜„ìœ¼ë¡œ ê°•ì••ì ìœ¼ë¡œ ëŠê»´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤")

            # Check for positive indicators
            positive_matches = sum(1 for p in positive_indicators if re.search(p, body, re.IGNORECASE))
            if positive_matches > 0:
                score += positive_matches
                if REGEX_PATTERNS['positive_words'].search(body):
                    strengths.append("ê¸ì •ì ì¸ í”¼ë“œë°±ì„ í¬í•¨í•˜ì—¬ ë™ê¸°ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤")

            # Classify based on score
            if score >= 2:
                constructive_count += 1
                if len(examples_good) < 3 and strengths:
                    examples_good.append({
                        "pr_number": review.get("pr_number", ""),
                        "author": review.get("author", ""),
                        "comment": body[:150] + "..." if len(body) > 150 else body,
                        "url": review.get("url", ""),
                        "strengths": strengths[:3],
                    })
            elif score <= -2:
                harsh_count += 1
                if len(examples_improve) < 3:
                    # Create improved version
                    improved = body
                    improved = REGEX_PATTERNS['harsh_words'].sub('ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„', improved)
                    improved = re.sub(r'ë‹¤ì‹œ\s+(\w+)', r'\1í•˜ë©´ ì–´ë–¨ê¹Œìš”', improved)  # Complex pattern, keep inline
                    improved = REGEX_PATTERNS['demanding_words'].sub('~í•˜ë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤', improved)

                    examples_improve.append({
                        "pr_number": review.get("pr_number", ""),
                        "author": review.get("author", ""),
                        "comment": body[:150] + "..." if len(body) > 150 else body,
                        "url": review.get("url", ""),
                        "issues": issues[:3] if issues else ["ë” ë¶€ë“œëŸ¬ìš´ í‘œí˜„ì„ ì‚¬ìš©í•˜ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤"],
                        "improved_version": improved[:200] + "..." if len(improved) > 200 else improved,
                    })
            else:
                neutral_count += 1

        # Generate suggestions
        suggestions = []
        if harsh_count > 0:
            suggestions.append("ëª…ë ¹í˜• í‘œí˜„ ëŒ€ì‹  ì œì•ˆí˜• í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš” (ì˜ˆ: '~í•˜ì„¸ìš”' â†’ '~í•˜ë©´ ì–´ë–¨ê¹Œìš”?')")
        if constructive_count < len(reviews) * 0.5:
            suggestions.append("êµ¬ì²´ì ì¸ ê°œì„  ë°©ì•ˆê³¼ ì˜ˆì‹œë¥¼ í•¨ê»˜ ì œê³µí•˜ì„¸ìš”")
        if len([r for r in reviews if REGEX_PATTERNS['positive_emojis'].search(r.get("body", ""))]) < len(reviews) * 0.3:
            suggestions.append("ê¸ì •ì ì¸ í”¼ë“œë°±ê³¼ í•¨ê»˜ ì´ëª¨ì§€ë¥¼ í™œìš©í•˜ì—¬ ì¹œê·¼í•œ ë¶„ìœ„ê¸°ë¥¼ ë§Œë“œì„¸ìš”")

        # Default suggestions if none generated
        if not suggestions:
            suggestions = [
                "ë¦¬ë·° ì½”ë©˜íŠ¸ëŠ” ê±´ì„¤ì ì´ê³  ì¡´ì¤‘í•˜ëŠ” í†¤ì„ ìœ ì§€í•˜ì„¸ìš”.",
                "êµ¬ì²´ì ì¸ ê°œì„  ì œì•ˆì„ í¬í•¨í•˜ì„¸ìš”.",
                "ê¸ì •ì ì¸ í”¼ë“œë°±ë„ í•¨ê»˜ ì œê³µí•˜ì„¸ìš”.",
            ]

        return {
            "constructive_reviews": constructive_count,
            "harsh_reviews": harsh_count,
            "neutral_reviews": neutral_count,
            "suggestions": suggestions,
            "examples_good": examples_good,
            "examples_improve": examples_improve,
        }


class IssueQualityAnalyzer:
    """Heuristic analyzer for issue quality."""

    @staticmethod
    def score_issue_quality(
        body: str,
        body_short: int,
        body_detailed: int,
        good_score: int
    ) -> tuple[int, list[str], list[str]]:
        """Score issue quality and return score, strengths, and missing elements.

        Args:
            body: Issue body text
            body_short: Short body threshold
            body_detailed: Detailed body threshold
            good_score: Good score threshold

        Returns:
            Tuple of (score, strengths, missing_elements)
        """
        score = 0
        strengths = []
        missing = []

        # Check body length
        if len(body) > body_detailed:
            score += 2
            strengths.append("ìƒì„¸í•œ ì„¤ëª…")
        elif len(body) > body_short:
            score += 1
        else:
            missing.append("ë³¸ë¬¸ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤")

        # Check for structured information
        structured_checks = [
            (r'(steps to reproduce|ì¬í˜„ ë‹¨ê³„|how to reproduce)', "ì¬í˜„ ë‹¨ê³„ í¬í•¨", "ì¬í˜„ ë‹¨ê³„", 2),
            (r'(expected|actual|ì˜ˆìƒ|ì‹¤ì œ)', "ì˜ˆìƒ/ì‹¤ì œ ê²°ê³¼ ë¹„êµ", "ì˜ˆìƒ/ì‹¤ì œ ê²°ê³¼", 1),
            (r'(environment|version|os|browser|í™˜ê²½)', "í™˜ê²½ ì •ë³´ í¬í•¨", "í™˜ê²½ ì •ë³´", 1),
            (r'(screenshot|image|!\\[|ìŠ¤í¬ë¦°ìƒ·)', "ìŠ¤í¬ë¦°ìƒ·/ì´ë¯¸ì§€ ì²¨ë¶€", None, 1),
        ]

        for pattern, strength, missing_name, points in structured_checks:
            if re.search(pattern, body, re.IGNORECASE):
                score += points
                strengths.append(strength)
            elif missing_name and score < good_score - 1:
                missing.append(missing_name)

        # Check for code blocks
        if '```' in body or '`' in body:
            score += 1
            strengths.append("ì½”ë“œ ì˜ˆì‹œ í¬í•¨")

        # Check for links/references
        if REGEX_PATTERNS['issue_reference'].search(body):
            score += 1

        return score, strengths, missing

    @staticmethod
    def detect_issue_type(title: str, body: str) -> str:
        """Detect issue type from title and body.

        Args:
            title: Issue title
            body: Issue body

        Returns:
            Issue type: 'bug', 'feature', 'question', or 'other'
        """
        text = (title + " " + body).lower()

        if REGEX_PATTERNS['bug_keywords'].search(text):
            return "bug"
        elif REGEX_PATTERNS['feature_keywords'].search(text):
            return "feature"
        elif REGEX_PATTERNS['question_keywords'].search(text):
            return "question"
        else:
            return "other"

    @staticmethod
    def analyze(issues: list[dict[str, str]]) -> dict[str, Any]:
        """Enhanced heuristic-based issue quality analysis.

        Args:
            issues: List of issue dictionaries with 'number', 'title', 'body' keys

        Returns:
            Analysis results dictionary
        """
        body_short = HEURISTIC_THRESHOLDS['issue_body_short']
        body_detailed = HEURISTIC_THRESHOLDS['issue_body_detailed']
        good_score = HEURISTIC_THRESHOLDS['issue_good_score']

        # Define scoring function
        def score_fn(issue):
            body = issue.get("body", "").strip()
            title = issue.get("title", "").strip()
            score, strengths, missing = IssueQualityAnalyzer.score_issue_quality(
                body, body_short, body_detailed, good_score
            )
            return score, (title, body, strengths, missing)

        # Define example formatters
        def good_example_fn(issue, metadata):
            title, body, strengths, _ = metadata
            return {
                "number": issue["number"],
                "title": title,
                "type": IssueQualityAnalyzer.detect_issue_type(title, body),
                "strengths": strengths[:3],
                "completeness_score": min(10, score_fn(issue)[0])
            }

        def poor_example_fn(issue, metadata):
            title, _, _, missing = metadata
            return {
                "number": issue["number"],
                "title": title,
                "missing_elements": missing,
                "suggestion": "ì´ìŠˆ í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ê±°ë‚˜ ì¬í˜„ ë‹¨ê³„, ì˜ˆìƒ/ì‹¤ì œ ê²°ê³¼, í™˜ê²½ ì •ë³´ë¥¼ ì¶”ê°€í•˜ì„¸ìš”."
            }

        # Use generic analyzer
        well_described, poorly_described, examples_good, examples_poor = HeuristicAnalyzer.analyze_with_scoring(
            issues, score_fn, good_score, good_example_fn, poor_example_fn,
            max_examples=3
        )

        return {
            "well_described": well_described,
            "poorly_described": poorly_described,
            "suggestions": [
                "ì´ìŠˆ ë³¸ë¬¸ì— ìƒì„¸í•œ ì„¤ëª…ì„ í¬í•¨í•˜ì„¸ìš” (ìµœì†Œ 100ì ì´ìƒ).",
                "Bug Report: ì¬í˜„ ë‹¨ê³„, ì˜ˆìƒ ê²°ê³¼, ì‹¤ì œ ê²°ê³¼, í™˜ê²½ ì •ë³´ë¥¼ í¬í•¨í•˜ì„¸ìš”.",
                "Feature Request: í•´ê²°í•˜ë ¤ëŠ” ë¬¸ì œ, ì œì•ˆí•˜ëŠ” ì†”ë£¨ì…˜, ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.",
                "ì½”ë“œ ë¸”ë¡(```)ì´ë‚˜ ìŠ¤í¬ë¦°ìƒ·ì„ í™œìš©í•˜ì—¬ ì‹œê°ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.",
                "ê´€ë ¨ ì´ìŠˆë‚˜ PRì„ ì°¸ì¡°í•˜ì„¸ìš” (#123 í˜•ì‹).",
            ],
            "examples_good": examples_good,
            "examples_poor": examples_poor,
        }
