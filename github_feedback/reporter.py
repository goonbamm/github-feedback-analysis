"""Report generation for GitHub feedback analysis."""

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Any, Callable, Dict, Iterable, List, Optional, Protocol, Tuple, Union

from .console import Console
from .constants import AWARD_CATEGORIES, AWARD_KEYWORDS, COLLECTION_LIMITS, DISPLAY_LIMITS
from .game_elements import GameRenderer, LevelCalculator
from .models import (
    CommitMessageFeedback,
    IssueFeedback,
    MetricSnapshot,
    PRTitleFeedback,
    ReviewToneFeedback,
)
from .utils import pad_to_width

console = Console()

# Type alias for feedback data structures
FeedbackData = Union[CommitMessageFeedback, PRTitleFeedback, ReviewToneFeedback, IssueFeedback]


# ============================================================================
# Helper Classes for Report Generation
# ============================================================================

class MarkdownSectionBuilder:
    """Helper class for building markdown sections with common patterns."""

    @staticmethod
    def build_section(
        title: str,
        description: str = "",
        emoji: str = ""
    ) -> List[str]:
        """Build a section header with optional description."""
        lines = []
        header = f"### {emoji} {title}" if emoji else f"### {title}"
        lines.append(header)
        lines.append("")

        if description:
            lines.append(f"> {description}")
            lines.append("")

        return lines

    @staticmethod
    def build_table(headers: List[str], rows: List[List[str]]) -> List[str]:
        """Build a markdown table from headers and rows."""
        lines = []
        lines.append("| " + " | ".join(headers) + " |")
        lines.append("|" + "|".join(["---"] * len(headers)) + "|")

        for row in rows:
            lines.append("| " + " | ".join(str(cell) for cell in row) + " |")

        lines.append("")
        return lines

    @staticmethod
    def build_list(items: List[str], prefix: str = "-") -> List[str]:
        """Build a markdown list from items."""
        return [f"{prefix} {item}" for item in items] + [""]

    @staticmethod
    def build_subsection(
        data_check: Any,
        title: str,
        content_builder: Callable[[], List[str]],
        emoji: str = "",
        description: str = ""
    ) -> List[str]:
        """Build a subsection if data exists, using a content builder function."""
        lines = []
        if data_check:
            lines.extend(MarkdownSectionBuilder.build_section(title, description, emoji))
            lines.extend(content_builder())
        return lines


def _format_metric_value(value: object) -> str:
    """Format numeric values with separators while keeping strings intact."""

    if isinstance(value, bool):
        return str(value)
    if isinstance(value, int):
        return f"{value:,}"
    if isinstance(value, float):
        return f"{value:,.2f}"
    return str(value)


def _escape_table_cell(text: str) -> str:
    """Escape special characters in markdown table cells to prevent table breakage.

    Args:
        text: Text to escape

    Returns:
        Escaped text safe for use in markdown tables
    """
    if not text:
        return text

    # Replace pipe characters that would break table structure
    text = text.replace("|", "\\|")

    # Replace newlines with HTML breaks for multi-line content
    text = text.replace("\n", "<br>")

    # Trim excessive whitespace
    text = " ".join(text.split())

    return text


@dataclass(slots=True)
class Reporter:
    """Create human-readable artefacts from metrics."""

    output_dir: Path = Path("reports")
    _current_repo: Optional[str] = None  # Temporary storage for current repo during report generation
    llm_client: Optional[Any] = None  # Optional LLM client for generating summary quotes
    web_url: str = "https://github.com"  # Base URL for GitHub links (configurable for enterprise)

    def ensure_structure(self) -> None:
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def _get_repo_from_context(self) -> str:
        """Get the current repository being processed.

        Returns:
            Repository in 'owner/repo' format, or empty string if not available
        """
        return self._current_repo or ""

    def _categorize_awards(self, awards: List[str]) -> dict:
        """Categorize awards by type for better organization."""
        # Initialize categories from constants
        categories = {label: [] for label in AWARD_CATEGORIES.values()}

        for award in awards:
            categorized = False
            # Check each category's keywords
            for category_key, keywords in AWARD_KEYWORDS.items():
                if any(keyword in award for keyword in keywords):
                    category_label = AWARD_CATEGORIES[category_key]
                    categories[category_label].append(award)
                    categorized = True
                    break

            # Default category if no keywords match
            if not categorized:
                categories[AWARD_CATEGORIES['basic']].append(award)

        # Remove empty categories
        return {k: v for k, v in categories.items() if v}



    def _build_header_and_summary(self, metrics: MetricSnapshot) -> List[str]:
        """Build header and summary section."""
        lines = ["# ğŸš€ GitHub Feedback Report", ""]

        # Generate witty summary quote if LLM client is available
        if self.llm_client and (metrics.awards or metrics.highlights or metrics.summary):
            try:
                quote = self.llm_client.generate_award_summary_quote(
                    metrics.awards,
                    metrics.highlights,
                    metrics.summary,
                )
                if quote:
                    lines.append(f"> âœ¨ **{quote}**")
                    lines.append("")
            except Exception as e:
                # Silently skip if quote generation fails
                console.log("Failed to generate award summary quote", f"error={e}")

        lines.append(f"**Repository**: {metrics.repo}")
        lines.append(f"**Period**: {metrics.months} months")

        if metrics.since_date and metrics.until_date:
            since_str = metrics.since_date.strftime("%Y-%m-%d")
            until_str = metrics.until_date.strftime("%Y-%m-%d")
            lines.append(f"**Analysis Period**: {since_str} ~ {until_str}")

        lines.append("")
        lines.append("---")
        lines.append("")

        return lines

    def _build_table_of_contents(self, metrics: MetricSnapshot) -> List[str]:
        """Build table of contents section."""
        lines = ["## ğŸ“‘ ëª©ì°¨", ""]

        sections = [
            ("ğŸ“Š Executive Summary", "í•œëˆˆì— ë³´ëŠ” í•µì‹¬ ì§€í‘œ"),
            ("ğŸ† Awards Cabinet", "íšë“í•œ ì–´ì›Œë“œ"),
            ("âœ¨ Growth Highlights", "ì„±ì¥ í•˜ì´ë¼ì´íŠ¸"),
            ("ğŸ“ˆ Monthly Trends", "ì›”ë³„ í™œë™ íŠ¸ë Œë“œ"),
        ]

        if metrics.detailed_feedback:
            sections.append(("ğŸ’¡ Detailed Feedback", "ìƒì„¸ í”¼ë“œë°±"))

        # Add retrospective section
        if metrics.retrospective:
            sections.append(("ğŸ” Deep Retrospective", "ì‹¬ì¸µ íšŒê³  ë¶„ì„"))

        sections.extend([
            ("ğŸ¯ Spotlight Examples", "ì£¼ìš” ê¸°ì—¬ ì‚¬ë¡€"),
            ("ğŸ’» Tech Stack", "ê¸°ìˆ  ìŠ¤íƒ ë¶„ì„"),
            ("ğŸ¤ Collaboration", "í˜‘ì—… ë„¤íŠ¸ì›Œí¬"),
            ("ğŸ“Š Detailed Metrics", "ìƒì„¸ ë©”íŠ¸ë¦­"),
            ("ğŸ”— Evidence", "ì¦ê±° ë§í¬"),
        ])

        for i, (title, desc) in enumerate(sections, 1):
            lines.append(f"{i}. **{title}** - {desc}")

        lines.append("")
        lines.append("---")
        lines.append("")
        return lines

    def _build_executive_summary(self, metrics: MetricSnapshot) -> List[str]:
        """Build executive summary section with key highlights."""
        lines = ["## ğŸ“Š Executive Summary", ""]
        lines.append("> í™œë™ ê¸°ê°„ì˜ í•µì‹¬ ì„±ê³¼ë¥¼ í•œëˆˆì— í™•ì¸í•˜ì„¸ìš”")
        lines.append("")

        # Key metrics in a box format
        total_activity = sum([
            metrics.stats.get("commits", {}).get("total", 0),
            metrics.stats.get("pull_requests", {}).get("total", 0),
            metrics.stats.get("reviews", {}).get("total", 0),
        ])

        lines.append("### ğŸ“ˆ í•µì‹¬ ì§€í‘œ")
        lines.append("")
        lines.append("| ì§€í‘œ | ê°’ | ì„¤ëª… |")
        lines.append("|------|-----|------|")

        for key, value in metrics.summary.items():
            display_value = (
                _format_metric_value(value) if isinstance(value, (int, float)) else str(value)
            )
            # Add descriptions for each metric
            descriptions = {
                "velocity": "ì›”í‰ê·  ì»¤ë°‹ ì†ë„",
                "collaboration": "ì›”í‰ê·  í˜‘ì—… í™œë™",
                "stability": "ì•ˆì •ì„± ì ìˆ˜",
                "growth": "ì „ì²´ ì„±ì¥ ìš”ì•½"
            }
            desc = descriptions.get(key, "")
            lines.append(f"| **{key.title()}** | {display_value} | {desc} |")

        lines.append("")

        # Quick stats
        if metrics.awards:
            lines.append(f"ğŸ† **ì´ {len(metrics.awards)}ê°œì˜ ì–´ì›Œë“œ íšë“**")

        if metrics.highlights:
            lines.append(f"âœ¨ **{len(metrics.highlights)}ê°œì˜ ì£¼ìš” ì„±ê³¼**")

        lines.append("")
        lines.append("---")
        lines.append("")

        return lines

    def _build_metrics_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build metrics section (HTML version)."""
        lines = ["## ğŸ“Š Detailed Metrics", ""]
        lines.append("> ê° í™œë™ ì˜ì—­ë³„ ìƒì„¸ ìˆ˜ì¹˜ë¥¼ í™•ì¸í•˜ì„¸ìš”")
        lines.append("")

        for domain, domain_stats in metrics.stats.items():
            lines.append(f"### {domain.title()}")
            lines.append("")

            # Build table data
            headers = ["ì§€í‘œ", "ê°’"]
            rows = []
            for stat_name, stat_value in domain_stats.items():
                formatted_value = (
                    _format_metric_value(stat_value)
                    if isinstance(stat_value, (int, float))
                    else str(stat_value)
                )
                rows.append([stat_name.replace('_', ' ').title(), formatted_value])

            # Render as HTML table
            lines.extend(GameRenderer.render_html_table(
                headers=headers,
                rows=rows,
                title="",
                description="",
                striped=True
            ))

        return lines

    def _build_highlights_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build growth highlights section (HTML version)."""
        if not metrics.highlights:
            return []

        lines = ["## âœ¨ Growth Highlights", ""]
        lines.append("> ì´ë²ˆ ê¸°ê°„ ë™ì•ˆì˜ ì£¼ìš” ì„±ê³¼ì™€ ì„±ì¥ í¬ì¸íŠ¸")
        lines.append("")

        # Build HTML table
        headers = ["#", "ì„±ê³¼"]
        rows = [[str(i), highlight] for i, highlight in enumerate(metrics.highlights, 1)]

        lines.extend(GameRenderer.render_html_table(
            headers=headers,
            rows=rows,
            title="",
            description="",
            striped=True
        ))

        lines.append("---")
        lines.append("")
        return lines

    def _build_spotlight_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build spotlight examples section (HTML version)."""
        if not metrics.spotlight_examples:
            return []

        # Filter out categories with no entries
        non_empty_categories = {
            category: entries
            for category, entries in metrics.spotlight_examples.items()
            if entries
        }

        # If no categories have content, don't create the section
        if not non_empty_categories:
            return []

        lines = ["## ğŸ¯ Spotlight Examples", ""]
        lines.append("> ì£¼ëª©í•  ë§Œí•œ ê¸°ì—¬ ì‚¬ë¡€")
        lines.append("")

        for category, entries in non_empty_categories.items():
            lines.append(f"### {category.replace('_', ' ').title()}")
            lines.append("")

            # Build table data
            headers = ["ì‚¬ë¡€"]
            rows = [[entry] for entry in entries]

            # Render as HTML table
            lines.extend(GameRenderer.render_html_table(
                headers=headers,
                rows=rows,
                title="",
                description="",
                striped=True
            ))

        lines.append("---")
        lines.append("")
        return lines

    def _build_year_in_review_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build comprehensive year in review section combining story and detailed review."""
        if not metrics.yearbook_story and not metrics.year_end_review:
            return []

        lines = ["## ğŸ“… Year in Review", ""]
        lines.append("> í•œ í•´ì˜ ì—¬ì •ì„ ëŒì•„ë´…ë‹ˆë‹¤")
        lines.append("")

        # Story beats
        if metrics.yearbook_story:
            lines.append("### ğŸŒŸ ì˜¬í•´ì˜ ì´ì•¼ê¸°")
            lines.append("")
            for paragraph in metrics.yearbook_story:
                lines.append(paragraph)
                lines.append("")

        # Year end review details
        if metrics.year_end_review:
            if metrics.year_end_review.proudest_moments:
                lines.append("### ğŸ… ìë‘ìŠ¤ëŸ¬ìš´ ìˆœê°„ë“¤")
                lines.append("")
                lines.append("| ìˆœê°„ |")
                lines.append("|------|")
                for moment in metrics.year_end_review.proudest_moments:
                    lines.append(f"| {moment} |")
                lines.append("")

            if metrics.year_end_review.biggest_challenges:
                lines.append("### ğŸ’ª ê·¹ë³µí•œ ë„ì „ë“¤")
                lines.append("")
                lines.append("| ë„ì „ |")
                lines.append("|------|")
                for challenge in metrics.year_end_review.biggest_challenges:
                    lines.append(f"| {challenge} |")
                lines.append("")

            if metrics.year_end_review.lessons_learned:
                lines.append("### ğŸ“š ë°°ìš´ êµí›ˆë“¤")
                lines.append("")
                lines.append("| êµí›ˆ |")
                lines.append("|------|")
                for lesson in metrics.year_end_review.lessons_learned:
                    lines.append(f"| {lesson} |")
                lines.append("")

            if metrics.year_end_review.next_year_goals:
                lines.append("### ğŸ¯ ë‚´ë…„ ëª©í‘œ")
                lines.append("")
                lines.append("| ëª©í‘œ |")
                lines.append("|------|")
                for goal in metrics.year_end_review.next_year_goals:
                    lines.append(f"| {goal} |")
                lines.append("")

        lines.append("---")
        lines.append("")
        return lines


    def _build_skill_tree_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build skill tree section showing acquired and available skills."""
        lines = ["## ğŸ® ìŠ¤í‚¬ íŠ¸ë¦¬", ""]
        lines.append("> íšë“í•œ ìŠ¤í‚¬ê³¼ ìŠµë“ ê°€ëŠ¥í•œ ìŠ¤í‚¬ì„ í™•ì¸í•˜ì„¸ìš”")
        lines.append("")

        # Collect acquired skills (from awards and highlights)
        acquired_skills = []
        available_skills = []
        growing_skills = []

        # 1. Acquired Skills - from top awards and strengths
        if metrics.awards:
            for award in metrics.awards[:3]:
                # Determine mastery based on award position
                mastery = 100 - (metrics.awards.index(award) * 10)
                acquired_skills.append({
                    "name": award,
                    "type": "íŒ¨ì‹œë¸Œ",
                    "mastery": mastery,
                    "effect": "ì§€ì†ì ìœ¼ë¡œ ë°œíœ˜ë˜ëŠ” ê°•ì ",
                    "evidence": [award],
                    "emoji": "ğŸ’"
                })

        # Add skills from highlights
        if metrics.highlights and len(acquired_skills) < 5:
            remaining = 5 - len(acquired_skills)
            for highlight in metrics.highlights[:remaining]:
                acquired_skills.append({
                    "name": highlight.split('.')[0],
                    "type": "ì•¡í‹°ë¸Œ",
                    "mastery": 80,
                    "effect": "ì˜ì‹ì ìœ¼ë¡œ í™œìš©í•˜ëŠ” ëŠ¥ë ¥",
                    "evidence": [highlight],
                    "emoji": "âœ¨"
                })

        # Add coding habits as acquired skills if quality is high
        if metrics.detailed_feedback and len(acquired_skills) < 5:
            # Commit message mastery
            if metrics.detailed_feedback.commit_feedback:
                cf = metrics.detailed_feedback.commit_feedback
                if cf.total_commits > 0:
                    quality_ratio = cf.good_messages / cf.total_commits
                    if quality_ratio >= 0.7:  # 70% or better
                        mastery = min(100, int(quality_ratio * 100))
                        acquired_skills.append({
                            "name": "ëª…í™•í•œ ì»¤ë°‹ ë©”ì‹œì§€ ì‘ì„±",
                            "type": "íŒ¨ì‹œë¸Œ",
                            "mastery": mastery,
                            "effect": f"ì „ì²´ ì»¤ë°‹ì˜ {int(quality_ratio * 100)}%ê°€ ëª…í™•í•˜ê³  ì˜ë¯¸ìˆëŠ” ë©”ì‹œì§€",
                            "evidence": [f"{cf.good_messages}/{cf.total_commits} ì»¤ë°‹ì´ ë†’ì€ í’ˆì§ˆ"],
                            "emoji": "ğŸ“"
                        })

            # PR title mastery
            if metrics.detailed_feedback.pr_title_feedback and len(acquired_skills) < 5:
                pf = metrics.detailed_feedback.pr_title_feedback
                if pf.total_prs > 0:
                    quality_ratio = pf.clear_titles / pf.total_prs
                    if quality_ratio >= 0.7:  # 70% or better
                        mastery = min(100, int(quality_ratio * 100))
                        acquired_skills.append({
                            "name": "ëª…í™•í•œ PR ì œëª© ì‘ì„±",
                            "type": "íŒ¨ì‹œë¸Œ",
                            "mastery": mastery,
                            "effect": f"ì „ì²´ PRì˜ {int(quality_ratio * 100)}%ê°€ ëª…í™•í•˜ê³  êµ¬ì²´ì ",
                            "evidence": [f"{pf.clear_titles}/{pf.total_prs} PRì´ ë†’ì€ í’ˆì§ˆ"],
                            "emoji": "ğŸ”€"
                        })

            # Review tone mastery
            if metrics.detailed_feedback.review_tone_feedback and len(acquired_skills) < 5:
                rtf = metrics.detailed_feedback.review_tone_feedback
                total_reviews = rtf.constructive_reviews + rtf.harsh_reviews + rtf.neutral_reviews
                if total_reviews > 0:
                    quality_ratio = rtf.constructive_reviews / total_reviews
                    if quality_ratio >= 0.7:  # 70% or better
                        mastery = min(100, int(quality_ratio * 100))
                        acquired_skills.append({
                            "name": "ê±´ì„¤ì ì¸ ë¦¬ë·° ì‘ì„±",
                            "type": "íŒ¨ì‹œë¸Œ",
                            "mastery": mastery,
                            "effect": f"ì „ì²´ ë¦¬ë·°ì˜ {int(quality_ratio * 100)}%ê°€ ê±´ì„¤ì ì´ê³  ë„ì›€ì´ ë¨",
                            "evidence": [f"{rtf.constructive_reviews}/{total_reviews} ë¦¬ë·°ê°€ ë†’ì€ í’ˆì§ˆ"],
                            "emoji": "ğŸ‘€"
                        })

        # 2. Available Skills - from improvement suggestions
        if metrics.detailed_feedback:
            if metrics.detailed_feedback.commit_feedback and hasattr(metrics.detailed_feedback.commit_feedback, 'suggestions'):
                for suggestion in metrics.detailed_feedback.commit_feedback.suggestions[:2]:
                    available_skills.append({
                        "name": "ì»¤ë°‹ ë©”ì‹œì§€ í–¥ìƒ",
                        "type": "ë¯¸ìŠµë“",
                        "mastery": 40,
                        "effect": suggestion,
                        "evidence": [suggestion],
                        "emoji": "ğŸ“"
                    })

            if metrics.detailed_feedback.pr_title_feedback and hasattr(metrics.detailed_feedback.pr_title_feedback, 'suggestions'):
                for suggestion in metrics.detailed_feedback.pr_title_feedback.suggestions[:2]:
                    available_skills.append({
                        "name": "PR ì œëª© ìµœì í™”",
                        "type": "ë¯¸ìŠµë“",
                        "mastery": 40,
                        "effect": suggestion,
                        "evidence": [suggestion],
                        "emoji": "ğŸ”€"
                    })

            if metrics.detailed_feedback.review_tone_feedback and hasattr(metrics.detailed_feedback.review_tone_feedback, 'suggestions'):
                for suggestion in metrics.detailed_feedback.review_tone_feedback.suggestions[:2]:
                    available_skills.append({
                        "name": "ê±´ì„¤ì ì¸ ë¦¬ë·° ì‘ì„±",
                        "type": "ë¯¸ìŠµë“",
                        "mastery": 40,
                        "effect": suggestion,
                        "evidence": [suggestion],
                        "emoji": "ğŸ‘€"
                    })

        # 3. Growing Skills - from retrospective positive patterns
        if metrics.retrospective and hasattr(metrics.retrospective, 'behavior_patterns'):
            positive_patterns = [bp for bp in metrics.retrospective.behavior_patterns if bp.impact == "positive"]
            for pattern in positive_patterns[:3]:
                growing_skills.append({
                    "name": pattern.description,
                    "type": "ì„±ì¥ì¤‘",
                    "mastery": 60,
                    "effect": "ë¹ ë¥´ê²Œ ë°œì „í•˜ê³  ìˆëŠ” ì˜ì—­",
                    "evidence": [pattern.description],
                    "emoji": "ğŸŒ±"
                })

        # Render acquired skills
        if acquired_skills:
            lines.append("### ğŸ’ íšë“í•œ ìŠ¤í‚¬ (Acquired Skills)")
            lines.append("")
            for skill in acquired_skills:
                lines.extend(GameRenderer.render_skill_card(
                    skill["name"],
                    skill["type"],
                    skill["mastery"],
                    skill["effect"],
                    skill["evidence"],
                    skill["emoji"]
                ))

        # Render growing skills
        if growing_skills:
            lines.append("### ğŸŒ± ì„±ì¥ ì¤‘ì¸ ìŠ¤í‚¬ (Growing Skills)")
            lines.append("")
            for skill in growing_skills:
                lines.extend(GameRenderer.render_skill_card(
                    skill["name"],
                    skill["type"],
                    skill["mastery"],
                    skill["effect"],
                    skill["evidence"],
                    skill["emoji"]
                ))

        # Render available skills
        if available_skills:
            lines.append("### ğŸ¯ ìŠµë“ ê°€ëŠ¥í•œ ìŠ¤í‚¬ (Available Skills)")
            lines.append("")
            for skill in available_skills[:3]:  # Limit to top 3
                lines.extend(GameRenderer.render_skill_card(
                    skill["name"],
                    skill["type"],
                    skill["mastery"],
                    skill["effect"],
                    skill["evidence"],
                    skill["emoji"]
                ))

        lines.append("---")
        lines.append("")
        return lines

    def _build_summary_overview_table(self, metrics: MetricSnapshot) -> List[str]:
        """Build integrated summary table with strengths, areas for improvement, and growth."""
        lines = ["## ğŸ“Š í•œëˆˆì— ë³´ëŠ” ìš”ì•½", ""]
        lines.append("> ì˜í•˜ê³  ìˆëŠ” ê²ƒ, ë³´ì™„í•˜ë©´ ì¢‹ì„ ê²ƒ, ì„±ì¥í•œ ì ì„ í•œëˆˆì— í™•ì¸í•˜ì„¸ìš”")
        lines.append("")

        lines.append("| êµ¬ë¶„ | ë‚´ìš© |")
        lines.append("|------|------|")

        # 1. ì˜í•˜ê³  ìˆëŠ” ê²ƒ (Strengths) - from awards and highlights
        strengths = []

        # Get top awards (max 3)
        if metrics.awards:
            top_awards = metrics.awards[:3]
            strengths.extend([f"ğŸ† {award}" for award in top_awards])

        # Get key highlights if we need more (max 3 total)
        if len(strengths) < 3 and metrics.highlights:
            remaining = 3 - len(strengths)
            for highlight in metrics.highlights[:remaining]:
                # Shorten highlight to first sentence or 80 chars
                short_highlight = highlight.split('.')[0][:80]
                if len(highlight.split('.')[0]) > 80:
                    short_highlight += "..."
                strengths.append(f"âœ¨ {short_highlight}")

        # Add strengths to table
        if strengths:
            strengths_text = "<br>".join(strengths)
            lines.append(f"| **âœ… ì˜í•˜ê³  ìˆëŠ” ê²ƒ** | {strengths_text} |")
        else:
            lines.append("| **âœ… ì˜í•˜ê³  ìˆëŠ” ê²ƒ** | í™œë™ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤ |")

        # 2. ë³´ì™„í•˜ë©´ ì¢‹ì„ ê²ƒ (Areas for Improvement) - from detailed feedback suggestions
        improvements = []

        if metrics.detailed_feedback:
            # Collect suggestions from all feedback types
            if metrics.detailed_feedback.commit_feedback and hasattr(metrics.detailed_feedback.commit_feedback, 'suggestions'):
                improvements.extend([f"ğŸ“ {s}" for s in metrics.detailed_feedback.commit_feedback.suggestions[:2]])

            if len(improvements) < 3 and metrics.detailed_feedback.pr_title_feedback and hasattr(metrics.detailed_feedback.pr_title_feedback, 'suggestions'):
                remaining = 3 - len(improvements)
                improvements.extend([f"ğŸ”€ {s}" for s in metrics.detailed_feedback.pr_title_feedback.suggestions[:remaining]])

            if len(improvements) < 3 and metrics.detailed_feedback.review_tone_feedback and hasattr(metrics.detailed_feedback.review_tone_feedback, 'suggestions'):
                remaining = 3 - len(improvements)
                improvements.extend([f"ğŸ‘€ {s}" for s in metrics.detailed_feedback.review_tone_feedback.suggestions[:remaining]])

        # Add improvement areas to table
        if improvements:
            improvements_text = "<br>".join(improvements[:3])
            lines.append(f"| **ğŸ’¡ ë³´ì™„í•˜ë©´ ì¢‹ì„ ê²ƒ** | {improvements_text} |")
        else:
            lines.append("| **ğŸ’¡ ë³´ì™„í•˜ë©´ ì¢‹ì„ ê²ƒ** | ì „ë°˜ì ìœ¼ë¡œ ì¢‹ì€ í’ˆì§ˆì„ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤ |")

        # 3. ì„±ì¥í•œ ì  (Growth) - from retrospective and highlights
        growth_points = []

        # Get from retrospective if available
        if metrics.retrospective:
            # Use time comparisons showing positive growth
            if hasattr(metrics.retrospective, 'time_comparisons') and metrics.retrospective.time_comparisons:
                for tc in metrics.retrospective.time_comparisons[:2]:
                    if tc.direction == "increasing" and tc.significance in ["major", "moderate"]:
                        growth_points.append(f"ğŸ“ˆ {tc.metric_name} {tc.change_percentage:+.0f}% ì¦ê°€")

            # Use behavior patterns with positive impact
            if len(growth_points) < 3 and hasattr(metrics.retrospective, 'behavior_patterns') and metrics.retrospective.behavior_patterns:
                remaining = 3 - len(growth_points)
                positive_patterns = [bp for bp in metrics.retrospective.behavior_patterns if bp.impact == "positive"]
                for pattern in positive_patterns[:remaining]:
                    short_desc = pattern.description[:60]
                    if len(pattern.description) > 60:
                        short_desc += "..."
                    growth_points.append(f"ğŸ§  {short_desc}")

        # Fallback to highlights
        if len(growth_points) < 3 and metrics.highlights:
            remaining = 3 - len(growth_points)
            for highlight in metrics.highlights[:remaining]:
                short_highlight = highlight.split('.')[0][:60]
                if len(highlight.split('.')[0]) > 60:
                    short_highlight += "..."
                growth_points.append(f"âœ¨ {short_highlight}")

        # Add growth points to table
        if growth_points:
            growth_text = "<br>".join(growth_points[:3])
            lines.append(f"| **ğŸŒ± ì„±ì¥í•œ ì ** | {growth_text} |")
        else:
            lines.append("| **ğŸŒ± ì„±ì¥í•œ ì ** | ê¾¸ì¤€í•œ í™œë™ìœ¼ë¡œ ì„±ì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤ |")

        lines.append("")
        lines.append("---")
        lines.append("")
        return lines

    def _build_awards_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build awards cabinet section (HTML version)."""
        if not metrics.awards:
            return []

        lines = ["## ğŸ† Awards Cabinet", ""]
        lines.append(f"**ì´ {len(metrics.awards)}ê°œì˜ ì–´ì›Œë“œë¥¼ íšë“í–ˆìŠµë‹ˆë‹¤!**")
        lines.append("")

        categories = self._categorize_awards(metrics.awards)

        # Build awards grid with HTML
        awards_data = []
        for category_name, category_awards in categories.items():
            if category_awards:
                # Extract emoji from category name
                emoji = category_name.split()[0] if category_name else "ğŸ†"
                category_title = " ".join(category_name.split()[1:]) if len(category_name.split()) > 1 else category_name

                # Combine all awards in this category
                description = "<br>".join(f"â€¢ {award}" for award in category_awards)

                awards_data.append({
                    "category": category_title,
                    "description": description,
                    "emoji": emoji,
                    "count": str(len(category_awards))
                })

        # Render using HTML
        lines.extend(GameRenderer.render_awards_grid(awards_data, columns=2))

        lines.append("---")
        lines.append("")
        return lines

    def _calculate_repo_character_stats(self, metrics: MetricSnapshot) -> dict:
        """Calculate RPG-style character stats from repository metrics."""
        stats = metrics.stats

        # Extract key metrics with safe defaults
        commits = stats.get("commits", {})
        prs = stats.get("pull_requests", {})
        reviews = stats.get("reviews", {})

        total_commits = commits.get("total", 0)
        total_prs = prs.get("total", 0)
        total_reviews = reviews.get("total", 0)
        merged_prs = prs.get("merged", 0)

        # Code Quality (0-100): Based on PR merge rate, awards, and coding habits
        merge_rate = (merged_prs / total_prs) if total_prs > 0 else 0
        award_count = len(metrics.awards) if metrics.awards else 0

        # Calculate coding habits quality (commit messages + PR titles)
        coding_habits_score = 0
        if metrics.detailed_feedback:
            # Commit message quality
            if metrics.detailed_feedback.commit_feedback:
                cf = metrics.detailed_feedback.commit_feedback
                if cf.total_commits > 0:
                    commit_quality_ratio = cf.good_messages / cf.total_commits
                    coding_habits_score += commit_quality_ratio * 50  # 0-50 points

            # PR title quality
            if metrics.detailed_feedback.pr_title_feedback:
                pf = metrics.detailed_feedback.pr_title_feedback
                if pf.total_prs > 0:
                    pr_title_quality_ratio = pf.clear_titles / pf.total_prs
                    coding_habits_score += pr_title_quality_ratio * 50  # 0-50 points

            # Normalize to 0-20 range
            coding_habits_score = min(20, coding_habits_score / 5)

        code_quality = min(100, int(
            (merge_rate * 35) +  # Merge success rate (0-35)
            (min(award_count / 15, 1) * 25) +  # Award achievement (0-25)
            (20 if total_commits >= 100 else (total_commits / 100) * 20) +  # Experience (0-20)
            coding_habits_score  # Coding habits (0-20)
        ))

        # Collaboration (0-100): Based on reviews, PR engagement, and review tone
        collab_network = metrics.collaboration
        unique_collaborators = collab_network.unique_collaborators if collab_network else 0
        review_count = collab_network.review_received_count if collab_network else 0

        # Calculate review tone quality
        review_tone_score = 0
        if metrics.detailed_feedback and metrics.detailed_feedback.review_tone_feedback:
            rtf = metrics.detailed_feedback.review_tone_feedback
            total_tone_reviews = rtf.constructive_reviews + rtf.harsh_reviews + rtf.neutral_reviews
            if total_tone_reviews > 0:
                # Constructive reviews contribute positively, harsh reviews reduce score
                constructive_ratio = rtf.constructive_reviews / total_tone_reviews
                harsh_ratio = rtf.harsh_reviews / total_tone_reviews
                review_tone_score = (constructive_ratio - (harsh_ratio * 0.5)) * 20  # 0-20 points
                review_tone_score = max(0, min(20, review_tone_score))  # Clamp to 0-20

        collaboration = min(100, int(
            (min(total_reviews / 30, 1) * 35) +  # Review activity (0-35)
            (min(unique_collaborators / 15, 1) * 30) +  # Network size (0-30)
            (15 if review_count >= 50 else (review_count / 50) * 15) +  # Review received (0-15)
            review_tone_score  # Review tone quality (0-20)
        ))

        # Problem Solving (0-100): Based on PR diversity and tech stack
        tech_stack = metrics.tech_stack
        tech_diversity = tech_stack.diversity_score if tech_stack else 0
        language_count = len(tech_stack.top_languages) if tech_stack and tech_stack.top_languages else 0

        problem_solving = min(100, int(
            (min(total_prs / 25, 1) * 40) +  # PR production (0-40) - ê¸°ì¤€ ìƒí–¥
            (tech_diversity * 35) +  # Technology breadth (0-35)
            (min(language_count / 7, 1) * 25)  # Language variety (0-25) - ê¸°ì¤€ ìƒí–¥
        ))

        # Productivity (0-100): Based on total activity volume
        total_activity = total_commits + total_prs + total_reviews
        monthly_velocity = total_activity / metrics.months if metrics.months > 0 else 0

        productivity = min(100, int(
            (min(total_commits / 150, 1) * 35) +  # Commit volume (0-35) - ê¸°ì¤€ ìƒí–¥
            (min(total_prs / 50, 1) * 35) +  # PR volume (0-35) - ê¸°ì¤€ ìƒí–¥
            (min(monthly_velocity / 30, 1) * 30)  # Velocity (0-30) - ê¸°ì¤€ ìƒí–¥
        ))

        # Growth (0-100): Based on highlights and retrospective insights
        highlight_count = len(metrics.highlights) if metrics.highlights else 0
        has_retrospective = metrics.retrospective is not None

        # Check for positive growth trends
        growth_indicators = 0
        if metrics.retrospective and hasattr(metrics.retrospective, 'time_comparisons'):
            positive_trends = sum(1 for tc in metrics.retrospective.time_comparisons
                                if tc.direction == "increasing")
            growth_indicators = min(positive_trends, 5)

        growth = min(100, int(
            30 +  # Base growth score - ê¸°ì¤€ í•˜í–¥ (50->30)
            (min(highlight_count / 8, 1) * 25) +  # Highlights (0-25) - ê¸°ì¤€ ìƒí–¥
            (15 if has_retrospective else 0) +  # Deep analysis bonus (0-15)
            (growth_indicators * 6)  # Positive trend bonus (0-30) - ë³´ë„ˆìŠ¤ ì¦ëŒ€
        ))

        return {
            "code_quality": code_quality,
            "collaboration": collaboration,
            "problem_solving": problem_solving,
            "productivity": productivity,
            "growth": growth,
        }

    def _render_repo_character_stats(self, metrics: MetricSnapshot) -> List[str]:
        """Render RPG-style character stats visualization for repository (í‹°ì–´ ì‹œìŠ¤í…œ ì‚¬ìš©)."""
        lines: List[str] = []

        stats = self._calculate_repo_character_stats(metrics)
        avg_stat = sum(stats.values()) / len(stats) if stats else 0

        # í‹°ì–´ ì‹œìŠ¤í…œìœ¼ë¡œ ë“±ê¸‰ ê³„ì‚°
        tier, title, rank_emoji = LevelCalculator.calculate_tier(avg_stat)

        # íŠ¹ì„± íƒ€ì´í‹€ ê²°ì •
        specialty_title = LevelCalculator.get_specialty_title(stats)

        # í™œë™ëŸ‰ ë°ì´í„°
        total_commits = metrics.stats.get("commits", {}).get("total", 0)
        total_prs = metrics.stats.get("pull_requests", {}).get("total", 0)

        # ë±ƒì§€ ìƒì„±
        badges = LevelCalculator.get_badges_from_stats(
            stats,
            total_commits=total_commits,
            total_prs=total_prs,
            total_repos=0  # ì¼ë°˜ ë³´ê³ ì„œëŠ” ë‹¨ì¼ ì €ì¥ì†Œ
        )

        # ì €ì¥ì†Œ íŠ¹í™” ë±ƒì§€ ì¶”ê°€
        if stats.get("growth", 0) >= 80:
            # "ğŸš€ ê¸‰ì„±ì¥ ê°œë°œì"ë¥¼ "ğŸš€ ê¸‰ì„±ì¥ ì €ì¥ì†Œ"ë¡œ êµì²´
            badges = [b.replace("ê¸‰ì„±ì¥ ê°œë°œì", "ê¸‰ì„±ì¥ ì €ì¥ì†Œ") for b in badges]

        # GameRendererë¡œ ìºë¦­í„° ìŠ¤íƒ¯ ë Œë”ë§
        lines.append("## ğŸ® ì €ì¥ì†Œ ìºë¦­í„° ìŠ¤íƒ¯")
        lines.append("")
        lines.append("> ì €ì¥ì†Œì˜ í™œë™ì„ RPG ìºë¦­í„° ìŠ¤íƒ¯ìœ¼ë¡œ ì‹œê°í™”")
        lines.append("")

        character_lines = GameRenderer.render_character_stats(
            level=tier,
            title=title,
            rank_emoji=rank_emoji,
            specialty_title=specialty_title,
            stats=stats,
            experience_data={},  # ê²½í—˜ì¹˜ ë°ì´í„° ì—†ìŒ
            badges=badges,
            use_tier_system=True  # í‹°ì–´ ì‹œìŠ¤í…œ ì‚¬ìš©
        )

        lines.extend(character_lines)
        lines.append("---")
        lines.append("")
        return lines

    def _build_detailed_feedback_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build detailed feedback section."""
        if not metrics.detailed_feedback:
            return []

        feedback = metrics.detailed_feedback

        # Check if there's any actual feedback content
        has_content = any([
            feedback.commit_feedback,
            feedback.pr_title_feedback,
            feedback.review_tone_feedback,
            feedback.issue_feedback
        ])

        # If no feedback content exists, don't create the section
        if not has_content:
            return []

        lines = ["## ğŸ’¡ ì½”ë”© ìŠµê´€ í‰ê°€ ë° ìŠ¤í‚¬ í–¥ìƒ ê°€ì´ë“œ", ""]
        lines.append("> ì»¤ë°‹ ë©”ì‹œì§€, PR ì œëª©, ë¦¬ë·° í†¤, ì´ìŠˆ ì‘ì„± ë“± ì½”ë”© ìŠµê´€ì„ ë¶„ì„í•˜ê³  ê°œì„  ë°©í–¥ì„ ì œì‹œí•©ë‹ˆë‹¤")
        lines.append("")

        # Commit message feedback
        if feedback.commit_feedback:
            lines.extend(self._build_commit_feedback(feedback.commit_feedback))

        # PR title feedback
        if feedback.pr_title_feedback:
            lines.extend(self._build_pr_title_feedback(feedback.pr_title_feedback))

        # Review tone feedback
        if feedback.review_tone_feedback:
            lines.extend(self._build_review_tone_feedback(feedback.review_tone_feedback))

        # Issue feedback
        if feedback.issue_feedback:
            lines.extend(self._build_issue_feedback(feedback.issue_feedback))

        lines.append("---")
        lines.append("")
        return lines

    def _build_feedback_section(
        self,
        title: str,
        feedback_data: FeedbackData,
        stats_config: Dict[str, str],
        example_formatter: Optional[Callable[[Any], str]] = None,
        examples_poor_attr: str = "examples_poor"
    ) -> List[str]:
        """Build a feedback subsection with a common structure.

        Args:
            title: Section title (e.g., "### ğŸ“ ì»¤ë°‹ ë©”ì‹œì§€ í’ˆì§ˆ")
            feedback_data: Feedback data object with stats and examples
            stats_config: Dictionary mapping stat names to labels
                - 'total': tuple of (attribute_name, label, unit)
                - 'good': tuple of (attribute_name, label, unit)
                - 'poor': tuple of (attribute_name, label, unit)
                - additional stats as needed
            example_formatter: Optional function to format examples
            examples_poor_attr: Attribute name for poor examples (default: "examples_poor")

        Returns:
            List of markdown lines
        """
        lines = [title, ""]

        # Build summary statistics as a table
        total_attr, total_label, unit = stats_config.get('total', (None, None, 'ê°œ'))
        good_attr, good_label, _ = stats_config.get('good', (None, None, 'ê°œ'))
        poor_attr, poor_label, _ = stats_config.get('poor', (None, None, 'ê°œ'))

        total_value = getattr(feedback_data, total_attr, 0) if total_attr else 0
        good_value = getattr(feedback_data, good_attr, 0) if good_attr else 0
        poor_value = getattr(feedback_data, poor_attr, 0) if poor_attr else 0

        lines.append("| ì§€í‘œ | ê°’ |")
        lines.append("|------|-----|")

        if total_value > 0:
            good_pct = (good_value / total_value) * 100
            lines.append(f"| {total_label} | {total_value:,}{unit} |")
            lines.append(f"| {good_label} | {good_value:,}{unit} ({good_pct:.1f}%) |")
            lines.append(f"| {poor_label} | {poor_value:,}{unit} |")

            # Add additional stats if configured
            for key, (attr, label, stat_unit) in stats_config.items():
                if key not in ('total', 'good', 'poor'):
                    value = getattr(feedback_data, attr, 0)
                    lines.append(f"| {label} | {value:,}{stat_unit} |")
        else:
            lines.append(f"| {total_label} | {total_value} |")
            lines.append(f"| {good_label} | {good_value} |")
            lines.append(f"| {poor_label} | {poor_value} |")

            # Add additional stats if configured
            for key, (attr, label, stat_unit) in stats_config.items():
                if key not in ('total', 'good', 'poor'):
                    value = getattr(feedback_data, attr, 0)
                    lines.append(f"| {label} | {value} |")
        lines.append("")

        # Suggestions section
        if hasattr(feedback_data, 'suggestions') and feedback_data.suggestions:
            lines.append("#### ğŸ’¡ ê°œì„  ì œì•ˆ")
            lines.append("")
            lines.append("| # | ì œì•ˆ |")
            lines.append("|---|------|")
            for i, suggestion in enumerate(feedback_data.suggestions, 1):
                lines.append(f"| {i} | {suggestion} |")
            lines.append("")

        # Good examples section
        if hasattr(feedback_data, 'examples_good') and feedback_data.examples_good:
            lines.append("#### âœ… ì¢‹ì€ ì˜ˆì‹œ")
            lines.append("")
            lines.append("| ì˜ˆì‹œ |")
            lines.append("|------|")
            for example in feedback_data.examples_good[:DISPLAY_LIMITS['feedback_examples']]:
                if example_formatter:
                    lines.append(f"| {example_formatter(example)} |")
                elif isinstance(example, dict):
                    lines.append(f"| {example} |")
                else:
                    lines.append(f"| {example} |")
            lines.append("")

        # Poor/improve examples section
        poor_examples = getattr(feedback_data, examples_poor_attr, None)
        if poor_examples:
            lines.append("#### âš ï¸ ê°œì„ ì´ í•„ìš”í•œ ì˜ˆì‹œ")
            lines.append("")
            lines.append("| ì˜ˆì‹œ |")
            lines.append("|------|")
            for example in poor_examples[:DISPLAY_LIMITS['feedback_examples']]:
                if example_formatter:
                    lines.append(f"| {example_formatter(example)} |")
                elif isinstance(example, dict):
                    lines.append(f"| {example} |")
                else:
                    lines.append(f"| {example} |")
            lines.append("")

        return lines

    def _build_feedback_table(
        self,
        title: str,
        feedback_data,
        good_category: str,
        poor_category: str,
        fallback_good_msg: str,
        fallback_poor_msg: str,
        evidence_formatter,
        link_formatter,
    ) -> List[str]:
        """Build a common feedback table format (HTML version).

        Args:
            title: Section title
            feedback_data: Feedback data object
            good_category: Category label for good examples
            poor_category: Category label for poor examples
            fallback_good_msg: Fallback message for non-dict good examples
            fallback_poor_msg: Fallback message for non-dict poor examples
            evidence_formatter: Function to format evidence from example dict
            link_formatter: Function to format link from example dict

        Returns:
            List of markdown lines
        """
        lines = [title, ""]

        # Build table rows
        headers = ["ì¥ì  í˜¹ì€ ê°œì„ ì /ë³´ì™„ì ", "ê·¼ê±° (ì½”ë“œ, ë©”ì„¸ì§€ ë“±)", "ë§í¬"]
        rows = []

        # Add good examples as strengths (ì¥ì )
        if hasattr(feedback_data, 'examples_good') and feedback_data.examples_good:
            for example in feedback_data.examples_good[:DISPLAY_LIMITS['feedback_examples']]:
                if isinstance(example, dict):
                    category = f"<strong>ì¥ì </strong>: {good_category}"
                    evidence = evidence_formatter(example)
                    link = link_formatter(example)
                    rows.append([category, evidence, link])
                else:
                    example_escaped = _escape_table_cell(str(example))
                    rows.append([f"<strong>ì¥ì </strong>: {fallback_good_msg}", example_escaped, "-"])

        # Add poor examples as improvement areas (ê°œì„ ì )
        if hasattr(feedback_data, 'examples_poor') and feedback_data.examples_poor:
            for example in feedback_data.examples_poor[:DISPLAY_LIMITS['feedback_examples']]:
                if isinstance(example, dict):
                    category = f"<strong>ê°œì„ ì </strong>: {poor_category}"
                    evidence = evidence_formatter(example)
                    link = link_formatter(example)
                    rows.append([category, evidence, link])
                else:
                    example_escaped = _escape_table_cell(str(example))
                    rows.append([f"<strong>ê°œì„ ì </strong>: {fallback_poor_msg}", example_escaped, "-"])

        # Handle improve examples (for review tone feedback)
        if hasattr(feedback_data, 'examples_improve') and feedback_data.examples_improve:
            for example in feedback_data.examples_improve[:DISPLAY_LIMITS['feedback_examples']]:
                if isinstance(example, dict):
                    category = f"<strong>ê°œì„ ì </strong>: {poor_category}"
                    evidence = evidence_formatter(example)
                    link = link_formatter(example)
                    rows.append([category, evidence, link])
                else:
                    example_escaped = _escape_table_cell(str(example))
                    rows.append([f"<strong>ê°œì„ ì </strong>: {fallback_poor_msg}", example_escaped, "-"])

        # Add suggestions as additional improvement areas
        if hasattr(feedback_data, 'suggestions') and feedback_data.suggestions:
            for suggestion in feedback_data.suggestions[:3]:  # Limit to 3 suggestions
                suggestion_escaped = _escape_table_cell(suggestion)
                rows.append([f"<strong>ë³´ì™„ì </strong>: {suggestion_escaped}", "ì „ë°˜ì ì¸ íŒ¨í„´ ë¶„ì„ ê²°ê³¼", "-"])

        # Render as HTML table
        lines.extend(GameRenderer.render_html_table(
            headers=headers,
            rows=rows,
            title="",
            description="",
            striped=True
        ))

        return lines

    def _build_commit_feedback(self, commit_feedback) -> List[str]:
        """Build commit feedback subsection with new table format."""
        def format_commit_evidence(example):
            message = example.get('message', '')
            reason = example.get('reason', '')
            suggestion = example.get('suggestion', '')

            # Escape special characters to prevent table breakage
            message_escaped = _escape_table_cell(message)
            reason_escaped = _escape_table_cell(reason)
            suggestion_escaped = _escape_table_cell(suggestion)

            # Build detailed evidence with message, reason, and suggestion
            parts = [f"**ë©”ì‹œì§€**: `{message_escaped}`"]
            if reason_escaped:
                parts.append(f"<br>**ê·¼ê±°**: {reason_escaped}")
            if suggestion_escaped:
                parts.append(f"<br>**ê°œì„ ë°©ì•ˆ**: {suggestion_escaped}")

            return "<br>".join(parts)

        def format_commit_link(example):
            if example.get('url'):
                sha_short = example.get('sha', '')[:7]
                url = _escape_table_cell(example.get('url', ''))
                return f"[{sha_short}]({url})"
            return example.get('sha', '')[:7]

        return self._build_feedback_table(
            title="### ğŸ“ ì»¤ë°‹ ë©”ì‹œì§€ í’ˆì§ˆ",
            feedback_data=commit_feedback,
            good_category="ëª…í™•í•˜ê³  ì˜ë¯¸ìˆëŠ” ì»¤ë°‹ ë©”ì‹œì§€",
            poor_category="ì»¤ë°‹ ë©”ì‹œì§€ êµ¬ì²´í™” í•„ìš”",
            fallback_good_msg="ì¢‹ì€ ì»¤ë°‹ ë©”ì‹œì§€",
            fallback_poor_msg="ì»¤ë°‹ ë©”ì‹œì§€ ê°œì„  í•„ìš”",
            evidence_formatter=format_commit_evidence,
            link_formatter=format_commit_link,
        )

    def _build_pr_title_feedback(self, pr_title_feedback) -> List[str]:
        """Build PR title feedback subsection with new table format."""
        def format_pr_evidence(example):
            title = example.get('title', '')
            reason = example.get('reason', '')
            suggestion = example.get('suggestion', '')

            # Escape special characters to prevent table breakage
            title_escaped = _escape_table_cell(title)
            reason_escaped = _escape_table_cell(reason)
            suggestion_escaped = _escape_table_cell(suggestion)

            # Build detailed evidence with title and reason
            parts = [f"**ì œëª©**: `{title_escaped}`"]
            if reason_escaped:
                parts.append(f"<br>**ê·¼ê±°**: {reason_escaped}")
            if suggestion_escaped:
                parts.append(f"<br>**ê°œì„ ë°©ì•ˆ**: {suggestion_escaped}")

            return "<br>".join(parts)

        def format_pr_link(example):
            url = example.get('url', '')
            number = example.get('number', '')

            if url:
                url_escaped = _escape_table_cell(url)
                return f"[#{number}]({url_escaped})" if number else f"[PR]({url_escaped})"
            elif number:
                # Fallback: construct URL if not provided
                return f"[#{number}]({self.web_url}/{self._get_repo_from_context()}/pull/{number})"
            return "-"

        return self._build_feedback_table(
            title="### ğŸ”€ PR ì œëª© í’ˆì§ˆ",
            feedback_data=pr_title_feedback,
            good_category="ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ PR ì œëª©",
            poor_category="PR ì œëª© êµ¬ì²´í™” í•„ìš”",
            fallback_good_msg="ì¢‹ì€ PR ì œëª©",
            fallback_poor_msg="PR ì œëª© ê°œì„  í•„ìš”",
            evidence_formatter=format_pr_evidence,
            link_formatter=format_pr_link,
        )

    def _build_review_tone_feedback(self, review_tone_feedback) -> List[str]:
        """Build review tone feedback subsection with new table format."""
        def format_review_evidence(example):
            # Get the comment/body
            comment = example.get('comment', example.get('body', ''))
            strengths = example.get('strengths', [])
            issues = example.get('issues', [])
            improved_version = example.get('improved_version', '')

            # Escape special characters
            comment_escaped = _escape_table_cell(comment[:150] + "..." if len(comment) > 150 else comment)

            # Build detailed evidence
            parts = [f"**ë¦¬ë·° ì½”ë©˜íŠ¸**: `{comment_escaped}`"]

            # Add strengths for good examples
            if strengths:
                strengths_text = "<br>".join(f"â€¢ {_escape_table_cell(s)}" for s in strengths[:3])
                parts.append(f"<br>**ì¥ì **: <br>{strengths_text}")

            # Add issues for examples that need improvement
            if issues:
                issues_text = "<br>".join(f"â€¢ {_escape_table_cell(i)}" for i in issues[:3])
                parts.append(f"<br>**ë¬¸ì œì **: <br>{issues_text}")

            # Add improved version if available
            if improved_version:
                improved_escaped = _escape_table_cell(improved_version[:150] + "..." if len(improved_version) > 150 else improved_version)
                parts.append(f"<br>**ê°œì„  ì˜ˆì‹œ**: `{improved_escaped}`")

            return "<br>".join(parts)

        def format_review_link(example):
            url = example.get('url', '')
            pr_number = example.get('pr_number', '')

            if url:
                url_escaped = _escape_table_cell(url)
                return f"[PR #{pr_number}]({url_escaped})"
            elif pr_number:
                return f"PR #{pr_number}"
            return "-"

        return self._build_feedback_table(
            title="### ğŸ‘€ ë¦¬ë·° í†¤ ë¶„ì„",
            feedback_data=review_tone_feedback,
            good_category="ê±´ì„¤ì ì´ê³  ë„ì›€ì´ ë˜ëŠ” ë¦¬ë·°",
            poor_category="ë¦¬ë·° í†¤ ê°œì„  í•„ìš”",
            fallback_good_msg="ì¢‹ì€ ë¦¬ë·° í†¤",
            fallback_poor_msg="ë¦¬ë·° í†¤ ê°œì„  í•„ìš”",
            evidence_formatter=format_review_evidence,
            link_formatter=format_review_link,
        )

    def _build_issue_feedback(self, issue_feedback) -> List[str]:
        """Build issue feedback subsection with new table format."""
        def format_issue_evidence(example):
            title = _escape_table_cell(example.get('title', ''))
            return f"#{example.get('number', '')}: `{title}`"

        def format_issue_link(example):
            if example.get('url'):
                url = _escape_table_cell(example.get('url', ''))
                return f"[ì´ìŠˆ ë³´ê¸°]({url})"
            return "-"

        return self._build_feedback_table(
            title="### ğŸ› ì´ìŠˆ í’ˆì§ˆ",
            feedback_data=issue_feedback,
            good_category="ëª…í™•í•˜ê³  ìƒì„¸í•œ ì´ìŠˆ ì‘ì„±",
            poor_category="ì´ìŠˆ ì„¤ëª… ë³´ì™„ í•„ìš”",
            fallback_good_msg="ì¢‹ì€ ì´ìŠˆ ì‘ì„±",
            fallback_poor_msg="ì´ìŠˆ ì„¤ëª… ê°œì„  í•„ìš”",
            evidence_formatter=format_issue_evidence,
            link_formatter=format_issue_link,
        )

    def _build_monthly_trends_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build monthly trends section (HTML version with charts)."""
        if not metrics.monthly_trends:
            return []

        lines = ["## ğŸ“ˆ Monthly Trends", ""]
        lines.append("> ì›”ë³„ í™œë™ íŒ¨í„´ê³¼ íŠ¸ë Œë“œ ë¶„ì„")
        lines.append("")

        # Insights as info box
        if metrics.monthly_insights and metrics.monthly_insights.insights:
            insights_text = "\n".join(f"{i}. {insight}" for i, insight in enumerate(metrics.monthly_insights.insights, 1))
            lines.extend(GameRenderer.render_info_box(
                title="ì£¼ìš” ì¸ì‚¬ì´íŠ¸",
                content=insights_text,
                emoji="ğŸ’¡",
                bg_color="#fffbeb",
                border_color="#f59e0b"
            ))

        # Render activity chart
        monthly_chart_data = []
        for trend in metrics.monthly_trends:
            total_activity = trend.commits + trend.pull_requests + trend.reviews + trend.issues
            monthly_chart_data.append({
                "month": trend.month,
                "count": total_activity
            })

        lines.extend(GameRenderer.render_monthly_chart(
            monthly_data=monthly_chart_data,
            title="ì›”ë³„ ì´ í™œë™ëŸ‰",
            value_key="count",
            label_key="month"
        ))

        # Render detailed data table
        lines.append("### ğŸ“Š ì›”ë³„ ìƒì„¸ ë°ì´í„°")
        lines.append("")

        headers = ["ì›”", "ì»¤ë°‹", "PR", "ë¦¬ë·°", "ì´ìŠˆ", "ì´ í™œë™"]
        rows = []
        for trend in metrics.monthly_trends:
            total_activity = trend.commits + trend.pull_requests + trend.reviews + trend.issues
            rows.append([
                trend.month,
                str(trend.commits),
                str(trend.pull_requests),
                str(trend.reviews),
                str(trend.issues),
                f"<strong>{total_activity}</strong>"
            ])

        lines.extend(GameRenderer.render_html_table(
            headers=headers,
            rows=rows,
            title="",
            description="",
            striped=True
        ))

        lines.append("---")
        lines.append("")
        return lines

    def _build_tech_stack_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build tech stack section (HTML version)."""
        if not metrics.tech_stack:
            return []

        # Check if there are any languages to display
        if not metrics.tech_stack.top_languages:
            return []

        lines = ["## ğŸ’» Tech Stack Analysis", ""]
        lines.append("> ì‚¬ìš©í•œ ê¸°ìˆ ê³¼ ì–¸ì–´ ë¶„í¬")
        lines.append("")
        lines.append(f"**ë‹¤ì–‘ì„± ì ìˆ˜**: {metrics.tech_stack.diversity_score:.2f} (0-1 ì²™ë„)")
        lines.append("")

        # Build table data
        headers = ["ìˆœìœ„", "ì–¸ì–´", "íŒŒì¼ ìˆ˜"]
        rows = []
        for i, lang in enumerate(metrics.tech_stack.top_languages[:DISPLAY_LIMITS['top_languages']], 1):
            count = metrics.tech_stack.languages.get(lang, 0)
            rows.append([str(i), lang, f"{count:,}"])

        # Render as HTML table
        lines.extend(GameRenderer.render_html_table(
            headers=headers,
            rows=rows,
            title="",
            description="",
            striped=True
        ))

        lines.append("---")
        lines.append("")
        return lines

    def _build_collaboration_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build PR activity summary section (HTML version)."""
        if not metrics.collaboration:
            return []

        lines = ["## ğŸ¤ PR í™œë™ ìš”ì•½", ""]
        lines.append("> í•¨ê»˜ ì„±ì¥í•œ ë™ë£Œë“¤ê³¼ì˜ í˜‘ì—…")
        lines.append("")

        # Summary table
        headers = ["í•­ëª©", "ê°’"]
        rows = [
            ["ë°›ì€ ë¦¬ë·° ìˆ˜", f"{metrics.collaboration.review_received_count:,}ê±´"],
            ["í˜‘ì—…í•œ ì‚¬ëŒ ìˆ˜", f"{metrics.collaboration.unique_collaborators:,}ëª…"]
        ]

        lines.extend(GameRenderer.render_html_table(
            headers=headers,
            rows=rows,
            title="",
            description="",
            striped=True
        ))

        if metrics.collaboration.top_reviewers:
            lines.append("### ğŸŒŸ ì£¼ìš” ë¦¬ë·°ì–´")
            lines.append("")

            # Top reviewers table
            headers = ["ìˆœìœ„", "ë¦¬ë·°ì–´", "ë¦¬ë·° íšŸìˆ˜"]
            rows = []
            for i, reviewer in enumerate(metrics.collaboration.top_reviewers, 1):
                count = metrics.collaboration.pr_reviewers.get(reviewer, 0)
                rows.append([str(i), f"@{reviewer}", f"{count:,}íšŒ"])

            lines.extend(GameRenderer.render_html_table(
                headers=headers,
                rows=rows,
                title="",
                description="",
                striped=True
            ))

        lines.append("---")
        lines.append("")
        return lines

    # Evidence Links section removed - links are already embedded in each section
    # where they are relevant (Detailed Feedback, Spotlight Examples, etc.)

    # Removed _build_executive_summary_subsection - already covered in main Executive Summary
    # Removed _build_key_wins_subsection - already covered in Growth Highlights

    def _build_time_comparisons_subsection(self, retro) -> List[str]:
        """Build time comparisons subsection of retrospective (HTML version)."""
        lines = []
        if not retro.time_comparisons:
            return lines

        lines.append("### ğŸ“Š ê¸°ê°„ ë¹„êµ ë¶„ì„")
        lines.append("")
        lines.append("> ì „ë°˜ê¸°ì™€ í›„ë°˜ê¸°ì˜ ë³€í™” ì¶”ì´ë¥¼ ë¹„êµí•©ë‹ˆë‹¤")
        lines.append("")

        # Build table data
        headers = ["ì§€í‘œ", "ì „ë°˜ê¸°", "í›„ë°˜ê¸°", "ë³€í™”ëŸ‰", "ë³€í™”ìœ¨", "ì˜ë¯¸"]
        rows = []
        for tc in retro.time_comparisons:
            direction_emoji = {"increasing": "ğŸ“ˆ", "decreasing": "ğŸ“‰"}.get(tc.direction, "â¡ï¸")
            significance_text = {
                "major": "í° ë³€í™”",
                "moderate": "ì¤‘ê°„ ë³€í™”",
                "minor": "ì‘ì€ ë³€í™”"
            }.get(tc.significance, tc.significance)

            rows.append([
                tc.metric_name,
                f"{tc.previous_value:.1f}",
                f"{tc.current_value:.1f}",
                f"{tc.change_absolute:+.1f}",
                f"{tc.change_percentage:+.1f}%",
                f"{direction_emoji} {significance_text}"
            ])

        # Render as HTML table
        lines.extend(GameRenderer.render_html_table(
            headers=headers,
            rows=rows,
            title="",
            description="",
            striped=True
        ))

        return lines

    def _build_behavior_patterns_subsection(self, retro) -> List[str]:
        """Build behavior patterns subsection of retrospective (HTML version)."""
        lines = []
        if not retro.behavior_patterns:
            return lines

        lines.append("### ğŸ§  í–‰ë™ íŒ¨í„´ ë¶„ì„")
        lines.append("")
        lines.append("> ì‘ì—… íŒ¨í„´ê³¼ ìŠµê´€ì—ì„œ ë°œê²¬ëœ ì¸ì‚¬ì´íŠ¸")
        lines.append("")

        # Impact emoji mapping for better readability
        impact_emojis = {
            "positive": "âœ…",
            "negative": "âš ï¸",
        }

        # Build table data
        headers = ["ì˜í–¥", "íŒ¨í„´", "ì œì•ˆ"]
        rows = []
        for pattern in retro.behavior_patterns:
            impact_emoji = impact_emojis.get(pattern.impact, "â„¹ï¸")
            recommendation = pattern.recommendation if pattern.recommendation else "-"
            rows.append([impact_emoji, pattern.description, recommendation])

        # Render as HTML table
        lines.extend(GameRenderer.render_html_table(
            headers=headers,
            rows=rows,
            title="",
            description="",
            striped=True
        ))

        return lines

    def _build_learning_insights_subsection(self, retro) -> List[str]:
        """Build learning insights subsection of retrospective (HTML version)."""
        lines = []
        if not retro.learning_insights:
            return lines

        lines.append("### ğŸ“š í•™ìŠµ ë° ì„±ì¥ ë¶„ì„")
        lines.append("")
        lines.append("> ê¸°ìˆ  ì—­ëŸ‰ê³¼ í•™ìŠµ ê¶¤ì ì„ ë¶„ì„í•©ë‹ˆë‹¤")
        lines.append("")

        # Build table data
        headers = ["ë¶„ì•¼", "ê¸°ìˆ ", "ì „ë¬¸ì„±", "ì„±ì¥ ì§€í‘œ"]
        rows = []

        for learning in retro.learning_insights:
            expertise_emoji = {"expert": "ğŸ‘‘", "proficient": "â­", "developing": "ğŸŒ±", "exploring": "ğŸ”"}.get(
                learning.expertise_level, "ğŸ“–"
            )
            technologies = ', '.join(learning.technologies)
            growth_indicators = '<br>'.join(f"â€¢ {ind}" for ind in learning.growth_indicators[:DISPLAY_LIMITS['growth_indicators']]) if learning.growth_indicators else "-"

            rows.append([
                f"{expertise_emoji} {learning.domain}",
                technologies,
                learning.expertise_level,
                growth_indicators
            ])

        # Render as HTML table
        lines.extend(GameRenderer.render_html_table(
            headers=headers,
            rows=rows,
            title="",
            description="",
            striped=True
        ))

        return lines

    def _build_impact_assessments_subsection(self, retro) -> List[str]:
        """Build impact assessments subsection of retrospective (HTML version)."""
        lines = []
        if not retro.impact_assessments:
            return lines

        lines.append("### ğŸ’ ì˜í–¥ë„ í‰ê°€")
        lines.append("")
        lines.append("> ê¸°ì—¬ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ë° íŒ€ ì˜í–¥ì„ í‰ê°€í•©ë‹ˆë‹¤")
        lines.append("")

        # Build table data
        headers = ["ì¹´í…Œê³ ë¦¬", "ê¸°ì—¬ íšŸìˆ˜", "ì˜í–¥ë„", "ì„¤ëª…"]
        rows = []

        for impact in retro.impact_assessments:
            impact_emoji = {"high": "ğŸ”¥", "medium": "âœ¨", "low": "ğŸ’¡"}.get(impact.estimated_impact, "ğŸ“Š")
            rows.append([
                f"{impact_emoji} {impact.category}",
                f"{impact.contribution_count:,}ê±´",
                impact.estimated_impact,
                impact.impact_description
            ])

        # Render as HTML table
        lines.extend(GameRenderer.render_html_table(
            headers=headers,
            rows=rows,
            title="",
            description="",
            striped=True
        ))

        return lines

    def _build_collaboration_insights_subsection(self, retro) -> List[str]:
        """Build collaboration insights subsection of retrospective (HTML version)."""
        lines = []
        if not retro.collaboration_insights:
            return lines

        collab = retro.collaboration_insights
        lines.append("### ğŸ¤ í˜‘ì—… ì‹¬ì¸µ ë¶„ì„")
        lines.append("")
        lines.append(f"**í˜‘ì—… ê°•ë„:** {collab.collaboration_strength}")
        lines.append(f"**í˜‘ì—… í’ˆì§ˆ:** {collab.collaboration_quality}")
        lines.append("")

        if collab.key_partnerships:
            lines.append("**ì£¼ìš” í˜‘ì—… íŒŒíŠ¸ë„ˆ:**")
            lines.append("")

            # Build table data
            headers = ["í˜‘ì—…ì", "ë¦¬ë·° íšŸìˆ˜", "ê´€ê³„"]
            rows = []
            for person, count, rel_type in collab.key_partnerships:
                rows.append([f"@{person}", f"{count}íšŒ", rel_type])

            # Render as HTML table
            lines.extend(GameRenderer.render_html_table(
                headers=headers,
                rows=rows,
                title="",
                description="",
                striped=True
            ))

        if collab.mentorship_indicators:
            lines.append("**ë©˜í† ë§ í™œë™:**")
            for indicator in collab.mentorship_indicators:
                lines.append(f"- {indicator}")
            lines.append("")

        if collab.improvement_areas:
            lines.append("**ê°œì„  ì˜ì—­:**")
            for area in collab.improvement_areas:
                lines.append(f"- {area}")
            lines.append("")

        return lines

    def _build_balance_metrics_subsection(self, retro) -> List[str]:
        """Build balance metrics subsection of retrospective (HTML version)."""
        lines = []
        if not retro.balance_metrics:
            return lines

        balance = retro.balance_metrics
        lines.append("### âš–ï¸ ì—…ë¬´ ë°¸ëŸ°ìŠ¤ ë¶„ì„")
        lines.append("")

        risk_emoji = {"low": "âœ…", "moderate": "âš ï¸", "high": "ğŸš¨"}.get(balance.burnout_risk_level, "â“")

        # Main metrics table
        headers = ["ì§€í‘œ", "ê°’"]
        rows = [
            ["ë²ˆì•„ì›ƒ ìœ„í—˜ë„", f"{risk_emoji} {balance.burnout_risk_level}"],
            ["ì§€ì†ê°€ëŠ¥ì„± ì ìˆ˜", f"{balance.sustainability_score:.0f}/100"],
            ["í™œë™ ë³€ë™ì„±", f"{balance.activity_variance:.2f}"]
        ]

        lines.extend(GameRenderer.render_html_table(
            headers=headers,
            rows=rows,
            title="",
            description="",
            striped=True
        ))

        if balance.positive_patterns:
            lines.append("**ê¸ì •ì  íŒ¨í„´:**")
            lines.append("")

            headers = ["íŒ¨í„´"]
            rows = [[f"âœ… {pattern}"] for pattern in balance.positive_patterns]

            lines.extend(GameRenderer.render_html_table(
                headers=headers,
                rows=rows,
                title="",
                description="",
                striped=True
            ))

        if balance.burnout_indicators:
            lines.append("**ì£¼ì˜ ì‚¬í•­:**")
            lines.append("")

            headers = ["ì§€í‘œ"]
            rows = [[f"âš ï¸ {indicator}"] for indicator in balance.burnout_indicators]

            lines.extend(GameRenderer.render_html_table(
                headers=headers,
                rows=rows,
                title="",
                description="",
                striped=True
            ))

        if balance.health_recommendations:
            lines.append("**ê¶Œì¥ ì‚¬í•­:**")
            lines.append("")

            headers = ["ê¶Œì¥ì‚¬í•­"]
            rows = [[f"ğŸ’¡ {rec}"] for rec in balance.health_recommendations]

            lines.extend(GameRenderer.render_html_table(
                headers=headers,
                rows=rows,
                title="",
                description="",
                striped=True
            ))

        return lines

    def _build_code_health_subsection(self, retro) -> List[str]:
        """Build code health subsection of retrospective (HTML version)."""
        lines = []
        if not retro.code_health:
            return lines

        health = retro.code_health
        lines.append("### ğŸ¥ ì½”ë“œ ê±´ê°•ë„ ë¶„ì„")
        lines.append("")

        # Main metrics table
        headers = ["ì§€í‘œ", "ê°’"]
        rows = [
            ["ìœ ì§€ë³´ìˆ˜ ë¶€ë‹´", health.maintenance_burden],
            ["í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ì¶”ì„¸", health.test_coverage_trend]
        ]

        lines.extend(GameRenderer.render_html_table(
            headers=headers,
            rows=rows,
            title="",
            description="",
            striped=True
        ))

        if health.code_quality_trends:
            lines.append("**í’ˆì§ˆ íŠ¸ë Œë“œ:**")
            lines.append("")

            headers = ["íŠ¸ë Œë“œ"]
            rows = [[trend] for trend in health.code_quality_trends]

            lines.extend(GameRenderer.render_html_table(
                headers=headers,
                rows=rows,
                title="",
                description="",
                striped=True
            ))

        if health.quality_improvement_suggestions:
            lines.append("**ê°œì„  ì œì•ˆ:**")
            lines.append("")

            headers = ["ì œì•ˆ"]
            rows = [[f"ğŸ’¡ {suggestion}"] for suggestion in health.quality_improvement_suggestions]

            lines.extend(GameRenderer.render_html_table(
                headers=headers,
                rows=rows,
                title="",
                description="",
                striped=True
            ))

        return lines

    def _build_actionable_insights_subsection(self, retro) -> List[str]:
        """Build actionable insights subsection of retrospective."""
        lines = []
        if retro.actionable_insights:
            lines.append("### ğŸ¯ ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸")
            lines.append("")
            lines.append("> êµ¬ì²´ì ì´ê³  ì¸¡ì • ê°€ëŠ¥í•œ ê°œì„  ë°©ì•ˆ")
            lines.append("")

            # Group by priority
            high_priority = [ai for ai in retro.actionable_insights if ai.priority == "high"]
            medium_priority = [ai for ai in retro.actionable_insights if ai.priority == "medium"]

            if high_priority:
                lines.append("#### ğŸ”´ ë†’ì€ ìš°ì„ ìˆœìœ„")
                lines.append("")
                for insight in high_priority:
                    lines.append(f"**{insight.title}**")
                    lines.append("")
                    lines.append(f"*{insight.description}*")
                    lines.append("")
                    lines.append(f"**ì™œ ì¤‘ìš”í•œê°€:** {insight.why_it_matters}")
                    lines.append("")
                    lines.append("**êµ¬ì²´ì  í–‰ë™:**")
                    for action in insight.concrete_actions:
                        lines.append(f"1. {action}")
                    lines.append("")
                    lines.append(f"**ê¸°ëŒ€ íš¨ê³¼:** {insight.expected_outcome}")
                    lines.append(f"**ì¸¡ì • ë°©ë²•:** {insight.measurement}")
                    lines.append("")
                    lines.append("---")
                    lines.append("")

            if medium_priority:
                lines.append("#### ğŸŸ¡ ì¤‘ê°„ ìš°ì„ ìˆœìœ„")
                lines.append("")
                for insight in medium_priority[:DISPLAY_LIMITS['medium_priority_insights']]:
                    lines.append(f"**{insight.title}**")
                    lines.append("")
                    lines.append(f"*{insight.description}*")
                    lines.append("")
                    lines.append("**êµ¬ì²´ì  í–‰ë™:**")
                    for action in insight.concrete_actions:
                        lines.append(f"- {action}")
                    lines.append("")
            lines.append("")
        return lines

    def _build_areas_for_growth_subsection(self, retro) -> List[str]:
        """Build areas for growth subsection of retrospective (HTML version)."""
        lines = []
        if not retro.areas_for_growth:
            return lines

        lines.append("### ğŸŒ± ì„±ì¥ ê¸°íšŒ")
        lines.append("")
        lines.append("> ë‹¤ìŒ ë‹¨ê³„ë¡œ ë‚˜ì•„ê°€ê¸° ìœ„í•œ ì˜ì—­")
        lines.append("")

        # Build table data
        headers = ["#", "ì„±ì¥ ê¸°íšŒ"]
        rows = [[str(i), area] for i, area in enumerate(retro.areas_for_growth, 1)]

        # Render as HTML table
        lines.extend(GameRenderer.render_html_table(
            headers=headers,
            rows=rows,
            title="",
            description="",
            striped=True
        ))

        return lines

    def _build_narrative_subsection(self, retro) -> List[str]:
        """Build narrative subsection of retrospective."""
        lines = []
        if retro.retrospective_narrative:
            lines.append("### ğŸ“– íšŒê³  ìŠ¤í† ë¦¬")
            lines.append("")
            lines.append("> ë‹¹ì‹ ì˜ ì—¬ì •ì„ ì´ì•¼ê¸°ë¡œ í’€ì–´ëƒ…ë‹ˆë‹¤")
            lines.append("")
            for paragraph in retro.retrospective_narrative:
                lines.append(paragraph)
                lines.append("")
        return lines

    def _build_retrospective_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build comprehensive retrospective analysis section.

        Refactored to use smaller, focused subsection methods for better maintainability.
        """
        if not metrics.retrospective:
            return []

        retro = metrics.retrospective

        # Build all subsections using dedicated methods
        # Note: executive_summary and key_wins removed to avoid duplication with main sections
        subsections = []
        subsections.extend(self._build_time_comparisons_subsection(retro))
        subsections.extend(self._build_behavior_patterns_subsection(retro))
        subsections.extend(self._build_learning_insights_subsection(retro))
        subsections.extend(self._build_impact_assessments_subsection(retro))
        subsections.extend(self._build_collaboration_insights_subsection(retro))
        subsections.extend(self._build_balance_metrics_subsection(retro))
        subsections.extend(self._build_code_health_subsection(retro))
        subsections.extend(self._build_actionable_insights_subsection(retro))
        subsections.extend(self._build_areas_for_growth_subsection(retro))
        subsections.extend(self._build_narrative_subsection(retro))

        # If no subsections have content, don't create the section
        if not subsections:
            return []

        lines = ["## ğŸ” Deep Retrospective Analysis", ""]
        lines.append("> ë°ì´í„° ê¸°ë°˜ì˜ ì‹¬ì¸µì ì¸ íšŒê³ ì™€ ì¸ì‚¬ì´íŠ¸")
        lines.append("")
        lines.extend(subsections)
        lines.append("---")
        lines.append("")
        return lines

    def generate_markdown(self, metrics: MetricSnapshot) -> Path:
        """Create a markdown report for the provided metrics.

        Improved report structure for better user experience:
        1. Header with basic info
        2. Summary Overview Table - Quick glance at strengths, improvements, and growth
        3. Character Stats - Gamified visualization of repository metrics
        4. Awards Cabinet to celebrate achievements
        5. Growth Highlights to show progress
        6. Monthly Trends for pattern analysis
        7. Detailed Feedback for actionable insights
        8. Deep Retrospective for comprehensive analysis
        9. Spotlight Examples for concrete evidence
        10. Tech Stack to show technical breadth
        """
        self.ensure_structure()
        report_path = self.output_dir / "report.md"

        # Store repo for use in link generation
        self._current_repo = metrics.repo

        console.log("Writing markdown report", f"path={report_path}")

        # Add font styles at the beginning
        font_styles = [
            '<style>',
            '  @import url("https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@300;400;500;700&display=swap");',
            '  * {',
            '    font-family: "Noto Sans KR", -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;',
            '  }',
            '</style>',
            ''
        ]

        # Build all sections in improved order
        sections = [
            # 1. Header with basic info
            self._build_header_and_summary(metrics),
            # 2. Summary Overview Table - NEW! Quick overview
            self._build_summary_overview_table(metrics),
            # 3. Character Stats - NEW! Gamified visualization
            self._render_repo_character_stats(metrics),
            # 4. Skill Tree - NEW! Game-style skill representation
            self._build_skill_tree_section(metrics),
            # 5. Awards Cabinet - Celebrate achievements first!
            self._build_awards_section(metrics),
            # 6. Growth Highlights - Show the story
            self._build_highlights_section(metrics),
            # 7. Monthly Trends - Show patterns
            self._build_monthly_trends_section(metrics),
            # 8. Detailed Feedback - Actionable insights
            self._build_detailed_feedback_section(metrics),
            # 9. Deep Retrospective - Comprehensive analysis
            self._build_retrospective_section(metrics),
            # 10. Spotlight Examples - Concrete evidence
            self._build_spotlight_section(metrics),
            # 11. Tech Stack - Technical breadth
            self._build_tech_stack_section(metrics),
            # Evidence Links section removed - links already embedded in relevant sections
        ]

        # Combine all sections
        all_lines = []
        all_lines.extend(font_styles)  # Add font styles first
        for section in sections:
            all_lines.extend(section)

        try:
            report_path.write_text("\n".join(all_lines), encoding="utf-8")
        except (IOError, OSError) as e:
            raise IOError(f"Failed to write report to {report_path}: {e}") from e

        return report_path

    def generate_markdown_content(self, metrics: MetricSnapshot) -> str:
        """Generate markdown report content without writing to file.

        This is useful for in-memory report generation without creating files.

        Args:
            metrics: Metrics snapshot to generate report from

        Returns:
            Markdown report content as a string
        """
        # Store repo for use in link generation
        self._current_repo = metrics.repo

        # Add font styles at the beginning
        font_styles = [
            '<style>',
            '  @import url("https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@300;400;500;700&display=swap");',
            '  * {',
            '    font-family: "Noto Sans KR", -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;',
            '  }',
            '</style>',
            ''
        ]

        # Build all sections in improved order (same as generate_markdown)
        sections = [
            # 1. Header with basic info
            self._build_header_and_summary(metrics),
            # 2. Summary Overview Table - NEW! Quick overview
            self._build_summary_overview_table(metrics),
            # 3. Character Stats - NEW! Gamified visualization
            self._render_repo_character_stats(metrics),
            # 4. Skill Tree - NEW! Game-style skill representation
            self._build_skill_tree_section(metrics),
            # 5. Awards Cabinet - Celebrate achievements first!
            self._build_awards_section(metrics),
            # 6. Growth Highlights - Show the story
            self._build_highlights_section(metrics),
            # 7. Monthly Trends - Show patterns
            self._build_monthly_trends_section(metrics),
            # 8. Detailed Feedback - Actionable insights
            self._build_detailed_feedback_section(metrics),
            # 9. Deep Retrospective - Comprehensive analysis
            self._build_retrospective_section(metrics),
            # 10. Spotlight Examples - Concrete evidence
            self._build_spotlight_section(metrics),
            # 11. Tech Stack - Technical breadth
            self._build_tech_stack_section(metrics),
            # Evidence Links section removed - links already embedded in relevant sections
        ]

        # Combine all sections
        all_lines = []
        all_lines.extend(font_styles)  # Add font styles first
        for section in sections:
            all_lines.extend(section)

        return "\n".join(all_lines)

