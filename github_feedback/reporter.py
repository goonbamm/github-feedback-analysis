"""Report generation for GitHub feedback analysis."""

from __future__ import annotations

from dataclasses import dataclass
from html import escape
from pathlib import Path
from typing import Any, Callable, Dict, Iterable, List, Optional, Tuple

from .console import Console
from .constants import AWARD_CATEGORIES, AWARD_KEYWORDS, COLLECTION_LIMITS, DISPLAY_LIMITS
from .models import MetricSnapshot, PromptRequest

console = Console()


def _format_metric_value(value: object) -> str:
    """Format numeric values with separators while keeping strings intact."""

    if isinstance(value, bool):
        return str(value)
    if isinstance(value, int):
        return f"{value:,}"
    if isinstance(value, float):
        return f"{value:,.2f}"
    return str(value)


@dataclass(slots=True)
class Reporter:
    """Create human-readable artefacts from metrics."""

    output_dir: Path = Path("reports")

    def ensure_structure(self) -> None:
        self.output_dir.mkdir(parents=True, exist_ok=True)
        (self.output_dir / "charts").mkdir(parents=True, exist_ok=True)

    def _categorize_awards(self, awards: List[str]) -> dict:
        """Categorize awards by type for better organization."""
        # Initialize categories from constants
        categories = {label: [] for label in AWARD_CATEGORIES.values()}

        for award in awards:
            categorized = False
            # Check each category's keywords
            for category_key, keywords in AWARD_KEYWORDS.items():
                if any(keyword in award for keyword in keywords):
                    category_label = AWARD_CATEGORIES[category_key]
                    categories[category_label].append(award)
                    categorized = True
                    break

            # Default category if no keywords match
            if not categorized:
                categories[AWARD_CATEGORIES['basic']].append(award)

        # Remove empty categories
        return {k: v for k, v in categories.items() if v}


    def _build_prompt_context(self, metrics: MetricSnapshot) -> str:
        """Create a reusable context block describing the metrics."""

        lines: List[str] = []
        period_label = (
            f"ì§€ë‚œ {metrics.months}ê°œì›”"
            if metrics.months and metrics.months < 12
            else "ì˜¬í•´"
        )

        lines.append(f"Repository: {metrics.repo}")
        lines.append(f"Period: {period_label}")
        lines.append("")

        if metrics.summary:
            lines.append("Summary:")
            for key, value in metrics.summary.items():
                lines.append(f"- {key.title()}: {value}")
            lines.append("")

        if metrics.stats:
            lines.append("Metrics:")
            for domain, domain_stats in metrics.stats.items():
                lines.append(f"- {domain.title()}:")
                for stat_name, stat_value in domain_stats.items():
                    lines.append(
                        "  â€¢ {}: {}".format(
                            stat_name.replace("_", " ").title(),
                            _format_metric_value(stat_value)
                            if isinstance(stat_value, (int, float))
                            else stat_value,
                        )
                    )
            lines.append("")

        if metrics.highlights:
            lines.append("Growth Highlights:")
            for highlight in metrics.highlights:
                lines.append(f"- {highlight}")
            lines.append("")

        if metrics.spotlight_examples:
            lines.append("Spotlight Examples:")
            for category, entries in metrics.spotlight_examples.items():
                lines.append(f"- {category.replace('_', ' ').title()}")
                for entry in entries:
                    lines.append(f"  â€¢ {entry}")
            lines.append("")

        if metrics.yearbook_story:
            lines.append("Year In Review:")
            for paragraph in metrics.yearbook_story:
                lines.append(f"- {paragraph}")
            lines.append("")

        if metrics.awards:
            lines.append("Awards:")
            for award in metrics.awards:
                lines.append(f"- {award}")
            lines.append("")

        if metrics.evidence:
            lines.append("Evidence Links:")
            for domain, links in metrics.evidence.items():
                for link in links:
                    lines.append(f"- {domain.title()}: {link}")

        return "\n".join(lines).strip()

    def _build_header_and_summary(self, metrics: MetricSnapshot) -> List[str]:
        """Build header and summary section."""
        lines = ["# ðŸš€ GitHub Feedback Report", ""]
        lines.append(f"**Repository**: {metrics.repo}")
        lines.append(f"**Period**: {metrics.months} months")

        if metrics.since_date and metrics.until_date:
            since_str = metrics.since_date.strftime("%Y-%m-%d")
            until_str = metrics.until_date.strftime("%Y-%m-%d")
            lines.append(f"**Analysis Period**: {since_str} ~ {until_str}")

        lines.append("")
        lines.append("---")
        lines.append("")

        return lines

    def _build_table_of_contents(self, metrics: MetricSnapshot) -> List[str]:
        """Build table of contents section."""
        lines = ["## ðŸ“‘ ëª©ì°¨", ""]

        sections = [
            ("ðŸ“Š Executive Summary", "í•œëˆˆì— ë³´ëŠ” í•µì‹¬ ì§€í‘œ"),
            ("ðŸ† Awards Cabinet", "íšë“í•œ ì–´ì›Œë“œ"),
            ("âœ¨ Growth Highlights", "ì„±ìž¥ í•˜ì´ë¼ì´íŠ¸"),
            ("ðŸ“ˆ Monthly Trends", "ì›”ë³„ í™œë™ íŠ¸ë Œë“œ"),
        ]

        if metrics.detailed_feedback:
            sections.append(("ðŸ’¡ Detailed Feedback", "ìƒì„¸ í”¼ë“œë°±"))

        # Add retrospective section
        if metrics.retrospective:
            sections.append(("ðŸ” Deep Retrospective", "ì‹¬ì¸µ íšŒê³  ë¶„ì„"))

        sections.extend([
            ("ðŸŽ¯ Spotlight Examples", "ì£¼ìš” ê¸°ì—¬ ì‚¬ë¡€"),
            ("ðŸ’» Tech Stack", "ê¸°ìˆ  ìŠ¤íƒ ë¶„ì„"),
            ("ðŸ¤ Collaboration", "í˜‘ì—… ë„¤íŠ¸ì›Œí¬"),
            ("ðŸ¤” Reflection", "íšŒê³  ì§ˆë¬¸"),
            ("ðŸ“Š Detailed Metrics", "ìƒì„¸ ë©”íŠ¸ë¦­"),
            ("ðŸ”— Evidence", "ì¦ê±° ë§í¬"),
        ])

        for i, (title, desc) in enumerate(sections, 1):
            lines.append(f"{i}. **{title}** - {desc}")

        lines.append("")
        lines.append("---")
        lines.append("")
        return lines

    def _build_executive_summary(self, metrics: MetricSnapshot) -> List[str]:
        """Build executive summary section with key highlights."""
        lines = ["## ðŸ“Š Executive Summary", ""]
        lines.append("> í™œë™ ê¸°ê°„ì˜ í•µì‹¬ ì„±ê³¼ë¥¼ í•œëˆˆì— í™•ì¸í•˜ì„¸ìš”")
        lines.append("")

        # Key metrics in a box format
        total_activity = sum([
            metrics.stats.get("commits", {}).get("total", 0),
            metrics.stats.get("pull_requests", {}).get("total", 0),
            metrics.stats.get("reviews", {}).get("total", 0),
        ])

        lines.append("### ðŸ“ˆ í•µì‹¬ ì§€í‘œ")
        lines.append("")
        lines.append("| ì§€í‘œ | ê°’ | ì„¤ëª… |")
        lines.append("|------|-----|------|")

        for key, value in metrics.summary.items():
            display_value = (
                _format_metric_value(value) if isinstance(value, (int, float)) else str(value)
            )
            # Add descriptions for each metric
            descriptions = {
                "velocity": "ì›”í‰ê·  ì»¤ë°‹ ì†ë„",
                "collaboration": "ì›”í‰ê·  í˜‘ì—… í™œë™",
                "stability": "ì•ˆì •ì„± ì ìˆ˜",
                "growth": "ì „ì²´ ì„±ìž¥ ìš”ì•½"
            }
            desc = descriptions.get(key, "")
            lines.append(f"| **{key.title()}** | {display_value} | {desc} |")

        lines.append("")

        # Quick stats
        if metrics.awards:
            lines.append(f"ðŸ† **ì´ {len(metrics.awards)}ê°œì˜ ì–´ì›Œë“œ íšë“**")

        if metrics.highlights:
            lines.append(f"âœ¨ **{len(metrics.highlights)}ê°œì˜ ì£¼ìš” ì„±ê³¼**")

        lines.append("")
        lines.append("---")
        lines.append("")

        return lines

    def _build_metrics_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build metrics section."""
        lines = ["## ðŸ“Š Detailed Metrics", ""]
        lines.append("> ê° í™œë™ ì˜ì—­ë³„ ìƒì„¸ ìˆ˜ì¹˜ë¥¼ í™•ì¸í•˜ì„¸ìš”")
        lines.append("")

        for domain, domain_stats in metrics.stats.items():
            lines.append(f"### {domain.title()}")
            for stat_name, stat_value in domain_stats.items():
                formatted_value = (
                    _format_metric_value(stat_value)
                    if isinstance(stat_value, (int, float))
                    else str(stat_value)
                )
                lines.append(f"- **{stat_name.replace('_', ' ').title()}**: {formatted_value}")
            lines.append("")
        return lines

    def _build_highlights_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build growth highlights section."""
        if not metrics.highlights:
            return []

        lines = ["## âœ¨ Growth Highlights", ""]
        lines.append("> ì´ë²ˆ ê¸°ê°„ ë™ì•ˆì˜ ì£¼ìš” ì„±ê³¼ì™€ ì„±ìž¥ í¬ì¸íŠ¸")
        lines.append("")
        for i, highlight in enumerate(metrics.highlights, 1):
            lines.append(f"{i}. {highlight}")
        lines.append("")
        lines.append("---")
        lines.append("")
        return lines

    def _build_spotlight_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build spotlight examples section."""
        if not metrics.spotlight_examples:
            return []

        lines = ["## ðŸŽ¯ Spotlight Examples", ""]
        lines.append("> ì£¼ëª©í•  ë§Œí•œ ê¸°ì—¬ ì‚¬ë¡€")
        lines.append("")
        for category, entries in metrics.spotlight_examples.items():
            lines.append(f"### {category.replace('_', ' ').title()}")
            for entry in entries:
                lines.append(f"- {entry}")
            lines.append("")
        lines.append("---")
        lines.append("")
        return lines

    def _build_year_in_review_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build comprehensive year in review section combining story and detailed review."""
        if not metrics.yearbook_story and not metrics.year_end_review:
            return []

        lines = ["## ðŸ“… Year in Review", ""]
        lines.append("> í•œ í•´ì˜ ì—¬ì •ì„ ëŒì•„ë´…ë‹ˆë‹¤")
        lines.append("")

        # Story beats
        if metrics.yearbook_story:
            lines.append("### ðŸŒŸ ì˜¬í•´ì˜ ì´ì•¼ê¸°")
            lines.append("")
            for paragraph in metrics.yearbook_story:
                lines.append(paragraph)
                lines.append("")

        # Year end review details
        if metrics.year_end_review:
            if metrics.year_end_review.proudest_moments:
                lines.append("### ðŸ… ìžëž‘ìŠ¤ëŸ¬ìš´ ìˆœê°„ë“¤")
                lines.append("")
                for moment in metrics.year_end_review.proudest_moments:
                    lines.append(f"- {moment}")
                lines.append("")

            if metrics.year_end_review.biggest_challenges:
                lines.append("### ðŸ’ª ê·¹ë³µí•œ ë„ì „ë“¤")
                lines.append("")
                for challenge in metrics.year_end_review.biggest_challenges:
                    lines.append(f"- {challenge}")
                lines.append("")

            if metrics.year_end_review.lessons_learned:
                lines.append("### ðŸ“š ë°°ìš´ êµí›ˆë“¤")
                lines.append("")
                for lesson in metrics.year_end_review.lessons_learned:
                    lines.append(f"- {lesson}")
                lines.append("")

            if metrics.year_end_review.next_year_goals:
                lines.append("### ðŸŽ¯ ë‚´ë…„ ëª©í‘œ")
                lines.append("")
                for goal in metrics.year_end_review.next_year_goals:
                    lines.append(f"- {goal}")
                lines.append("")

        lines.append("---")
        lines.append("")
        return lines

    def _build_awards_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build awards cabinet section."""
        if not metrics.awards:
            return []

        lines = ["## ðŸ† Awards Cabinet", ""]
        lines.append(f"**ì´ {len(metrics.awards)}ê°œì˜ ì–´ì›Œë“œë¥¼ íšë“í–ˆìŠµë‹ˆë‹¤!**")
        lines.append("")

        categories = self._categorize_awards(metrics.awards)
        for category_name, category_awards in categories.items():
            if category_awards:
                lines.append(f"### {category_name}")
                for award in category_awards:
                    lines.append(f"- {award}")
                lines.append("")
        return lines


    def _build_detailed_feedback_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build detailed feedback section."""
        if not metrics.detailed_feedback:
            return []

        lines = ["## ðŸ’¡ Detailed Feedback", ""]
        lines.append("> ì½”ë“œ, PR, ë¦¬ë·°, ì´ìŠˆ í’ˆì§ˆì— ëŒ€í•œ ìƒì„¸ ë¶„ì„")
        lines.append("")
        feedback = metrics.detailed_feedback

        # Commit message feedback
        if feedback.commit_feedback:
            lines.extend(self._build_commit_feedback(feedback.commit_feedback))

        # PR title feedback
        if feedback.pr_title_feedback:
            lines.extend(self._build_pr_title_feedback(feedback.pr_title_feedback))

        # Review tone feedback
        if feedback.review_tone_feedback:
            lines.extend(self._build_review_tone_feedback(feedback.review_tone_feedback))

        # Issue feedback
        if feedback.issue_feedback:
            lines.extend(self._build_issue_feedback(feedback.issue_feedback))

        lines.append("---")
        lines.append("")
        return lines

    def _build_feedback_section(
        self,
        title: str,
        feedback_data: Any,
        stats_config: Dict[str, str],
        example_formatter: Optional[Callable[[Any], str]] = None,
        examples_poor_attr: str = "examples_poor"
    ) -> List[str]:
        """Build a feedback subsection with a common structure.

        Args:
            title: Section title (e.g., "### ðŸ“ ì»¤ë°‹ ë©”ì‹œì§€ í’ˆì§ˆ")
            feedback_data: Feedback data object with stats and examples
            stats_config: Dictionary mapping stat names to labels
                - 'total': tuple of (attribute_name, label, unit)
                - 'good': tuple of (attribute_name, label, unit)
                - 'poor': tuple of (attribute_name, label, unit)
                - additional stats as needed
            example_formatter: Optional function to format examples
            examples_poor_attr: Attribute name for poor examples (default: "examples_poor")

        Returns:
            List of markdown lines
        """
        lines = [title, ""]

        # Build summary statistics
        total_attr, total_label, unit = stats_config.get('total', (None, None, 'ê°œ'))
        good_attr, good_label, _ = stats_config.get('good', (None, None, 'ê°œ'))
        poor_attr, poor_label, _ = stats_config.get('poor', (None, None, 'ê°œ'))

        total_value = getattr(feedback_data, total_attr, 0) if total_attr else 0
        good_value = getattr(feedback_data, good_attr, 0) if good_attr else 0
        poor_value = getattr(feedback_data, poor_attr, 0) if poor_attr else 0

        if total_value > 0:
            good_pct = (good_value / total_value) * 100
            lines.append(f"**{total_label}**: {total_value}{unit}")
            lines.append(f"**{good_label}**: {good_value}{unit} ({good_pct:.1f}%)")
            lines.append(f"**{poor_label}**: {poor_value}{unit}")

            # Add additional stats if configured
            for key, (attr, label, stat_unit) in stats_config.items():
                if key not in ('total', 'good', 'poor'):
                    value = getattr(feedback_data, attr, 0)
                    lines.append(f"**{label}**: {value}{stat_unit}")
        else:
            lines.append(f"- {total_label}: {total_value}")
            lines.append(f"- {good_label}: {good_value}")
            lines.append(f"- {poor_label}: {poor_value}")

            # Add additional stats if configured
            for key, (attr, label, stat_unit) in stats_config.items():
                if key not in ('total', 'good', 'poor'):
                    value = getattr(feedback_data, attr, 0)
                    lines.append(f"- {label}: {value}")
        lines.append("")

        # Suggestions section
        if hasattr(feedback_data, 'suggestions') and feedback_data.suggestions:
            lines.append("#### ðŸ’¡ ê°œì„  ì œì•ˆ")
            lines.append("")
            for i, suggestion in enumerate(feedback_data.suggestions, 1):
                lines.append(f"{i}. {suggestion}")
            lines.append("")

        # Good examples section
        if hasattr(feedback_data, 'examples_good') and feedback_data.examples_good:
            lines.append("#### âœ… ì¢‹ì€ ì˜ˆì‹œ")
            lines.append("")
            for example in feedback_data.examples_good[:DISPLAY_LIMITS['feedback_examples']]:
                if example_formatter:
                    lines.append(f"- {example_formatter(example)}")
                elif isinstance(example, dict):
                    lines.append(f"- {example}")
                else:
                    lines.append(f"- {example}")
            lines.append("")

        # Poor/improve examples section
        poor_examples = getattr(feedback_data, examples_poor_attr, None)
        if poor_examples:
            lines.append("#### âš ï¸ ê°œì„ ì´ í•„ìš”í•œ ì˜ˆì‹œ")
            lines.append("")
            for example in poor_examples[:DISPLAY_LIMITS['feedback_examples']]:
                if example_formatter:
                    lines.append(f"- {example_formatter(example)}")
                elif isinstance(example, dict):
                    lines.append(f"- {example}")
                else:
                    lines.append(f"- {example}")
            lines.append("")

        return lines

    def _build_commit_feedback(self, cf) -> List[str]:
        """Build commit feedback subsection."""
        def format_commit_example(example):
            if isinstance(example, dict):
                return f"`{example.get('message', '')}` ({example.get('sha', '')[:7]})"
            return str(example)

        return self._build_feedback_section(
            title="### ðŸ“ ì»¤ë°‹ ë©”ì‹œì§€ í’ˆì§ˆ",
            feedback_data=cf,
            stats_config={
                'total': ('total_commits', 'ì´ ì»¤ë°‹', 'ê°œ'),
                'good': ('good_messages', 'ì¢‹ì€ ë©”ì‹œì§€', 'ê°œ'),
                'poor': ('poor_messages', 'ê°œì„  í•„ìš”', 'ê°œ'),
            },
            example_formatter=format_commit_example,
        )

    def _build_pr_title_feedback(self, pf) -> List[str]:
        """Build PR title feedback subsection."""
        def format_pr_example(example):
            if isinstance(example, dict):
                return f"#{example.get('number', '')}: `{example.get('title', '')}`"
            return str(example)

        return self._build_feedback_section(
            title="### ðŸ”€ PR ì œëª© í’ˆì§ˆ",
            feedback_data=pf,
            stats_config={
                'total': ('total_prs', 'ì´ PR', 'ê°œ'),
                'good': ('clear_titles', 'ëª…í™•í•œ ì œëª©', 'ê°œ'),
                'poor': ('vague_titles', 'ëª¨í˜¸í•œ ì œëª©', 'ê°œ'),
            },
            example_formatter=format_pr_example,
        )

    def _build_review_tone_feedback(self, rf) -> List[str]:
        """Build review tone feedback subsection."""
        return self._build_feedback_section(
            title="### ðŸ‘€ ë¦¬ë·° í†¤ ë¶„ì„",
            feedback_data=rf,
            stats_config={
                'total': ('total_reviews', 'ì´ ë¦¬ë·°', 'ê°œ'),
                'good': ('constructive_reviews', 'ê±´ì„¤ì ì¸ ë¦¬ë·°', 'ê°œ'),
                'poor': ('harsh_reviews', 'ê°€í˜¹í•œ ë¦¬ë·°', 'ê°œ'),
                'neutral': ('neutral_reviews', 'ì¤‘ë¦½ì ì¸ ë¦¬ë·°', 'ê°œ'),
            },
            examples_poor_attr='examples_improve',
        )

    def _build_issue_feedback(self, isf) -> List[str]:
        """Build issue feedback subsection."""
        def format_issue_example(example):
            if isinstance(example, dict):
                return f"#{example.get('number', '')}: `{example.get('title', '')}`"
            return str(example)

        return self._build_feedback_section(
            title="### ðŸ› ì´ìŠˆ í’ˆì§ˆ",
            feedback_data=isf,
            stats_config={
                'total': ('total_issues', 'ì´ ì´ìŠˆ', 'ê°œ'),
                'good': ('well_described', 'ìž˜ ìž‘ì„±ë¨', 'ê°œ'),
                'poor': ('poorly_described', 'ê°œì„  í•„ìš”', 'ê°œ'),
            },
            example_formatter=format_issue_example,
        )

    def _build_monthly_trends_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build monthly trends section."""
        if not metrics.monthly_trends:
            return []

        lines = ["## ðŸ“ˆ Monthly Trends", ""]
        lines.append("> ì›”ë³„ í™œë™ íŒ¨í„´ê³¼ íŠ¸ë Œë“œ ë¶„ì„")
        lines.append("")

        if metrics.monthly_insights and metrics.monthly_insights.insights:
            lines.append("### ðŸ’¡ ì¸ì‚¬ì´íŠ¸")
            lines.append("")
            for i, insight in enumerate(metrics.monthly_insights.insights, 1):
                lines.append(f"{i}. {insight}")
            lines.append("")

        lines.append("### ðŸ“Š ì›”ë³„ ìƒì„¸ ë°ì´í„°")
        lines.append("")
        lines.append("| ì›” | ì»¤ë°‹ | PR | ë¦¬ë·° | ì´ìŠˆ | ì´ í™œë™ |")
        lines.append("|---|---|---|---|---|---|")
        for trend in metrics.monthly_trends:
            total_activity = trend.commits + trend.pull_requests + trend.reviews + trend.issues
            lines.append(
                f"| {trend.month} | {trend.commits} | {trend.pull_requests} | "
                f"{trend.reviews} | {trend.issues} | **{total_activity}** |"
            )
        lines.append("")
        lines.append("---")
        lines.append("")
        return lines

    def _build_tech_stack_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build tech stack section."""
        if not metrics.tech_stack:
            return []

        lines = ["## ðŸ’» Tech Stack Analysis", ""]
        lines.append("> ì‚¬ìš©í•œ ê¸°ìˆ ê³¼ ì–¸ì–´ ë¶„í¬")
        lines.append("")
        lines.append(f"**ë‹¤ì–‘ì„± ì ìˆ˜**: {metrics.tech_stack.diversity_score:.2f} (0-1 ì²™ë„)")
        lines.append("")
        lines.append("**ì£¼ìš” ì‚¬ìš© ì–¸ì–´:**")
        lines.append("")
        for i, lang in enumerate(metrics.tech_stack.top_languages[:5], 1):
            count = metrics.tech_stack.languages.get(lang, 0)
            lines.append(f"{i}. **{lang}** - {count}ê°œ íŒŒì¼")
        lines.append("")
        lines.append("---")
        lines.append("")
        return lines

    def _build_collaboration_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build collaboration section."""
        if not metrics.collaboration:
            return []

        lines = ["## ðŸ¤ Collaboration Network", ""]
        lines.append("> í•¨ê»˜ ì„±ìž¥í•œ ë™ë£Œë“¤ê³¼ì˜ í˜‘ì—…")
        lines.append("")
        lines.append(f"- ë°›ì€ ë¦¬ë·° ìˆ˜: **{metrics.collaboration.review_received_count}ê±´**")
        lines.append(f"- í˜‘ì—…í•œ ì‚¬ëžŒ ìˆ˜: **{metrics.collaboration.unique_collaborators}ëª…**")
        lines.append("")

        if metrics.collaboration.top_reviewers:
            lines.append("### ðŸŒŸ ì£¼ìš” ë¦¬ë·°ì–´")
            lines.append("")
            for i, reviewer in enumerate(metrics.collaboration.top_reviewers, 1):
                count = metrics.collaboration.pr_reviewers.get(reviewer, 0)
                lines.append(f"{i}. **@{reviewer}** - {count}íšŒ ë¦¬ë·°")
            lines.append("")
        lines.append("---")
        lines.append("")
        return lines

    def _build_reflection_prompts_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build reflection prompts section."""
        if not (metrics.reflection_prompts and metrics.reflection_prompts.questions):
            return []

        lines = ["## ðŸ¤” Reflection Prompts", ""]
        lines.append("> ìŠ¤ìŠ¤ë¡œì—ê²Œ ë¬¼ì–´ë³´ì„¸ìš”")
        lines.append("")
        for i, question in enumerate(metrics.reflection_prompts.questions, 1):
            lines.append(f"{i}. {question}")
        lines.append("")
        lines.append("---")
        lines.append("")
        return lines

    def _build_evidence_section_improved(self, metrics: MetricSnapshot) -> List[str]:
        """Build evidence section."""
        if not metrics.evidence:
            return []

        lines = ["## ðŸ”— Evidence Links", ""]
        lines.append("> ìƒì„¸ ë°ì´í„°ë¥¼ í™•ì¸í•  ìˆ˜ ìžˆëŠ” ë§í¬")
        lines.append("")
        for domain, links in metrics.evidence.items():
            lines.append(f"### {domain.title()}")
            for link in links:
                lines.append(f"- [{domain.title()} ë³´ê¸°]({link})")
            lines.append("")
        lines.append("---")
        lines.append("")
        return lines

    def _build_retrospective_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build comprehensive retrospective analysis section."""
        if not metrics.retrospective:
            return []

        retro = metrics.retrospective
        lines = ["## ðŸ” Deep Retrospective Analysis", ""]
        lines.append("> ë°ì´í„° ê¸°ë°˜ì˜ ì‹¬ì¸µì ì¸ íšŒê³ ì™€ ì¸ì‚¬ì´íŠ¸")
        lines.append("")

        # Executive Summary
        if retro.executive_summary:
            lines.append("### ðŸ“‹ íšŒê³  ìš”ì•½")
            lines.append("")
            lines.append(retro.executive_summary)
            lines.append("")

        # Key Wins
        if retro.key_wins:
            lines.append("### ðŸŽ‰ ì£¼ìš” ì„±ê³¼")
            lines.append("")
            lines.append("> ì´ë²ˆ ê¸°ê°„ ë™ì•ˆ ë‹¬ì„±í•œ í•µì‹¬ ì„±ê³¼ë“¤ìž…ë‹ˆë‹¤")
            lines.append("")
            for i, win in enumerate(retro.key_wins, 1):
                lines.append(f"{i}. **{win}**")
            lines.append("")

        # Time Comparisons
        if retro.time_comparisons:
            lines.append("### ðŸ“Š ê¸°ê°„ ë¹„êµ ë¶„ì„")
            lines.append("")
            lines.append("> ì „ë°˜ê¸°ì™€ í›„ë°˜ê¸°ì˜ ë³€í™” ì¶”ì´ë¥¼ ë¹„êµí•©ë‹ˆë‹¤")
            lines.append("")
            lines.append("| ì§€í‘œ | ì „ë°˜ê¸° | í›„ë°˜ê¸° | ë³€í™”ëŸ‰ | ë³€í™”ìœ¨ | ì˜ë¯¸ |")
            lines.append("|------|--------|--------|--------|--------|------|")

            for tc in retro.time_comparisons:
                direction_emoji = "ðŸ“ˆ" if tc.direction == "increasing" else "ðŸ“‰" if tc.direction == "decreasing" else "âž¡ï¸"
                significance_text = {
                    "major": "í° ë³€í™”",
                    "moderate": "ì¤‘ê°„ ë³€í™”",
                    "minor": "ìž‘ì€ ë³€í™”"
                }.get(tc.significance, tc.significance)

                lines.append(
                    f"| {tc.metric_name} | {tc.previous_value:.1f} | {tc.current_value:.1f} | "
                    f"{tc.change_absolute:+.1f} | {tc.change_percentage:+.1f}% | "
                    f"{direction_emoji} {significance_text} |"
                )
            lines.append("")

        # Behavior Patterns
        if retro.behavior_patterns:
            lines.append("### ðŸ§  í–‰ë™ íŒ¨í„´ ë¶„ì„")
            lines.append("")
            lines.append("> ìž‘ì—… íŒ¨í„´ê³¼ ìŠµê´€ì—ì„œ ë°œê²¬ëœ ì¸ì‚¬ì´íŠ¸")
            lines.append("")

            for pattern in retro.behavior_patterns:
                impact_emoji = "âœ…" if pattern.impact == "positive" else "âš ï¸" if pattern.impact == "negative" else "â„¹ï¸"
                lines.append(f"#### {impact_emoji} {pattern.description}")
                lines.append("")

                if pattern.evidence:
                    lines.append("**ê·¼ê±°:**")
                    for evidence in pattern.evidence:
                        lines.append(f"- {evidence}")
                    lines.append("")

                if pattern.recommendation:
                    lines.append(f"**ì œì•ˆ:** {pattern.recommendation}")
                    lines.append("")
            lines.append("")

        # Learning Insights
        if retro.learning_insights:
            lines.append("### ðŸ“š í•™ìŠµ ë° ì„±ìž¥ ë¶„ì„")
            lines.append("")
            lines.append("> ê¸°ìˆ  ì—­ëŸ‰ê³¼ í•™ìŠµ ê¶¤ì ì„ ë¶„ì„í•©ë‹ˆë‹¤")
            lines.append("")

            for learning in retro.learning_insights:
                expertise_emoji = {"expert": "ðŸ‘‘", "proficient": "â­", "developing": "ðŸŒ±", "exploring": "ðŸ”"}.get(
                    learning.expertise_level, "ðŸ“–"
                )
                lines.append(f"#### {expertise_emoji} {learning.domain}")
                lines.append("")
                lines.append(f"**ê¸°ìˆ :** {', '.join(learning.technologies)}")
                lines.append(f"**ì „ë¬¸ì„± ìˆ˜ì¤€:** {learning.expertise_level}")
                lines.append("")

                if learning.growth_indicators:
                    lines.append("**ì„±ìž¥ ì§€í‘œ:**")
                    for indicator in learning.growth_indicators:
                        lines.append(f"- {indicator}")
                    lines.append("")
            lines.append("")

        # Impact Assessments
        if retro.impact_assessments:
            lines.append("### ðŸ’Ž ì˜í–¥ë„ í‰ê°€")
            lines.append("")
            lines.append("> ê¸°ì—¬ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ë° íŒ€ ì˜í–¥ì„ í‰ê°€í•©ë‹ˆë‹¤")
            lines.append("")

            for impact in retro.impact_assessments:
                impact_emoji = {"high": "ðŸ”¥", "medium": "âœ¨", "low": "ðŸ’¡"}.get(impact.estimated_impact, "ðŸ“Š")
                lines.append(f"#### {impact_emoji} {impact.category}")
                lines.append("")
                lines.append(f"**ê¸°ì—¬ íšŸìˆ˜:** {impact.contribution_count:,}ê±´")
                lines.append(f"**ì˜í–¥ë„:** {impact.estimated_impact}")
                lines.append(f"**ì„¤ëª…:** {impact.impact_description}")
                lines.append("")

                if impact.key_achievements:
                    lines.append("**í•µì‹¬ ì„±ê³¼:**")
                    for achievement in impact.key_achievements:
                        lines.append(f"- {achievement}")
                    lines.append("")
            lines.append("")

        # Collaboration Insights
        if retro.collaboration_insights:
            collab = retro.collaboration_insights
            lines.append("### ðŸ¤ í˜‘ì—… ì‹¬ì¸µ ë¶„ì„")
            lines.append("")
            lines.append(f"**í˜‘ì—… ê°•ë„:** {collab.collaboration_strength}")
            lines.append(f"**í˜‘ì—… í’ˆì§ˆ:** {collab.collaboration_quality}")
            lines.append("")

            if collab.key_partnerships:
                lines.append("**ì£¼ìš” í˜‘ì—… íŒŒíŠ¸ë„ˆ:**")
                lines.append("")
                lines.append("| í˜‘ì—…ìž | ë¦¬ë·° íšŸìˆ˜ | ê´€ê³„ |")
                lines.append("|--------|-----------|------|")
                for person, count, rel_type in collab.key_partnerships:
                    lines.append(f"| @{person} | {count}íšŒ | {rel_type} |")
                lines.append("")

            if collab.mentorship_indicators:
                lines.append("**ë©˜í† ë§ í™œë™:**")
                for indicator in collab.mentorship_indicators:
                    lines.append(f"- {indicator}")
                lines.append("")

            if collab.improvement_areas:
                lines.append("**ê°œì„  ì˜ì—­:**")
                for area in collab.improvement_areas:
                    lines.append(f"- {area}")
                lines.append("")
            lines.append("")

        # Balance Metrics
        if retro.balance_metrics:
            balance = retro.balance_metrics
            lines.append("### âš–ï¸ ì—…ë¬´ ë°¸ëŸ°ìŠ¤ ë¶„ì„")
            lines.append("")

            risk_emoji = {"low": "âœ…", "moderate": "âš ï¸", "high": "ðŸš¨"}.get(balance.burnout_risk_level, "â“")
            lines.append(f"**ë²ˆì•„ì›ƒ ìœ„í—˜ë„:** {risk_emoji} {balance.burnout_risk_level}")
            lines.append(f"**ì§€ì†ê°€ëŠ¥ì„± ì ìˆ˜:** {balance.sustainability_score:.0f}/100")
            lines.append(f"**í™œë™ ë³€ë™ì„±:** {balance.activity_variance:.2f}")
            lines.append("")

            if balance.positive_patterns:
                lines.append("**ê¸ì •ì  íŒ¨í„´:**")
                for pattern in balance.positive_patterns:
                    lines.append(f"- âœ… {pattern}")
                lines.append("")

            if balance.burnout_indicators:
                lines.append("**ì£¼ì˜ ì‚¬í•­:**")
                for indicator in balance.burnout_indicators:
                    lines.append(f"- âš ï¸ {indicator}")
                lines.append("")

            if balance.health_recommendations:
                lines.append("**ê¶Œìž¥ ì‚¬í•­:**")
                for rec in balance.health_recommendations:
                    lines.append(f"- ðŸ’¡ {rec}")
                lines.append("")
            lines.append("")

        # Code Health
        if retro.code_health:
            health = retro.code_health
            lines.append("### ðŸ¥ ì½”ë“œ ê±´ê°•ë„ ë¶„ì„")
            lines.append("")
            lines.append(f"**ìœ ì§€ë³´ìˆ˜ ë¶€ë‹´:** {health.maintenance_burden}")
            lines.append(f"**í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ì¶”ì„¸:** {health.test_coverage_trend}")
            lines.append("")

            if health.code_quality_trends:
                lines.append("**í’ˆì§ˆ íŠ¸ë Œë“œ:**")
                for trend in health.code_quality_trends:
                    lines.append(f"- {trend}")
                lines.append("")

            if health.quality_improvement_suggestions:
                lines.append("**ê°œì„  ì œì•ˆ:**")
                for suggestion in health.quality_improvement_suggestions:
                    lines.append(f"- ðŸ’¡ {suggestion}")
                lines.append("")
            lines.append("")

        # Actionable Insights
        if retro.actionable_insights:
            lines.append("### ðŸŽ¯ ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸")
            lines.append("")
            lines.append("> êµ¬ì²´ì ì´ê³  ì¸¡ì • ê°€ëŠ¥í•œ ê°œì„  ë°©ì•ˆ")
            lines.append("")

            # Group by priority
            high_priority = [ai for ai in retro.actionable_insights if ai.priority == "high"]
            medium_priority = [ai for ai in retro.actionable_insights if ai.priority == "medium"]

            if high_priority:
                lines.append("#### ðŸ”´ ë†’ì€ ìš°ì„ ìˆœìœ„")
                lines.append("")
                for insight in high_priority:
                    lines.append(f"**{insight.title}**")
                    lines.append("")
                    lines.append(f"*{insight.description}*")
                    lines.append("")
                    lines.append(f"**ì™œ ì¤‘ìš”í•œê°€:** {insight.why_it_matters}")
                    lines.append("")
                    lines.append("**êµ¬ì²´ì  í–‰ë™:**")
                    for action in insight.concrete_actions:
                        lines.append(f"1. {action}")
                    lines.append("")
                    lines.append(f"**ê¸°ëŒ€ íš¨ê³¼:** {insight.expected_outcome}")
                    lines.append(f"**ì¸¡ì • ë°©ë²•:** {insight.measurement}")
                    lines.append("")
                    lines.append("---")
                    lines.append("")

            if medium_priority:
                lines.append("#### ðŸŸ¡ ì¤‘ê°„ ìš°ì„ ìˆœìœ„")
                lines.append("")
                for insight in medium_priority[:DISPLAY_LIMITS['medium_priority_insights']]:  # Limit to top N for readability
                    lines.append(f"**{insight.title}**")
                    lines.append("")
                    lines.append(f"*{insight.description}*")
                    lines.append("")
                    lines.append("**êµ¬ì²´ì  í–‰ë™:**")
                    for action in insight.concrete_actions:
                        lines.append(f"- {action}")
                    lines.append("")
            lines.append("")

        # Areas for Growth
        if retro.areas_for_growth:
            lines.append("### ðŸŒ± ì„±ìž¥ ê¸°íšŒ")
            lines.append("")
            lines.append("> ë‹¤ìŒ ë‹¨ê³„ë¡œ ë‚˜ì•„ê°€ê¸° ìœ„í•œ ì˜ì—­")
            lines.append("")
            for i, area in enumerate(retro.areas_for_growth, 1):
                lines.append(f"{i}. {area}")
            lines.append("")

        # Narrative
        if retro.retrospective_narrative:
            lines.append("### ðŸ“– íšŒê³  ìŠ¤í† ë¦¬")
            lines.append("")
            lines.append("> ë‹¹ì‹ ì˜ ì—¬ì •ì„ ì´ì•¼ê¸°ë¡œ í’€ì–´ëƒ…ë‹ˆë‹¤")
            lines.append("")
            for paragraph in retro.retrospective_narrative:
                lines.append(paragraph)
                lines.append("")

        lines.append("---")
        lines.append("")
        return lines

    def generate_markdown(self, metrics: MetricSnapshot) -> Path:
        """Create a markdown report for the provided metrics.

        Improved report structure for better user experience:
        1. Header with basic info
        2. Table of Contents for easy navigation
        3. Executive Summary for quick overview
        4. Awards Cabinet to celebrate achievements
        5. Growth Highlights to show progress
        6. Monthly Trends for pattern analysis
        7. Detailed Feedback for actionable insights
        8. Spotlight Examples for concrete evidence
        9. Tech Stack to show technical breadth
        10. Collaboration Network to show teamwork
        11. Year in Review for storytelling
        12. Reflection Prompts for introspection
        13. Detailed Metrics for deep dive
        14. Evidence Links for verification
        """
        self.ensure_structure()
        report_path = self.output_dir / "report.md"

        console.log("Writing markdown report", f"path={report_path}")

        # Build all sections in improved order
        sections = [
            # 1. Header with basic info
            self._build_header_and_summary(metrics),
            # 2. Table of Contents
            self._build_table_of_contents(metrics),
            # 3. Executive Summary - Quick overview
            self._build_executive_summary(metrics),
            # 4. Awards Cabinet - Celebrate achievements first!
            self._build_awards_section(metrics),
            # 5. Growth Highlights - Show the story
            self._build_highlights_section(metrics),
            # 6. Monthly Trends - Show patterns
            self._build_monthly_trends_section(metrics),
            # 7. Detailed Feedback - Actionable insights
            self._build_detailed_feedback_section(metrics),
            # 8. Deep Retrospective - Comprehensive analysis NEW!
            self._build_retrospective_section(metrics),
            # 9. Spotlight Examples - Concrete evidence
            self._build_spotlight_section(metrics),
            # 10. Tech Stack - Technical breadth
            self._build_tech_stack_section(metrics),
            # 11. Collaboration - Teamwork
            self._build_collaboration_section(metrics),
            # 12. Year in Review - Complete story (merged with year-end review)
            self._build_year_in_review_section(metrics),
            # 13. Reflection Prompts - Think deeper
            self._build_reflection_prompts_section(metrics),
            # 14. Detailed Metrics - For those who want numbers
            self._build_metrics_section(metrics),
            # 15. Evidence Links - Verification
            self._build_evidence_section_improved(metrics),
        ]

        # Combine all sections
        all_lines = []
        for section in sections:
            all_lines.extend(section)

        report_path.write_text("\n".join(all_lines), encoding="utf-8")
        return report_path

    # ------------------------------------------------------------------
    # Rich visual reporting
    # ------------------------------------------------------------------

    def generate_prompt_packets(
        self, metrics: MetricSnapshot
    ) -> List[Tuple[PromptRequest, Path]]:
        """Create multi-angle LLM prompts for annual feedback synthesis."""

        self.ensure_structure()
        prompts_dir = self.output_dir / "prompts"
        prompts_dir.mkdir(parents=True, exist_ok=True)

        context = self._build_prompt_context(metrics)
        if context:
            context_block = context
        else:
            context_block = (
                f"Repository: {metrics.repo}\nPeriod: ì§€ë‚œ {metrics.months}ê°œì›”"
            )

        definitions: List[Tuple[str, str, str]] = [
            (
                "strengths_overview",
                "ì—°ê°„ í™œë™ ì´í‰ (ìž¥ì  ì¤‘ì‹¬)",
                (
                    "ì•„ëž˜ëŠ” ìµœê·¼ í™œë™ ìš”ì•½ìž…ë‹ˆë‹¤. ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŒ€/ì¡°ì§ ê´€ì ì—ì„œ ë°”ë¼ë³¸ "
                    "ì„±ê³¼ì˜ ìž¥ì  5ê°€ì§€ë¥¼ bulletë¡œ ì •ë¦¬í•´ ì£¼ì„¸ìš”. ê° bulletì—ëŠ” (1) ì–´ë–¤ í™œë™ì´ë‚˜ "
                    "ì§€í‘œê°€ ê·¼ê±°ì¸ì§€, (2) ì¡°ì§ì— ì¤€ ì˜í–¥ì´ ë¬´ì—‡ì¸ì§€ í¬í•¨í•´ ì£¼ì„¸ìš”."
                ),
            ),
            (
                "collaboration_improvements",
                "í˜‘ì—… ë° ë¦¬ë·° ë¬¸í™” ë³´ì™„ì ",
                (
                    "Collaborations ê´€ë ¨ ìˆ˜ì¹˜ì™€ Spotlight Examples, Year in Review ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ "
                    "ë¦¬ë·° ë¬¸í™”/í˜‘ì—… ì¸¡ë©´ì—ì„œ ê°œì„ ì´ í•„ìš”í•œ ì  5ê°€ì§€ë¥¼ ì œì•ˆí•´ ì£¼ì„¸ìš”. ê° í•­ëª©ì—ëŠ” "
                    "(1) í˜„ìž¬ í™œë™ íŒ¨í„´, (2) ìœ„í—˜ ë˜ëŠ” ê¸°íšŒ, (3) ë‹¤ìŒ ë¶„ê¸° ì•¡ì…˜ ì•„ì´ë””ì–´ë¥¼ í¬í•¨í•´ ì£¼ì„¸ìš”."
                ),
            ),
            (
                "quality_balance",
                "ì½”ë“œ í’ˆì§ˆ ë° ì•ˆì •ì„± í‰ê°€",
                (
                    "Stability ê´€ë ¨ ìš”ì•½, Issues í†µê³„, Spotlight ì‚¬ë¡€ë¥¼ ê·¼ê±°ë¡œ ì½”ë“œ í’ˆì§ˆê³¼ ì•ˆì •ì„± ìœ ì§€ "
                    "ì¸¡ë©´ì˜ ìž¥ì ê³¼ ë³´ì™„ì ì„ ê°ê° 3ê°œì”© ìž‘ì„±í•´ ì£¼ì„¸ìš”. ê°€ëŠ¥í•˜ë‹¤ë©´ Spotlight PRì˜ êµ¬ì²´ì  "
                    "ì˜ˆì‹œë¥¼ ì¸ìš©í•´ ì£¼ì„¸ìš”."
                ),
            ),
            (
                "growth_story",
                "ì—°ê°„ ì„±ìž¥ ìŠ¤í† ë¦¬ì™€ í•µì‹¬ ê¸°ì—¬",
                (
                    "Year in Review, Growth Highlights, Awards ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¸ ë‹¨ë½ìœ¼ë¡œ êµ¬ì„±ëœ ì„œì‚¬ë¥¼ ìž‘ì„±í•´ ì£¼ì„¸ìš”. "
                    "1ë‹¨ë½: ì˜¬í•´ ì–´ë–¤ ì—­ëŸ‰ì´ ê°€ìž¥ ì„±ìž¥í–ˆëŠ”ì§€, 2ë‹¨ë½: ì €ìž¥ì†Œì— ì–´ë–¤ ì˜ì—­ì— ì¤‘ì ì ìœ¼ë¡œ ê¸°ì—¬í–ˆëŠ”ì§€, "
                    "3ë‹¨ë½: ê·¸ ê²°ê³¼ íŒ€ì´ë‚˜ ë¹„ì¦ˆë‹ˆìŠ¤ì— ê¸°ëŒ€ë˜ëŠ” íŒŒê¸‰íš¨ê³¼ê°€ ë¬´ì—‡ì¸ì§€ ì„¤ëª…í•´ ì£¼ì„¸ìš”."
                ),
            ),
            (
                "next_half_goals",
                "ì°¨ê¸° ëª©í‘œ ë° ì‹¤í–‰ ê³„íš",
                (
                    "Summaryì™€ ìœ„ì—ì„œ ë„ì¶œí•œ ê°œì„ ì ë“¤ì„ ì°¸ê³ í•˜ì—¬ ë‹¤ìŒ ê¸°ê°„(6ê°œì›”)ì„ ìœ„í•œ ìƒìœ„ 3ê°œ ëª©í‘œì™€ "
                    "ê° ëª©í‘œë³„ ì‹¤í–‰ ê³„íšì„ ìž‘ì„±í•´ ì£¼ì„¸ìš”. ì‹¤í–‰ ê³„íšì—ëŠ” ì¸¡ì • ê°€ëŠ¥í•œ ì§€í‘œë¥¼ í¬í•¨í•´ ì£¼ì„¸ìš”."
                ),
            ),
        ]

        generated: List[Tuple[PromptRequest, Path]] = []
        for identifier, title, instructions in definitions:
            prompt_text = f"{instructions}\n\n{context_block}".strip()
            request = PromptRequest(
                identifier=identifier,
                title=title,
                instructions=instructions,
                prompt=prompt_text,
            )

            prompt_path = prompts_dir / f"{identifier}.txt"
            prompt_lines = [
                f"# {title}",
                "",
                "## Instructions",
                instructions,
                "",
                "## Context",
                context_block,
                "",
                "## Prompt (ready to send)",
                prompt_text,
                "",
            ]
            prompt_path.write_text("\n".join(prompt_lines), encoding="utf-8")
            generated.append((request, prompt_path))

        return generated

    def _create_charts(self, metrics: MetricSnapshot) -> List[Tuple[str, Path]]:
        """Render SVG bar charts for numeric metric domains."""

        charts_dir = self.output_dir / "charts"
        created: List[Tuple[str, Path]] = []

        for domain, domain_stats in metrics.stats.items():
            numeric_stats: List[Tuple[str, float, object]] = []
            for stat_name, stat_value in domain_stats.items():
                if isinstance(stat_value, (int, float)):
                    numeric_stats.append((stat_name, float(stat_value), stat_value))

            if not numeric_stats:
                continue

            values = [value for _, value, _ in numeric_stats]
            max_value = max(values) if values else 1.0
            safe_domain = domain.lower().replace(" ", "_")
            chart_path = charts_dir / f"{safe_domain}.svg"

            width = 720
            chart_width = 520
            bar_height = 28
            spacing = 18
            top_padding = 48
            left_padding = 160
            height = top_padding + spacing + (bar_height + spacing) * len(values)

            svg_parts = [
                f"<svg xmlns='http://www.w3.org/2000/svg' width='{width}' height='{height}' viewBox='0 0 {width} {height}'>",
                "<defs>",
                "<linearGradient id='barGradient' x1='0%' x2='100%' y1='0%' y2='0%'>",
                "<stop offset='0%' stop-color='#60a5fa' />",
                "<stop offset='100%' stop-color='#2563eb' />",
                "</linearGradient>",
                "</defs>",
                "<rect width='100%' height='100%' fill='rgba(15,23,42,0.75)' rx='24' />",
                f"<text x='{width/2}' y='32' text-anchor='middle' fill='#38bdf8' font-size='24' font-weight='600'>{escape(domain.title())} Metrics</text>",
            ]

            for index, (stat_name, value, original) in enumerate(numeric_stats):
                label = stat_name.replace("_", " ").title()
                y = top_padding + index * (bar_height + spacing)
                bar_width = 0 if max_value == 0 else (value / max_value) * chart_width
                svg_parts.extend(
                    [
                        f"<text x='{left_padding - 12}' y='{y + bar_height / 1.5}' text-anchor='end' fill='#cbd5f5' font-size='14'>{escape(label)}</text>",
                        f"<rect x='{left_padding}' y='{y}' width='{bar_width}' height='{bar_height}' rx='10' fill='url(#barGradient)' />",
                        f"<text x='{left_padding + bar_width + 12}' y='{y + bar_height / 1.5}' fill='#f8fafc' font-size='14'>{_format_metric_value(original)}</text>",
                    ]
                )

            svg_parts.append("</svg>")

            chart_path.write_text("".join(svg_parts), encoding="utf-8")
            created.append((domain, chart_path))

            console.log("Chart created", f"domain={domain}", f"path={chart_path}")

        return created

    def _render_list(self, title: str, items: Iterable[str]) -> str:
        """Render an HTML list section when the content is available."""

        escaped_items = [f"<li>{escape(item)}</li>" for item in items]
        if not escaped_items:
            return ""
        return f"<section><h2>{escape(title)}</h2><ul>{''.join(escaped_items)}</ul></section>"

    def generate_html(self, metrics: MetricSnapshot) -> Path:
        """Create an HTML report complete with charts for numeric metrics."""

        self.ensure_structure()
        charts = self._create_charts(metrics)
        report_path = self.output_dir / "report.html"

        console.log("Writing HTML report", f"path={report_path}")

        summary_items = "".join(
            f"<li><strong>{escape(key.title())}</strong>: {escape(_format_metric_value(value) if isinstance(value, (int, float)) else str(value))}</li>"
            for key, value in metrics.summary.items()
        )

        metrics_sections: List[str] = []
        for domain, stats in metrics.stats.items():
            rows = []
            for name, value in stats.items():
                label = escape(name.replace("_", " ").title())
                display_value = (
                    _format_metric_value(value) if isinstance(value, (int, float)) else str(value)
                )
                rows.append(f"<tr><th>{label}</th><td>{escape(display_value)}</td></tr>")
            if rows:
                metrics_sections.append(
                    f"<section><h3>{escape(domain.title())}</h3><table>{''.join(rows)}</table></section>"
                )

        chart_sections = []
        for domain, chart_path in charts:
            relative_path = chart_path.relative_to(self.output_dir)
            chart_sections.append(
                """
                <figure>
                    <img src="{src}" alt="{alt}" loading="lazy" />
                    <figcaption>{caption}</figcaption>
                </figure>
                """.format(
                    src=escape(str(relative_path).replace("\\", "/")),
                    alt=escape(f"{domain.title()} metrics"),
                    caption=escape(domain.title()),
                )
            )

        html_sections = [
            "<section><h1>GitHub Feedback Report</h1>",
            f"<p><strong>Repository:</strong> {escape(metrics.repo)}</p>",
            f"<p><strong>Period:</strong> {escape(str(metrics.months))} months</p>",
            "</section>",
        ]

        if summary_items:
            html_sections.append(f"<section><h2>Summary</h2><ul>{summary_items}</ul></section>")
        if metrics_sections:
            html_sections.append("<section><h2>Metrics</h2>" + "".join(metrics_sections) + "</section>")
        if chart_sections:
            html_sections.append("<section><h2>Visual Highlights</h2>" + "".join(chart_sections) + "</section>")

        if metrics.highlights:
            html_sections.append(self._render_list("Growth Highlights", metrics.highlights))
        if metrics.spotlight_examples:
            for category, entries in metrics.spotlight_examples.items():
                html_sections.append(
                    self._render_list(f"Spotlight â€” {category.replace('_', ' ').title()}", entries)
                )
        if metrics.yearbook_story:
            paragraphs = "".join(f"<p>{escape(paragraph)}</p>" for paragraph in metrics.yearbook_story)
            html_sections.append(f"<section><h2>Year in Review</h2>{paragraphs}</section>")
        if metrics.awards:
            awards_html = f"<section><h2>ðŸ† Awards Cabinet</h2>"
            awards_html += f"<p><strong>ì´ {len(metrics.awards)}ê°œì˜ ì–´ì›Œë“œë¥¼ íšë“í–ˆìŠµë‹ˆë‹¤!</strong></p>"

            # Categorize awards
            categories = self._categorize_awards(metrics.awards)

            for category_name, category_awards in categories.items():
                if category_awards:
                    awards_html += f"<h3>{escape(category_name)}</h3>"
                    awards_html += "<ul>"
                    for award in category_awards:
                        awards_html += f"<li>{escape(award)}</li>"
                    awards_html += "</ul>"

            awards_html += "</section>"
            html_sections.append(awards_html)

        evidence_sections = []
        for domain, links in metrics.evidence.items():
            link_items = "".join(
                f"<li><a href='{escape(link)}' target='_blank' rel='noopener'>{escape(link)}</a></li>"
                for link in links
            )
            if link_items:
                evidence_sections.append(
                    f"<section><h3>{escape(domain.title())}</h3><ul>{link_items}</ul></section>"
                )
        if evidence_sections:
            html_sections.append("<section><h2>Evidence</h2>" + "".join(evidence_sections) + "</section>")

        html_report = f"""
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>GitHub Feedback Report â€” {escape(metrics.repo)}</title>
    <style>
        :root {{
            color-scheme: light dark;
            font-family: 'Segoe UI', Roboto, sans-serif;
            background-color: #0f172a;
            color: #e2e8f0;
        }}
        body {{
            margin: 0 auto;
            max-width: 960px;
            padding: 2rem 1.5rem 4rem;
            line-height: 1.6;
        }}
        section {{
            margin-bottom: 2rem;
            background: rgba(15, 23, 42, 0.6);
            padding: 1.5rem;
            border-radius: 1rem;
            box-shadow: 0 10px 30px rgba(15, 23, 42, 0.35);
        }}
        h1, h2, h3 {{
            margin-top: 0;
            color: #38bdf8;
        }}
        table {{
            width: 100%;
            border-collapse: collapse;
        }}
        th, td {{
            padding: 0.6rem 0.8rem;
            border-bottom: 1px solid rgba(148, 163, 184, 0.2);
            text-align: left;
        }}
        figure {{
            margin: 0;
            display: grid;
            gap: 0.5rem;
            justify-items: center;
        }}
        figure img {{
            max-width: 100%;
            border-radius: 0.75rem;
            background: rgba(148, 163, 184, 0.12);
            padding: 0.5rem;
        }}
        a {{
            color: #38bdf8;
        }}
    </style>
</head>
<body>
    {''.join(html_sections)}
</body>
</html>
"""

        report_path.write_text(html_report, encoding="utf-8")
        return report_path

