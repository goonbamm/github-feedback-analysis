"""Report generation for GitHub feedback analysis."""

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Any, Callable, Dict, Iterable, List, Optional, Protocol, Tuple, Union

from .console import Console
from .constants import AWARD_CATEGORIES, AWARD_KEYWORDS, COLLECTION_LIMITS, DISPLAY_LIMITS
from .models import (
    CommitMessageFeedback,
    IssueFeedback,
    MetricSnapshot,
    PRTitleFeedback,
    PromptRequest,
    ReviewToneFeedback,
)

console = Console()

# Type alias for feedback data structures
FeedbackData = Union[CommitMessageFeedback, PRTitleFeedback, ReviewToneFeedback, IssueFeedback]


# ============================================================================
# Helper Classes for Report Generation
# ============================================================================

class MarkdownSectionBuilder:
    """Helper class for building markdown sections with common patterns."""

    @staticmethod
    def build_section(
        title: str,
        description: str = "",
        emoji: str = ""
    ) -> List[str]:
        """Build a section header with optional description."""
        lines = []
        header = f"### {emoji} {title}" if emoji else f"### {title}"
        lines.append(header)
        lines.append("")

        if description:
            lines.append(f"> {description}")
            lines.append("")

        return lines

    @staticmethod
    def build_table(headers: List[str], rows: List[List[str]]) -> List[str]:
        """Build a markdown table from headers and rows."""
        lines = []
        lines.append("| " + " | ".join(headers) + " |")
        lines.append("|" + "|".join(["---"] * len(headers)) + "|")

        for row in rows:
            lines.append("| " + " | ".join(str(cell) for cell in row) + " |")

        lines.append("")
        return lines

    @staticmethod
    def build_list(items: List[str], prefix: str = "-") -> List[str]:
        """Build a markdown list from items."""
        return [f"{prefix} {item}" for item in items] + [""]

    @staticmethod
    def build_subsection(
        data_check: Any,
        title: str,
        content_builder: Callable[[], List[str]],
        emoji: str = "",
        description: str = ""
    ) -> List[str]:
        """Build a subsection if data exists, using a content builder function."""
        lines = []
        if data_check:
            lines.extend(MarkdownSectionBuilder.build_section(title, description, emoji))
            lines.extend(content_builder())
        return lines


def _format_metric_value(value: object) -> str:
    """Format numeric values with separators while keeping strings intact."""

    if isinstance(value, bool):
        return str(value)
    if isinstance(value, int):
        return f"{value:,}"
    if isinstance(value, float):
        return f"{value:,.2f}"
    return str(value)


@dataclass(slots=True)
class Reporter:
    """Create human-readable artefacts from metrics."""

    output_dir: Path = Path("reports")

    def ensure_structure(self) -> None:
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def _categorize_awards(self, awards: List[str]) -> dict:
        """Categorize awards by type for better organization."""
        # Initialize categories from constants
        categories = {label: [] for label in AWARD_CATEGORIES.values()}

        for award in awards:
            categorized = False
            # Check each category's keywords
            for category_key, keywords in AWARD_KEYWORDS.items():
                if any(keyword in award for keyword in keywords):
                    category_label = AWARD_CATEGORIES[category_key]
                    categories[category_label].append(award)
                    categorized = True
                    break

            # Default category if no keywords match
            if not categorized:
                categories[AWARD_CATEGORIES['basic']].append(award)

        # Remove empty categories
        return {k: v for k, v in categories.items() if v}


    def _build_prompt_context(self, metrics: MetricSnapshot) -> str:
        """Create a reusable context block describing the metrics."""

        lines: List[str] = []
        period_label = (
            f"ì§€ë‚œ {metrics.months}ê°œì›”"
            if metrics.months and metrics.months < 12
            else "ì˜¬í•´"
        )

        lines.append(f"Repository: {metrics.repo}")
        lines.append(f"Period: {period_label}")
        lines.append("")

        if metrics.summary:
            lines.append("Summary:")
            for key, value in metrics.summary.items():
                lines.append(f"- {key.title()}: {value}")
            lines.append("")

        if metrics.stats:
            lines.append("Metrics:")
            for domain, domain_stats in metrics.stats.items():
                lines.append(f"- {domain.title()}:")
                for stat_name, stat_value in domain_stats.items():
                    lines.append(
                        "  â€¢ {}: {}".format(
                            stat_name.replace("_", " ").title(),
                            _format_metric_value(stat_value)
                            if isinstance(stat_value, (int, float))
                            else stat_value,
                        )
                    )
            lines.append("")

        if metrics.highlights:
            lines.append("Growth Highlights:")
            for highlight in metrics.highlights:
                lines.append(f"- {highlight}")
            lines.append("")

        if metrics.spotlight_examples:
            lines.append("Spotlight Examples:")
            for category, entries in metrics.spotlight_examples.items():
                lines.append(f"- {category.replace('_', ' ').title()}")
                for entry in entries:
                    lines.append(f"  â€¢ {entry}")
            lines.append("")

        if metrics.yearbook_story:
            lines.append("Year In Review:")
            for paragraph in metrics.yearbook_story:
                lines.append(f"- {paragraph}")
            lines.append("")

        if metrics.awards:
            lines.append("Awards:")
            for award in metrics.awards:
                lines.append(f"- {award}")
            lines.append("")

        if metrics.evidence:
            lines.append("Evidence Links:")
            for domain, links in metrics.evidence.items():
                for link in links:
                    lines.append(f"- {domain.title()}: {link}")

        return "\n".join(lines).strip()

    def _build_header_and_summary(self, metrics: MetricSnapshot) -> List[str]:
        """Build header and summary section."""
        lines = ["# ğŸš€ GitHub Feedback Report", ""]
        lines.append(f"**Repository**: {metrics.repo}")
        lines.append(f"**Period**: {metrics.months} months")

        if metrics.since_date and metrics.until_date:
            since_str = metrics.since_date.strftime("%Y-%m-%d")
            until_str = metrics.until_date.strftime("%Y-%m-%d")
            lines.append(f"**Analysis Period**: {since_str} ~ {until_str}")

        lines.append("")
        lines.append("---")
        lines.append("")

        return lines

    def _build_table_of_contents(self, metrics: MetricSnapshot) -> List[str]:
        """Build table of contents section."""
        lines = ["## ğŸ“‘ ëª©ì°¨", ""]

        sections = [
            ("ğŸ“Š Executive Summary", "í•œëˆˆì— ë³´ëŠ” í•µì‹¬ ì§€í‘œ"),
            ("ğŸ† Awards Cabinet", "íšë“í•œ ì–´ì›Œë“œ"),
            ("âœ¨ Growth Highlights", "ì„±ì¥ í•˜ì´ë¼ì´íŠ¸"),
            ("ğŸ“ˆ Monthly Trends", "ì›”ë³„ í™œë™ íŠ¸ë Œë“œ"),
        ]

        if metrics.detailed_feedback:
            sections.append(("ğŸ’¡ Detailed Feedback", "ìƒì„¸ í”¼ë“œë°±"))

        # Add retrospective section
        if metrics.retrospective:
            sections.append(("ğŸ” Deep Retrospective", "ì‹¬ì¸µ íšŒê³  ë¶„ì„"))

        sections.extend([
            ("ğŸ¯ Spotlight Examples", "ì£¼ìš” ê¸°ì—¬ ì‚¬ë¡€"),
            ("ğŸ’» Tech Stack", "ê¸°ìˆ  ìŠ¤íƒ ë¶„ì„"),
            ("ğŸ¤ Collaboration", "í˜‘ì—… ë„¤íŠ¸ì›Œí¬"),
            ("ğŸ¤” Reflection", "íšŒê³  ì§ˆë¬¸"),
            ("ğŸ“Š Detailed Metrics", "ìƒì„¸ ë©”íŠ¸ë¦­"),
            ("ğŸ”— Evidence", "ì¦ê±° ë§í¬"),
        ])

        for i, (title, desc) in enumerate(sections, 1):
            lines.append(f"{i}. **{title}** - {desc}")

        lines.append("")
        lines.append("---")
        lines.append("")
        return lines

    def _build_executive_summary(self, metrics: MetricSnapshot) -> List[str]:
        """Build executive summary section with key highlights."""
        lines = ["## ğŸ“Š Executive Summary", ""]
        lines.append("> í™œë™ ê¸°ê°„ì˜ í•µì‹¬ ì„±ê³¼ë¥¼ í•œëˆˆì— í™•ì¸í•˜ì„¸ìš”")
        lines.append("")

        # Key metrics in a box format
        total_activity = sum([
            metrics.stats.get("commits", {}).get("total", 0),
            metrics.stats.get("pull_requests", {}).get("total", 0),
            metrics.stats.get("reviews", {}).get("total", 0),
        ])

        lines.append("### ğŸ“ˆ í•µì‹¬ ì§€í‘œ")
        lines.append("")
        lines.append("| ì§€í‘œ | ê°’ | ì„¤ëª… |")
        lines.append("|------|-----|------|")

        for key, value in metrics.summary.items():
            display_value = (
                _format_metric_value(value) if isinstance(value, (int, float)) else str(value)
            )
            # Add descriptions for each metric
            descriptions = {
                "velocity": "ì›”í‰ê·  ì»¤ë°‹ ì†ë„",
                "collaboration": "ì›”í‰ê·  í˜‘ì—… í™œë™",
                "stability": "ì•ˆì •ì„± ì ìˆ˜",
                "growth": "ì „ì²´ ì„±ì¥ ìš”ì•½"
            }
            desc = descriptions.get(key, "")
            lines.append(f"| **{key.title()}** | {display_value} | {desc} |")

        lines.append("")

        # Quick stats
        if metrics.awards:
            lines.append(f"ğŸ† **ì´ {len(metrics.awards)}ê°œì˜ ì–´ì›Œë“œ íšë“**")

        if metrics.highlights:
            lines.append(f"âœ¨ **{len(metrics.highlights)}ê°œì˜ ì£¼ìš” ì„±ê³¼**")

        lines.append("")
        lines.append("---")
        lines.append("")

        return lines

    def _build_metrics_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build metrics section."""
        lines = ["## ğŸ“Š Detailed Metrics", ""]
        lines.append("> ê° í™œë™ ì˜ì—­ë³„ ìƒì„¸ ìˆ˜ì¹˜ë¥¼ í™•ì¸í•˜ì„¸ìš”")
        lines.append("")

        for domain, domain_stats in metrics.stats.items():
            lines.append(f"### {domain.title()}")
            lines.append("")
            lines.append("| ì§€í‘œ | ê°’ |")
            lines.append("|------|-----|")
            for stat_name, stat_value in domain_stats.items():
                formatted_value = (
                    _format_metric_value(stat_value)
                    if isinstance(stat_value, (int, float))
                    else str(stat_value)
                )
                lines.append(f"| {stat_name.replace('_', ' ').title()} | {formatted_value} |")
            lines.append("")
        return lines

    def _build_highlights_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build growth highlights section."""
        if not metrics.highlights:
            return []

        lines = ["## âœ¨ Growth Highlights", ""]
        lines.append("> ì´ë²ˆ ê¸°ê°„ ë™ì•ˆì˜ ì£¼ìš” ì„±ê³¼ì™€ ì„±ì¥ í¬ì¸íŠ¸")
        lines.append("")
        lines.append("| # | ì„±ê³¼ |")
        lines.append("|---|------|")
        for i, highlight in enumerate(metrics.highlights, 1):
            lines.append(f"| {i} | {highlight} |")
        lines.append("")
        lines.append("---")
        lines.append("")
        return lines

    def _build_spotlight_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build spotlight examples section."""
        if not metrics.spotlight_examples:
            return []

        lines = ["## ğŸ¯ Spotlight Examples", ""]
        lines.append("> ì£¼ëª©í•  ë§Œí•œ ê¸°ì—¬ ì‚¬ë¡€")
        lines.append("")
        for category, entries in metrics.spotlight_examples.items():
            lines.append(f"### {category.replace('_', ' ').title()}")
            lines.append("")
            lines.append("| ì‚¬ë¡€ |")
            lines.append("|------|")
            for entry in entries:
                lines.append(f"| {entry} |")
            lines.append("")
        lines.append("---")
        lines.append("")
        return lines

    def _build_year_in_review_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build comprehensive year in review section combining story and detailed review."""
        if not metrics.yearbook_story and not metrics.year_end_review:
            return []

        lines = ["## ğŸ“… Year in Review", ""]
        lines.append("> í•œ í•´ì˜ ì—¬ì •ì„ ëŒì•„ë´…ë‹ˆë‹¤")
        lines.append("")

        # Story beats
        if metrics.yearbook_story:
            lines.append("### ğŸŒŸ ì˜¬í•´ì˜ ì´ì•¼ê¸°")
            lines.append("")
            for paragraph in metrics.yearbook_story:
                lines.append(paragraph)
                lines.append("")

        # Year end review details
        if metrics.year_end_review:
            if metrics.year_end_review.proudest_moments:
                lines.append("### ğŸ… ìë‘ìŠ¤ëŸ¬ìš´ ìˆœê°„ë“¤")
                lines.append("")
                lines.append("| ìˆœê°„ |")
                lines.append("|------|")
                for moment in metrics.year_end_review.proudest_moments:
                    lines.append(f"| {moment} |")
                lines.append("")

            if metrics.year_end_review.biggest_challenges:
                lines.append("### ğŸ’ª ê·¹ë³µí•œ ë„ì „ë“¤")
                lines.append("")
                lines.append("| ë„ì „ |")
                lines.append("|------|")
                for challenge in metrics.year_end_review.biggest_challenges:
                    lines.append(f"| {challenge} |")
                lines.append("")

            if metrics.year_end_review.lessons_learned:
                lines.append("### ğŸ“š ë°°ìš´ êµí›ˆë“¤")
                lines.append("")
                lines.append("| êµí›ˆ |")
                lines.append("|------|")
                for lesson in metrics.year_end_review.lessons_learned:
                    lines.append(f"| {lesson} |")
                lines.append("")

            if metrics.year_end_review.next_year_goals:
                lines.append("### ğŸ¯ ë‚´ë…„ ëª©í‘œ")
                lines.append("")
                lines.append("| ëª©í‘œ |")
                lines.append("|------|")
                for goal in metrics.year_end_review.next_year_goals:
                    lines.append(f"| {goal} |")
                lines.append("")

        lines.append("---")
        lines.append("")
        return lines

    def _build_awards_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build awards cabinet section."""
        if not metrics.awards:
            return []

        lines = ["## ğŸ† Awards Cabinet", ""]
        lines.append(f"**ì´ {len(metrics.awards)}ê°œì˜ ì–´ì›Œë“œë¥¼ íšë“í–ˆìŠµë‹ˆë‹¤!**")
        lines.append("")

        categories = self._categorize_awards(metrics.awards)
        for category_name, category_awards in categories.items():
            if category_awards:
                lines.append(f"### {category_name}")
                lines.append("")
                lines.append("| ì–´ì›Œë“œ |")
                lines.append("|--------|")
                for award in category_awards:
                    lines.append(f"| {award} |")
                lines.append("")
        lines.append("---")
        lines.append("")
        return lines


    def _build_detailed_feedback_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build detailed feedback section."""
        if not metrics.detailed_feedback:
            return []

        lines = ["## ğŸ’¡ Detailed Feedback", ""]
        lines.append("> ì½”ë“œ, PR, ë¦¬ë·°, ì´ìŠˆ í’ˆì§ˆì— ëŒ€í•œ ìƒì„¸ ë¶„ì„")
        lines.append("")
        feedback = metrics.detailed_feedback

        # Commit message feedback
        if feedback.commit_feedback:
            lines.extend(self._build_commit_feedback(feedback.commit_feedback))

        # PR title feedback
        if feedback.pr_title_feedback:
            lines.extend(self._build_pr_title_feedback(feedback.pr_title_feedback))

        # Review tone feedback
        if feedback.review_tone_feedback:
            lines.extend(self._build_review_tone_feedback(feedback.review_tone_feedback))

        # Issue feedback
        if feedback.issue_feedback:
            lines.extend(self._build_issue_feedback(feedback.issue_feedback))

        lines.append("---")
        lines.append("")
        return lines

    def _build_feedback_section(
        self,
        title: str,
        feedback_data: FeedbackData,
        stats_config: Dict[str, str],
        example_formatter: Optional[Callable[[Any], str]] = None,
        examples_poor_attr: str = "examples_poor"
    ) -> List[str]:
        """Build a feedback subsection with a common structure.

        Args:
            title: Section title (e.g., "### ğŸ“ ì»¤ë°‹ ë©”ì‹œì§€ í’ˆì§ˆ")
            feedback_data: Feedback data object with stats and examples
            stats_config: Dictionary mapping stat names to labels
                - 'total': tuple of (attribute_name, label, unit)
                - 'good': tuple of (attribute_name, label, unit)
                - 'poor': tuple of (attribute_name, label, unit)
                - additional stats as needed
            example_formatter: Optional function to format examples
            examples_poor_attr: Attribute name for poor examples (default: "examples_poor")

        Returns:
            List of markdown lines
        """
        lines = [title, ""]

        # Build summary statistics as a table
        total_attr, total_label, unit = stats_config.get('total', (None, None, 'ê°œ'))
        good_attr, good_label, _ = stats_config.get('good', (None, None, 'ê°œ'))
        poor_attr, poor_label, _ = stats_config.get('poor', (None, None, 'ê°œ'))

        total_value = getattr(feedback_data, total_attr, 0) if total_attr else 0
        good_value = getattr(feedback_data, good_attr, 0) if good_attr else 0
        poor_value = getattr(feedback_data, poor_attr, 0) if poor_attr else 0

        lines.append("| ì§€í‘œ | ê°’ |")
        lines.append("|------|-----|")

        if total_value > 0:
            good_pct = (good_value / total_value) * 100
            lines.append(f"| {total_label} | {total_value:,}{unit} |")
            lines.append(f"| {good_label} | {good_value:,}{unit} ({good_pct:.1f}%) |")
            lines.append(f"| {poor_label} | {poor_value:,}{unit} |")

            # Add additional stats if configured
            for key, (attr, label, stat_unit) in stats_config.items():
                if key not in ('total', 'good', 'poor'):
                    value = getattr(feedback_data, attr, 0)
                    lines.append(f"| {label} | {value:,}{stat_unit} |")
        else:
            lines.append(f"| {total_label} | {total_value} |")
            lines.append(f"| {good_label} | {good_value} |")
            lines.append(f"| {poor_label} | {poor_value} |")

            # Add additional stats if configured
            for key, (attr, label, stat_unit) in stats_config.items():
                if key not in ('total', 'good', 'poor'):
                    value = getattr(feedback_data, attr, 0)
                    lines.append(f"| {label} | {value} |")
        lines.append("")

        # Suggestions section
        if hasattr(feedback_data, 'suggestions') and feedback_data.suggestions:
            lines.append("#### ğŸ’¡ ê°œì„  ì œì•ˆ")
            lines.append("")
            lines.append("| # | ì œì•ˆ |")
            lines.append("|---|------|")
            for i, suggestion in enumerate(feedback_data.suggestions, 1):
                lines.append(f"| {i} | {suggestion} |")
            lines.append("")

        # Good examples section
        if hasattr(feedback_data, 'examples_good') and feedback_data.examples_good:
            lines.append("#### âœ… ì¢‹ì€ ì˜ˆì‹œ")
            lines.append("")
            lines.append("| ì˜ˆì‹œ |")
            lines.append("|------|")
            for example in feedback_data.examples_good[:DISPLAY_LIMITS['feedback_examples']]:
                if example_formatter:
                    lines.append(f"| {example_formatter(example)} |")
                elif isinstance(example, dict):
                    lines.append(f"| {example} |")
                else:
                    lines.append(f"| {example} |")
            lines.append("")

        # Poor/improve examples section
        poor_examples = getattr(feedback_data, examples_poor_attr, None)
        if poor_examples:
            lines.append("#### âš ï¸ ê°œì„ ì´ í•„ìš”í•œ ì˜ˆì‹œ")
            lines.append("")
            lines.append("| ì˜ˆì‹œ |")
            lines.append("|------|")
            for example in poor_examples[:DISPLAY_LIMITS['feedback_examples']]:
                if example_formatter:
                    lines.append(f"| {example_formatter(example)} |")
                elif isinstance(example, dict):
                    lines.append(f"| {example} |")
                else:
                    lines.append(f"| {example} |")
            lines.append("")

        return lines

    def _build_commit_feedback(self, commit_feedback) -> List[str]:
        """Build commit feedback subsection."""
        def format_commit_example(example):
            if isinstance(example, dict):
                return f"`{example.get('message', '')}` ({example.get('sha', '')[:7]})"
            return str(example)

        return self._build_feedback_section(
            title="### ğŸ“ ì»¤ë°‹ ë©”ì‹œì§€ í’ˆì§ˆ",
            feedback_data=commit_feedback,
            stats_config={
                'total': ('total_commits', 'ì´ ì»¤ë°‹', 'ê°œ'),
                'good': ('good_messages', 'ì¢‹ì€ ë©”ì‹œì§€', 'ê°œ'),
                'poor': ('poor_messages', 'ê°œì„  í•„ìš”', 'ê°œ'),
            },
            example_formatter=format_commit_example,
        )

    def _build_pr_title_feedback(self, pr_title_feedback) -> List[str]:
        """Build PR title feedback subsection."""
        def format_pr_example(example):
            if isinstance(example, dict):
                return f"#{example.get('number', '')}: `{example.get('title', '')}`"
            return str(example)

        return self._build_feedback_section(
            title="### ğŸ”€ PR ì œëª© í’ˆì§ˆ",
            feedback_data=pr_title_feedback,
            stats_config={
                'total': ('total_prs', 'ì´ PR', 'ê°œ'),
                'good': ('clear_titles', 'ëª…í™•í•œ ì œëª©', 'ê°œ'),
                'poor': ('vague_titles', 'ëª¨í˜¸í•œ ì œëª©', 'ê°œ'),
            },
            example_formatter=format_pr_example,
        )

    def _build_review_tone_feedback(self, review_tone_feedback) -> List[str]:
        """Build review tone feedback subsection."""
        return self._build_feedback_section(
            title="### ğŸ‘€ ë¦¬ë·° í†¤ ë¶„ì„",
            feedback_data=review_tone_feedback,
            stats_config={
                'total': ('total_reviews', 'ì´ ë¦¬ë·°', 'ê°œ'),
                'good': ('constructive_reviews', 'ê±´ì„¤ì ì¸ ë¦¬ë·°', 'ê°œ'),
                'poor': ('harsh_reviews', 'ê°€í˜¹í•œ ë¦¬ë·°', 'ê°œ'),
                'neutral': ('neutral_reviews', 'ì¤‘ë¦½ì ì¸ ë¦¬ë·°', 'ê°œ'),
            },
            examples_poor_attr='examples_improve',
        )

    def _build_issue_feedback(self, issue_feedback) -> List[str]:
        """Build issue feedback subsection."""
        def format_issue_example(example):
            if isinstance(example, dict):
                return f"#{example.get('number', '')}: `{example.get('title', '')}`"
            return str(example)

        return self._build_feedback_section(
            title="### ğŸ› ì´ìŠˆ í’ˆì§ˆ",
            feedback_data=issue_feedback,
            stats_config={
                'total': ('total_issues', 'ì´ ì´ìŠˆ', 'ê°œ'),
                'good': ('well_described', 'ì˜ ì‘ì„±ë¨', 'ê°œ'),
                'poor': ('poorly_described', 'ê°œì„  í•„ìš”', 'ê°œ'),
            },
            example_formatter=format_issue_example,
        )

    def _build_monthly_trends_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build monthly trends section."""
        if not metrics.monthly_trends:
            return []

        lines = ["## ğŸ“ˆ Monthly Trends", ""]
        lines.append("> ì›”ë³„ í™œë™ íŒ¨í„´ê³¼ íŠ¸ë Œë“œ ë¶„ì„")
        lines.append("")

        if metrics.monthly_insights and metrics.monthly_insights.insights:
            lines.append("### ğŸ’¡ ì¸ì‚¬ì´íŠ¸")
            lines.append("")
            for i, insight in enumerate(metrics.monthly_insights.insights, 1):
                lines.append(f"{i}. {insight}")
            lines.append("")

        lines.append("### ğŸ“Š ì›”ë³„ ìƒì„¸ ë°ì´í„°")
        lines.append("")
        lines.append("| ì›” | ì»¤ë°‹ | PR | ë¦¬ë·° | ì´ìŠˆ | ì´ í™œë™ |")
        lines.append("|---|---|---|---|---|---|")
        for trend in metrics.monthly_trends:
            total_activity = trend.commits + trend.pull_requests + trend.reviews + trend.issues
            lines.append(
                f"| {trend.month} | {trend.commits} | {trend.pull_requests} | "
                f"{trend.reviews} | {trend.issues} | **{total_activity}** |"
            )
        lines.append("")
        lines.append("---")
        lines.append("")
        return lines

    def _build_tech_stack_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build tech stack section."""
        if not metrics.tech_stack:
            return []

        lines = ["## ğŸ’» Tech Stack Analysis", ""]
        lines.append("> ì‚¬ìš©í•œ ê¸°ìˆ ê³¼ ì–¸ì–´ ë¶„í¬")
        lines.append("")
        lines.append(f"**ë‹¤ì–‘ì„± ì ìˆ˜**: {metrics.tech_stack.diversity_score:.2f} (0-1 ì²™ë„)")
        lines.append("")
        lines.append("| ìˆœìœ„ | ì–¸ì–´ | íŒŒì¼ ìˆ˜ |")
        lines.append("|------|------|---------|")
        for i, lang in enumerate(metrics.tech_stack.top_languages[:DISPLAY_LIMITS['top_languages']], 1):
            count = metrics.tech_stack.languages.get(lang, 0)
            lines.append(f"| {i} | {lang} | {count:,} |")
        lines.append("")
        lines.append("---")
        lines.append("")
        return lines

    def _build_collaboration_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build collaboration section."""
        if not metrics.collaboration:
            return []

        lines = ["## ğŸ¤ Collaboration Network", ""]
        lines.append("> í•¨ê»˜ ì„±ì¥í•œ ë™ë£Œë“¤ê³¼ì˜ í˜‘ì—…")
        lines.append("")

        lines.append("| í•­ëª© | ê°’ |")
        lines.append("|------|-----|")
        lines.append(f"| ë°›ì€ ë¦¬ë·° ìˆ˜ | {metrics.collaboration.review_received_count:,}ê±´ |")
        lines.append(f"| í˜‘ì—…í•œ ì‚¬ëŒ ìˆ˜ | {metrics.collaboration.unique_collaborators:,}ëª… |")
        lines.append("")

        if metrics.collaboration.top_reviewers:
            lines.append("### ğŸŒŸ ì£¼ìš” ë¦¬ë·°ì–´")
            lines.append("")
            lines.append("| ìˆœìœ„ | ë¦¬ë·°ì–´ | ë¦¬ë·° íšŸìˆ˜ |")
            lines.append("|------|--------|-----------|")
            for i, reviewer in enumerate(metrics.collaboration.top_reviewers, 1):
                count = metrics.collaboration.pr_reviewers.get(reviewer, 0)
                lines.append(f"| {i} | @{reviewer} | {count:,}íšŒ |")
            lines.append("")
        lines.append("---")
        lines.append("")
        return lines

    def _build_reflection_prompts_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build reflection prompts section."""
        if not (metrics.reflection_prompts and metrics.reflection_prompts.questions):
            return []

        lines = ["## ğŸ¤” Reflection Prompts", ""]
        lines.append("> ìŠ¤ìŠ¤ë¡œì—ê²Œ ë¬¼ì–´ë³´ì„¸ìš”")
        lines.append("")
        lines.append("| # | ì§ˆë¬¸ |")
        lines.append("|---|------|")
        for i, question in enumerate(metrics.reflection_prompts.questions, 1):
            lines.append(f"| {i} | {question} |")
        lines.append("")
        lines.append("---")
        lines.append("")
        return lines

    def _build_evidence_section_improved(self, metrics: MetricSnapshot) -> List[str]:
        """Build evidence section."""
        if not metrics.evidence:
            return []

        lines = ["## ğŸ”— Evidence Links", ""]
        lines.append("> ìƒì„¸ ë°ì´í„°ë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ” ë§í¬")
        lines.append("")
        for domain, links in metrics.evidence.items():
            lines.append(f"### {domain.title()}")
            for link in links:
                lines.append(f"- [{domain.title()} ë³´ê¸°]({link})")
            lines.append("")
        lines.append("---")
        lines.append("")
        return lines

    def _build_executive_summary_subsection(self, retro) -> List[str]:
        """Build executive summary subsection of retrospective."""
        def build_content():
            return [retro.executive_summary, ""]

        return MarkdownSectionBuilder.build_subsection(
            retro.executive_summary,
            "íšŒê³  ìš”ì•½",
            build_content,
            emoji="ğŸ“‹"
        )

    def _build_key_wins_subsection(self, retro) -> List[str]:
        """Build key wins subsection of retrospective."""
        def build_content():
            rows = [[str(i), win] for i, win in enumerate(retro.key_wins, 1)]
            return MarkdownSectionBuilder.build_table(["#", "ì„±ê³¼"], rows)

        return MarkdownSectionBuilder.build_subsection(
            retro.key_wins,
            "ì£¼ìš” ì„±ê³¼",
            build_content,
            emoji="ğŸ‰",
            description="ì´ë²ˆ ê¸°ê°„ ë™ì•ˆ ë‹¬ì„±í•œ í•µì‹¬ ì„±ê³¼ë“¤ì…ë‹ˆë‹¤"
        )

    def _build_time_comparisons_subsection(self, retro) -> List[str]:
        """Build time comparisons subsection of retrospective using helper."""
        def build_content():
            rows = []
            for tc in retro.time_comparisons:
                direction_emoji = {"increasing": "ğŸ“ˆ", "decreasing": "ğŸ“‰"}.get(tc.direction, "â¡ï¸")
                significance_text = {
                    "major": "í° ë³€í™”",
                    "moderate": "ì¤‘ê°„ ë³€í™”",
                    "minor": "ì‘ì€ ë³€í™”"
                }.get(tc.significance, tc.significance)

                rows.append([
                    tc.metric_name,
                    f"{tc.previous_value:.1f}",
                    f"{tc.current_value:.1f}",
                    f"{tc.change_absolute:+.1f}",
                    f"{tc.change_percentage:+.1f}%",
                    f"{direction_emoji} {significance_text}"
                ])

            return MarkdownSectionBuilder.build_table(
                ["ì§€í‘œ", "ì „ë°˜ê¸°", "í›„ë°˜ê¸°", "ë³€í™”ëŸ‰", "ë³€í™”ìœ¨", "ì˜ë¯¸"],
                rows
            )

        return MarkdownSectionBuilder.build_subsection(
            retro.time_comparisons,
            "ê¸°ê°„ ë¹„êµ ë¶„ì„",
            build_content,
            emoji="ğŸ“Š",
            description="ì „ë°˜ê¸°ì™€ í›„ë°˜ê¸°ì˜ ë³€í™” ì¶”ì´ë¥¼ ë¹„êµí•©ë‹ˆë‹¤"
        )

    def _build_behavior_patterns_subsection(self, retro) -> List[str]:
        """Build behavior patterns subsection of retrospective."""
        lines = []
        if retro.behavior_patterns:
            lines.append("### ğŸ§  í–‰ë™ íŒ¨í„´ ë¶„ì„")
            lines.append("")
            lines.append("> ì‘ì—… íŒ¨í„´ê³¼ ìŠµê´€ì—ì„œ ë°œê²¬ëœ ì¸ì‚¬ì´íŠ¸")
            lines.append("")
            lines.append("| ì˜í–¥ | íŒ¨í„´ | ì œì•ˆ |")
            lines.append("|------|------|------|")

            for pattern in retro.behavior_patterns:
                impact_emoji = "âœ…" if pattern.impact == "positive" else "âš ï¸" if pattern.impact == "negative" else "â„¹ï¸"
                recommendation = pattern.recommendation if pattern.recommendation else "-"
                lines.append(f"| {impact_emoji} | {pattern.description} | {recommendation} |")
            lines.append("")
        return lines

    def _build_learning_insights_subsection(self, retro) -> List[str]:
        """Build learning insights subsection of retrospective."""
        lines = []
        if retro.learning_insights:
            lines.append("### ğŸ“š í•™ìŠµ ë° ì„±ì¥ ë¶„ì„")
            lines.append("")
            lines.append("> ê¸°ìˆ  ì—­ëŸ‰ê³¼ í•™ìŠµ ê¶¤ì ì„ ë¶„ì„í•©ë‹ˆë‹¤")
            lines.append("")
            lines.append("| ë¶„ì•¼ | ê¸°ìˆ  | ì „ë¬¸ì„± | ì„±ì¥ ì§€í‘œ |")
            lines.append("|------|------|--------|-----------|")

            for learning in retro.learning_insights:
                expertise_emoji = {"expert": "ğŸ‘‘", "proficient": "â­", "developing": "ğŸŒ±", "exploring": "ğŸ”"}.get(
                    learning.expertise_level, "ğŸ“–"
                )
                technologies = ', '.join(learning.technologies)
                growth_indicators = '<br>'.join(f"â€¢ {ind}" for ind in learning.growth_indicators[:DISPLAY_LIMITS['growth_indicators']]) if learning.growth_indicators else "-"
                lines.append(
                    f"| {expertise_emoji} {learning.domain} | {technologies} | {learning.expertise_level} | {growth_indicators} |"
                )
            lines.append("")
        return lines

    def _build_impact_assessments_subsection(self, retro) -> List[str]:
        """Build impact assessments subsection of retrospective."""
        lines = []
        if retro.impact_assessments:
            lines.append("### ğŸ’ ì˜í–¥ë„ í‰ê°€")
            lines.append("")
            lines.append("> ê¸°ì—¬ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ë° íŒ€ ì˜í–¥ì„ í‰ê°€í•©ë‹ˆë‹¤")
            lines.append("")
            lines.append("| ì¹´í…Œê³ ë¦¬ | ê¸°ì—¬ íšŸìˆ˜ | ì˜í–¥ë„ | ì„¤ëª… |")
            lines.append("|----------|-----------|--------|------|")

            for impact in retro.impact_assessments:
                impact_emoji = {"high": "ğŸ”¥", "medium": "âœ¨", "low": "ğŸ’¡"}.get(impact.estimated_impact, "ğŸ“Š")
                lines.append(
                    f"| {impact_emoji} {impact.category} | {impact.contribution_count:,}ê±´ | "
                    f"{impact.estimated_impact} | {impact.impact_description} |"
                )
            lines.append("")
        return lines

    def _build_collaboration_insights_subsection(self, retro) -> List[str]:
        """Build collaboration insights subsection of retrospective."""
        lines = []
        if retro.collaboration_insights:
            collab = retro.collaboration_insights
            lines.append("### ğŸ¤ í˜‘ì—… ì‹¬ì¸µ ë¶„ì„")
            lines.append("")
            lines.append(f"**í˜‘ì—… ê°•ë„:** {collab.collaboration_strength}")
            lines.append(f"**í˜‘ì—… í’ˆì§ˆ:** {collab.collaboration_quality}")
            lines.append("")

            if collab.key_partnerships:
                lines.append("**ì£¼ìš” í˜‘ì—… íŒŒíŠ¸ë„ˆ:**")
                lines.append("")
                lines.append("| í˜‘ì—…ì | ë¦¬ë·° íšŸìˆ˜ | ê´€ê³„ |")
                lines.append("|--------|-----------|------|")
                for person, count, rel_type in collab.key_partnerships:
                    lines.append(f"| @{person} | {count}íšŒ | {rel_type} |")
                lines.append("")

            if collab.mentorship_indicators:
                lines.append("**ë©˜í† ë§ í™œë™:**")
                for indicator in collab.mentorship_indicators:
                    lines.append(f"- {indicator}")
                lines.append("")

            if collab.improvement_areas:
                lines.append("**ê°œì„  ì˜ì—­:**")
                for area in collab.improvement_areas:
                    lines.append(f"- {area}")
                lines.append("")
            lines.append("")
        return lines

    def _build_balance_metrics_subsection(self, retro) -> List[str]:
        """Build balance metrics subsection of retrospective."""
        lines = []
        if retro.balance_metrics:
            balance = retro.balance_metrics
            lines.append("### âš–ï¸ ì—…ë¬´ ë°¸ëŸ°ìŠ¤ ë¶„ì„")
            lines.append("")

            risk_emoji = {"low": "âœ…", "moderate": "âš ï¸", "high": "ğŸš¨"}.get(balance.burnout_risk_level, "â“")

            lines.append("| ì§€í‘œ | ê°’ |")
            lines.append("|------|-----|")
            lines.append(f"| ë²ˆì•„ì›ƒ ìœ„í—˜ë„ | {risk_emoji} {balance.burnout_risk_level} |")
            lines.append(f"| ì§€ì†ê°€ëŠ¥ì„± ì ìˆ˜ | {balance.sustainability_score:.0f}/100 |")
            lines.append(f"| í™œë™ ë³€ë™ì„± | {balance.activity_variance:.2f} |")
            lines.append("")

            if balance.positive_patterns:
                lines.append("**ê¸ì •ì  íŒ¨í„´:**")
                lines.append("")
                lines.append("| íŒ¨í„´ |")
                lines.append("|------|")
                for pattern in balance.positive_patterns:
                    lines.append(f"| âœ… {pattern} |")
                lines.append("")

            if balance.burnout_indicators:
                lines.append("**ì£¼ì˜ ì‚¬í•­:**")
                lines.append("")
                lines.append("| ì§€í‘œ |")
                lines.append("|------|")
                for indicator in balance.burnout_indicators:
                    lines.append(f"| âš ï¸ {indicator} |")
                lines.append("")

            if balance.health_recommendations:
                lines.append("**ê¶Œì¥ ì‚¬í•­:**")
                lines.append("")
                lines.append("| ê¶Œì¥ì‚¬í•­ |")
                lines.append("|----------|")
                for rec in balance.health_recommendations:
                    lines.append(f"| ğŸ’¡ {rec} |")
                lines.append("")
        return lines

    def _build_code_health_subsection(self, retro) -> List[str]:
        """Build code health subsection of retrospective."""
        lines = []
        if retro.code_health:
            health = retro.code_health
            lines.append("### ğŸ¥ ì½”ë“œ ê±´ê°•ë„ ë¶„ì„")
            lines.append("")

            lines.append("| ì§€í‘œ | ê°’ |")
            lines.append("|------|-----|")
            lines.append(f"| ìœ ì§€ë³´ìˆ˜ ë¶€ë‹´ | {health.maintenance_burden} |")
            lines.append(f"| í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ì¶”ì„¸ | {health.test_coverage_trend} |")
            lines.append("")

            if health.code_quality_trends:
                lines.append("**í’ˆì§ˆ íŠ¸ë Œë“œ:**")
                lines.append("")
                lines.append("| íŠ¸ë Œë“œ |")
                lines.append("|--------|")
                for trend in health.code_quality_trends:
                    lines.append(f"| {trend} |")
                lines.append("")

            if health.quality_improvement_suggestions:
                lines.append("**ê°œì„  ì œì•ˆ:**")
                lines.append("")
                lines.append("| ì œì•ˆ |")
                lines.append("|------|")
                for suggestion in health.quality_improvement_suggestions:
                    lines.append(f"| ğŸ’¡ {suggestion} |")
                lines.append("")
        return lines

    def _build_actionable_insights_subsection(self, retro) -> List[str]:
        """Build actionable insights subsection of retrospective."""
        lines = []
        if retro.actionable_insights:
            lines.append("### ğŸ¯ ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸")
            lines.append("")
            lines.append("> êµ¬ì²´ì ì´ê³  ì¸¡ì • ê°€ëŠ¥í•œ ê°œì„  ë°©ì•ˆ")
            lines.append("")

            # Group by priority
            high_priority = [ai for ai in retro.actionable_insights if ai.priority == "high"]
            medium_priority = [ai for ai in retro.actionable_insights if ai.priority == "medium"]

            if high_priority:
                lines.append("#### ğŸ”´ ë†’ì€ ìš°ì„ ìˆœìœ„")
                lines.append("")
                for insight in high_priority:
                    lines.append(f"**{insight.title}**")
                    lines.append("")
                    lines.append(f"*{insight.description}*")
                    lines.append("")
                    lines.append(f"**ì™œ ì¤‘ìš”í•œê°€:** {insight.why_it_matters}")
                    lines.append("")
                    lines.append("**êµ¬ì²´ì  í–‰ë™:**")
                    for action in insight.concrete_actions:
                        lines.append(f"1. {action}")
                    lines.append("")
                    lines.append(f"**ê¸°ëŒ€ íš¨ê³¼:** {insight.expected_outcome}")
                    lines.append(f"**ì¸¡ì • ë°©ë²•:** {insight.measurement}")
                    lines.append("")
                    lines.append("---")
                    lines.append("")

            if medium_priority:
                lines.append("#### ğŸŸ¡ ì¤‘ê°„ ìš°ì„ ìˆœìœ„")
                lines.append("")
                for insight in medium_priority[:DISPLAY_LIMITS['medium_priority_insights']]:
                    lines.append(f"**{insight.title}**")
                    lines.append("")
                    lines.append(f"*{insight.description}*")
                    lines.append("")
                    lines.append("**êµ¬ì²´ì  í–‰ë™:**")
                    for action in insight.concrete_actions:
                        lines.append(f"- {action}")
                    lines.append("")
            lines.append("")
        return lines

    def _build_areas_for_growth_subsection(self, retro) -> List[str]:
        """Build areas for growth subsection of retrospective."""
        lines = []
        if retro.areas_for_growth:
            lines.append("### ğŸŒ± ì„±ì¥ ê¸°íšŒ")
            lines.append("")
            lines.append("> ë‹¤ìŒ ë‹¨ê³„ë¡œ ë‚˜ì•„ê°€ê¸° ìœ„í•œ ì˜ì—­")
            lines.append("")
            lines.append("| # | ì„±ì¥ ê¸°íšŒ |")
            lines.append("|---|-----------|")
            for i, area in enumerate(retro.areas_for_growth, 1):
                lines.append(f"| {i} | {area} |")
            lines.append("")
        return lines

    def _build_narrative_subsection(self, retro) -> List[str]:
        """Build narrative subsection of retrospective."""
        lines = []
        if retro.retrospective_narrative:
            lines.append("### ğŸ“– íšŒê³  ìŠ¤í† ë¦¬")
            lines.append("")
            lines.append("> ë‹¹ì‹ ì˜ ì—¬ì •ì„ ì´ì•¼ê¸°ë¡œ í’€ì–´ëƒ…ë‹ˆë‹¤")
            lines.append("")
            for paragraph in retro.retrospective_narrative:
                lines.append(paragraph)
                lines.append("")
        return lines

    def _build_retrospective_section(self, metrics: MetricSnapshot) -> List[str]:
        """Build comprehensive retrospective analysis section.

        Refactored to use smaller, focused subsection methods for better maintainability.
        """
        if not metrics.retrospective:
            return []

        retro = metrics.retrospective
        lines = ["## ğŸ” Deep Retrospective Analysis", ""]
        lines.append("> ë°ì´í„° ê¸°ë°˜ì˜ ì‹¬ì¸µì ì¸ íšŒê³ ì™€ ì¸ì‚¬ì´íŠ¸")
        lines.append("")

        # Build all subsections using dedicated methods
        lines.extend(self._build_executive_summary_subsection(retro))
        lines.extend(self._build_key_wins_subsection(retro))
        lines.extend(self._build_time_comparisons_subsection(retro))
        lines.extend(self._build_behavior_patterns_subsection(retro))
        lines.extend(self._build_learning_insights_subsection(retro))
        lines.extend(self._build_impact_assessments_subsection(retro))
        lines.extend(self._build_collaboration_insights_subsection(retro))
        lines.extend(self._build_balance_metrics_subsection(retro))
        lines.extend(self._build_code_health_subsection(retro))
        lines.extend(self._build_actionable_insights_subsection(retro))
        lines.extend(self._build_areas_for_growth_subsection(retro))
        lines.extend(self._build_narrative_subsection(retro))

        lines.append("---")
        lines.append("")
        return lines

    def generate_markdown(self, metrics: MetricSnapshot) -> Path:
        """Create a markdown report for the provided metrics.

        Improved report structure for better user experience:
        1. Header with basic info
        2. Table of Contents for easy navigation
        3. Executive Summary for quick overview
        4. Awards Cabinet to celebrate achievements
        5. Growth Highlights to show progress
        6. Monthly Trends for pattern analysis
        7. Detailed Feedback for actionable insights
        8. Spotlight Examples for concrete evidence
        9. Tech Stack to show technical breadth
        10. Collaboration Network to show teamwork
        11. Year in Review for storytelling
        12. Reflection Prompts for introspection
        13. Detailed Metrics for deep dive
        14. Evidence Links for verification
        """
        self.ensure_structure()
        report_path = self.output_dir / "report.md"

        console.log("Writing markdown report", f"path={report_path}")

        # Build all sections in improved order
        sections = [
            # 1. Header with basic info
            self._build_header_and_summary(metrics),
            # 2. Table of Contents
            self._build_table_of_contents(metrics),
            # 3. Executive Summary - Quick overview
            self._build_executive_summary(metrics),
            # 4. Awards Cabinet - Celebrate achievements first!
            self._build_awards_section(metrics),
            # 5. Growth Highlights - Show the story
            self._build_highlights_section(metrics),
            # 6. Monthly Trends - Show patterns
            self._build_monthly_trends_section(metrics),
            # 7. Detailed Feedback - Actionable insights
            self._build_detailed_feedback_section(metrics),
            # 8. Deep Retrospective - Comprehensive analysis NEW!
            self._build_retrospective_section(metrics),
            # 9. Spotlight Examples - Concrete evidence
            self._build_spotlight_section(metrics),
            # 10. Tech Stack - Technical breadth
            self._build_tech_stack_section(metrics),
            # 11. Collaboration - Teamwork
            self._build_collaboration_section(metrics),
            # 12. Year in Review - Complete story (merged with year-end review)
            self._build_year_in_review_section(metrics),
            # 13. Reflection Prompts - Think deeper
            self._build_reflection_prompts_section(metrics),
            # 14. Detailed Metrics - For those who want numbers
            self._build_metrics_section(metrics),
            # 15. Evidence Links - Verification
            self._build_evidence_section_improved(metrics),
        ]

        # Combine all sections
        all_lines = []
        for section in sections:
            all_lines.extend(section)

        try:
            report_path.write_text("\n".join(all_lines), encoding="utf-8")
        except (IOError, OSError) as e:
            raise IOError(f"Failed to write report to {report_path}: {e}") from e

        return report_path

    # ------------------------------------------------------------------
    # Rich visual reporting
    # ------------------------------------------------------------------

    def generate_prompt_packets(
        self, metrics: MetricSnapshot
    ) -> List[Tuple[PromptRequest, Path]]:
        """Create multi-angle LLM prompts for annual feedback synthesis."""

        self.ensure_structure()
        prompts_dir = self.output_dir / "prompts"
        prompts_dir.mkdir(parents=True, exist_ok=True)

        context = self._build_prompt_context(metrics)
        if context:
            context_block = context
        else:
            context_block = (
                f"Repository: {metrics.repo}\nPeriod: ì§€ë‚œ {metrics.months}ê°œì›”"
            )

        definitions: List[Tuple[str, str, str]] = [
            (
                "strengths_overview",
                "ì—°ê°„ í™œë™ ì´í‰ (ì¥ì  ì¤‘ì‹¬)",
                (
                    "ì•„ë˜ëŠ” ìµœê·¼ í™œë™ ìš”ì•½ì…ë‹ˆë‹¤. ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŒ€/ì¡°ì§ ê´€ì ì—ì„œ ë°”ë¼ë³¸ "
                    "ì„±ê³¼ì˜ ì¥ì  5ê°€ì§€ë¥¼ bulletë¡œ ì •ë¦¬í•´ ì£¼ì„¸ìš”. ê° bulletì—ëŠ” (1) ì–´ë–¤ í™œë™ì´ë‚˜ "
                    "ì§€í‘œê°€ ê·¼ê±°ì¸ì§€, (2) ì¡°ì§ì— ì¤€ ì˜í–¥ì´ ë¬´ì—‡ì¸ì§€ í¬í•¨í•´ ì£¼ì„¸ìš”."
                ),
            ),
            (
                "collaboration_improvements",
                "í˜‘ì—… ë° ë¦¬ë·° ë¬¸í™” ë³´ì™„ì ",
                (
                    "Collaborations ê´€ë ¨ ìˆ˜ì¹˜ì™€ Spotlight Examples, Year in Review ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ "
                    "ë¦¬ë·° ë¬¸í™”/í˜‘ì—… ì¸¡ë©´ì—ì„œ ê°œì„ ì´ í•„ìš”í•œ ì  5ê°€ì§€ë¥¼ ì œì•ˆí•´ ì£¼ì„¸ìš”. ê° í•­ëª©ì—ëŠ” "
                    "(1) í˜„ì¬ í™œë™ íŒ¨í„´, (2) ìœ„í—˜ ë˜ëŠ” ê¸°íšŒ, (3) ë‹¤ìŒ ë¶„ê¸° ì•¡ì…˜ ì•„ì´ë””ì–´ë¥¼ í¬í•¨í•´ ì£¼ì„¸ìš”."
                ),
            ),
            (
                "quality_balance",
                "ì½”ë“œ í’ˆì§ˆ ë° ì•ˆì •ì„± í‰ê°€",
                (
                    "Stability ê´€ë ¨ ìš”ì•½, Issues í†µê³„, Spotlight ì‚¬ë¡€ë¥¼ ê·¼ê±°ë¡œ ì½”ë“œ í’ˆì§ˆê³¼ ì•ˆì •ì„± ìœ ì§€ "
                    "ì¸¡ë©´ì˜ ì¥ì ê³¼ ë³´ì™„ì ì„ ê°ê° 3ê°œì”© ì‘ì„±í•´ ì£¼ì„¸ìš”. ê°€ëŠ¥í•˜ë‹¤ë©´ Spotlight PRì˜ êµ¬ì²´ì  "
                    "ì˜ˆì‹œë¥¼ ì¸ìš©í•´ ì£¼ì„¸ìš”."
                ),
            ),
            (
                "growth_story",
                "ì—°ê°„ ì„±ì¥ ìŠ¤í† ë¦¬ì™€ í•µì‹¬ ê¸°ì—¬",
                (
                    "Year in Review, Growth Highlights, Awards ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¸ ë‹¨ë½ìœ¼ë¡œ êµ¬ì„±ëœ ì„œì‚¬ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”. "
                    "1ë‹¨ë½: ì˜¬í•´ ì–´ë–¤ ì—­ëŸ‰ì´ ê°€ì¥ ì„±ì¥í–ˆëŠ”ì§€, 2ë‹¨ë½: ì €ì¥ì†Œì— ì–´ë–¤ ì˜ì—­ì— ì¤‘ì ì ìœ¼ë¡œ ê¸°ì—¬í–ˆëŠ”ì§€, "
                    "3ë‹¨ë½: ê·¸ ê²°ê³¼ íŒ€ì´ë‚˜ ë¹„ì¦ˆë‹ˆìŠ¤ì— ê¸°ëŒ€ë˜ëŠ” íŒŒê¸‰íš¨ê³¼ê°€ ë¬´ì—‡ì¸ì§€ ì„¤ëª…í•´ ì£¼ì„¸ìš”."
                ),
            ),
            (
                "next_half_goals",
                "ì°¨ê¸° ëª©í‘œ ë° ì‹¤í–‰ ê³„íš",
                (
                    "Summaryì™€ ìœ„ì—ì„œ ë„ì¶œí•œ ê°œì„ ì ë“¤ì„ ì°¸ê³ í•˜ì—¬ ë‹¤ìŒ ê¸°ê°„(6ê°œì›”)ì„ ìœ„í•œ ìƒìœ„ 3ê°œ ëª©í‘œì™€ "
                    "ê° ëª©í‘œë³„ ì‹¤í–‰ ê³„íšì„ ì‘ì„±í•´ ì£¼ì„¸ìš”. ì‹¤í–‰ ê³„íšì—ëŠ” ì¸¡ì • ê°€ëŠ¥í•œ ì§€í‘œë¥¼ í¬í•¨í•´ ì£¼ì„¸ìš”."
                ),
            ),
        ]

        generated: List[Tuple[PromptRequest, Path]] = []
        for identifier, title, instructions in definitions:
            prompt_text = f"{instructions}\n\n{context_block}".strip()
            request = PromptRequest(
                identifier=identifier,
                title=title,
                instructions=instructions,
                prompt=prompt_text,
            )

            prompt_path = prompts_dir / f"{identifier}.txt"
            prompt_lines = [
                f"# {title}",
                "",
                "## Instructions",
                instructions,
                "",
                "## Context",
                context_block,
                "",
                "## Prompt (ready to send)",
                prompt_text,
                "",
            ]
            prompt_path.write_text("\n".join(prompt_lines), encoding="utf-8")
            generated.append((request, prompt_path))

        return generated
