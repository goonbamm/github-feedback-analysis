"""Award calculation strategies for GitHub feedback analysis.

This module implements the Strategy pattern for award determination,
making it easier to add, remove, or modify award rules.
"""

from __future__ import annotations

from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import List, Optional, Dict, Tuple, Any

from .models import CollectionResult
from .constants import (
    AWARD_CONSISTENCY_THRESHOLDS,
    AWARD_BALANCED_THRESHOLDS,
    AWARD_PR_THRESHOLDS,
)


# Award tier configurations
AWARD_TIERS = {
    "commits": [
        (1000, "ğŸ’ ì½”ë“œ ì „ì„¤ ìƒ (ë‹¤ì´ì•„ëª¬ë“œ) â€” 1000íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ì €ì¥ì†Œì˜ ì‚´ì•„ìˆëŠ” ì—­ì‚¬ë¥¼ ì¼ìŠµë‹ˆë‹¤."),
        (500, "ğŸ† ì½”ë“œ ë§ˆìŠ¤í„° ìƒ (í”Œë˜í‹°ë„˜) â€” 500íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ì½”ë“œë² ì´ìŠ¤ì˜ ì¤‘ì¶”ë¥¼ ì™„ì„±í–ˆìŠµë‹ˆë‹¤."),
        (200, "ğŸ¥‡ ì½”ë“œ ëŒ€ì¥ì¥ì´ ìƒ (ê³¨ë“œ) â€” 200íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ì €ì¥ì†Œì˜ í•µì‹¬ì„ ë‹¨ë‹¨í•˜ê²Œ ë‹¤ì¡ŒìŠµë‹ˆë‹¤."),
        (100, "ğŸ¥ˆ ì½”ë“œ ì¥ì¸ ìƒ (ì‹¤ë²„) â€” 100íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ê¾¸ì¤€í•œ ê°œì„ ì„ ì´ì–´ê°”ìŠµë‹ˆë‹¤."),
        (50, "ğŸ¥‰ ì½”ë“œ ê²¬ìŠµìƒ ìƒ (ë¸Œë¡ ì¦ˆ) â€” 50íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ì„±ì¥ì˜ ë°œíŒì„ ë§ˆë ¨í–ˆìŠµë‹ˆë‹¤."),
    ],
    "pull_requests": [
        (200, "ğŸ’ ë¦´ë¦¬ìŠ¤ ì „ì„¤ ìƒ (ë‹¤ì´ì•„ëª¬ë“œ) â€” 200ê±´ ì´ìƒì˜ Pull Requestë¡œ ë°°í¬ì˜ ìƒˆ ì—­ì‚¬ë¥¼ ì—´ì—ˆìŠµë‹ˆë‹¤."),
        (100, "ğŸ† ë°°í¬ ì œë… ìƒ (í”Œë˜í‹°ë„˜) â€” 100ê±´ ì´ìƒì˜ Pull Requestë¡œ ë¦´ë¦¬ìŠ¤ í•¨ëŒ€ë¥¼ ì§€íœ˜í–ˆìŠµë‹ˆë‹¤."),
        (50, "ğŸ¥‡ ë¦´ë¦¬ìŠ¤ ì„ ì¥ ìƒ (ê³¨ë“œ) â€” 50ê±´ ì´ìƒì˜ Pull Requestë¡œ ì¶œì‹œ íë¦„ì„ ì´ëŒì—ˆìŠµë‹ˆë‹¤."),
        (25, "ğŸ¥ˆ ë¦´ë¦¬ìŠ¤ í•­í•´ì‚¬ ìƒ (ì‹¤ë²„) â€” 25ê±´ ì´ìƒì˜ Pull Requestë¡œ í˜‘ì—… ë¦´ë¦¬ìŠ¤ë¥¼ ì£¼ë„í–ˆìŠµë‹ˆë‹¤."),
        (10, "ğŸ¥‰ ë°°í¬ ì„ ì› ìƒ (ë¸Œë¡ ì¦ˆ) â€” 10ê±´ ì´ìƒì˜ Pull Requestë¡œ íŒ€ ë°°í¬ì— ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤."),
    ],
    "reviews": [
        (200, "ğŸ’ ì§€ì‹ ì „íŒŒì ìƒ (ë‹¤ì´ì•„ëª¬ë“œ) â€” 200íšŒ ì´ìƒì˜ ë¦¬ë·°ë¡œ íŒ€ ì „ì²´ì˜ ì„±ì¥ì„ ì´ëŒì—ˆìŠµë‹ˆë‹¤."),
        (100, "ğŸ† ë©˜í† ë§ ëŒ€ê°€ ìƒ (í”Œë˜í‹°ë„˜) â€” 100íšŒ ì´ìƒì˜ ë¦¬ë·°ë¡œ ì§€ì‹ ê³µìœ  ë¬¸í™”ë¥¼ ì •ì°©ì‹œì¼°ìŠµë‹ˆë‹¤."),
        (50, "ğŸ¥‡ ë¦¬ë·° ì „ë¬¸ê°€ ìƒ (ê³¨ë“œ) â€” 50íšŒ ì´ìƒì˜ ë¦¬ë·°ë¡œ ì½”ë“œ í’ˆì§ˆì„ í•œ ë‹¨ê³„ ëŒì–´ì˜¬ë ¸ìŠµë‹ˆë‹¤."),
        (20, "ğŸ¥ˆ ì„±ì¥ ë©˜í†  ìƒ (ì‹¤ë²„) â€” 20íšŒ ì´ìƒì˜ ë¦¬ë·°ë¡œ íŒ€ì˜ ì„±ì¥ì„ ë’·ë°›ì¹¨í–ˆìŠµë‹ˆë‹¤."),
        (10, "ğŸ¥‰ ì½”ë“œ ì§€ì›ì ìƒ (ë¸Œë¡ ì¦ˆ) â€” 10íšŒ ì´ìƒì˜ ë¦¬ë·°ë¡œ ë™ë£Œë¥¼ ë„ì™”ìŠµë‹ˆë‹¤."),
    ],
    "issues": [
        (50, "ğŸ”§ ë¬¸ì œ í•´ê²°ì‚¬ ìƒ â€” 50ê±´ ì´ìƒì˜ ì´ìŠˆë¥¼ ë‹¤ë£¨ë©° ì €ì¥ì†Œ í’ˆì§ˆì„ ê°œì„ í–ˆìŠµë‹ˆë‹¤."),
        (20, "ğŸ› ï¸ ë²„ê·¸ í—Œí„° ìƒ â€” 20ê±´ ì´ìƒì˜ ì´ìŠˆë¥¼ ì²˜ë¦¬í•˜ë©° ì•ˆì •ì„± í™•ë³´ì— ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤."),
    ],
    "velocity": [
        (50, "âš¡ ë²ˆê°œ ê°œë°œì ìƒ â€” ì›” í‰ê·  50íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ë†€ë¼ìš´ ì†ë„ë¥¼ ë³´ì—¬ì¤¬ìŠµë‹ˆë‹¤."),
        (20, "ğŸš€ ì†ë„ì™• ìƒ â€” ì›” í‰ê·  20íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ë¹ ë¥¸ ê°œë°œ í…œí¬ë¥¼ ìœ ì§€í–ˆìŠµë‹ˆë‹¤."),
        (10, "ğŸƒ ìŠ¤í”„ë¦°í„° ìƒ â€” ì›” í‰ê·  10íšŒ ì´ìƒì˜ ì»¤ë°‹ìœ¼ë¡œ ê¾¸ì¤€í•œ ì§„ì „ì„ ì´ë¤˜ìŠµë‹ˆë‹¤."),
    ],
    "collaboration": [
        (20, "ğŸ¤ í˜‘ì—… ë§ˆìŠ¤í„° ìƒ â€” ì›” í‰ê·  20íšŒ ì´ìƒì˜ PRê³¼ ë¦¬ë·°ë¡œ íŒ€ì›Œí¬ì˜ ì¤‘ì‹¬ì´ ë˜ì—ˆìŠµë‹ˆë‹¤."),
        (10, "ğŸ‘¥ í˜‘ì—… ì „ë¬¸ê°€ ìƒ â€” ì›” í‰ê·  10íšŒ ì´ìƒì˜ PRê³¼ ë¦¬ë·°ë¡œ íŒ€ ì‹œë„ˆì§€ë¥¼ ê°•í™”í–ˆìŠµë‹ˆë‹¤."),
        (5, "ğŸ¤— íŒ€ í”Œë ˆì´ì–´ ìƒ â€” ì›” í‰ê·  5íšŒ ì´ìƒì˜ PRê³¼ ë¦¬ë·°ë¡œ í˜‘ì—… ë¬¸í™”ì— ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤."),
    ],
    "activity_consistency": [
        ((30, 6), "ğŸ“… ê¾¸ì¤€í•¨ì˜ ë‹¬ì¸ ìƒ â€” 6ê°œì›” ì´ìƒ ì›” í‰ê·  30íšŒ ì´ìƒì˜ í™œë™ìœ¼ë¡œ ì¼ê´€ì„±ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤."),
        ((15, 3), "ğŸ”„ ì§€ì†ì„± ìƒ â€” ê¾¸ì¤€í•œ ì›”ë³„ í™œë™ìœ¼ë¡œ ì„±ì‹¤í•¨ì„ ë³´ì—¬ì¤¬ìŠµë‹ˆë‹¤."),
    ],
    "change_scale": [
        (10000, "ğŸŒ‹ ì½”ë“œ í™”ì‚° ìƒ â€” 10000ì¤„ ì´ìƒì˜ í­ë°œì ì¸ ë³€ê²½ìœ¼ë¡œ ìƒˆë¡œìš´ ì‹œëŒ€ë¥¼ ì—´ì—ˆìŠµë‹ˆë‹¤."),
        (5000, "ğŸ—ï¸ ëŒ€ê·œëª¨ ì•„í‚¤í…íŠ¸ ìƒ â€” 5000ì¤„ ì´ìƒì˜ ë³€ê²½ìœ¼ë¡œ ëŒ€ë‹´í•œ ë¦¬íŒ©í„°ë§ì„ ì™„ìˆ˜í–ˆìŠµë‹ˆë‹¤."),
        (2000, "ğŸ”¨ ëŒ€í˜• ë¹Œë” ìƒ â€” 2000ì¤„ ì´ìƒì˜ ë³€ê²½ìœ¼ë¡œ í° ê·œëª¨ì˜ ê°œì„ ì„ ì´ë¤„ëƒˆìŠµë‹ˆë‹¤."),
        (1000, "ğŸ  ì¤‘í˜• ê±´ì¶•ê°€ ìƒ â€” 1000ì¤„ ì´ìƒì˜ ë³€ê²½ìœ¼ë¡œ ì˜ë¯¸ìˆëŠ” ê°œì„ ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤."),
    ],
    "review_dedication": [
        (3.0, "ğŸ” ë¦¬ë·° ë§¤ë‹ˆì•„ ìƒ â€” ìì‹ ì˜ PRë³´ë‹¤ 3ë°° ì´ìƒ ë§ì€ ë¦¬ë·°ë¡œ íŒ€ ì„±ì¥ì— í—Œì‹ í–ˆìŠµë‹ˆë‹¤."),
        (2.0, "ğŸ‘ï¸ ì½”ë“œ ê°ì‹œì ìƒ â€” ìì‹ ì˜ PRë³´ë‹¤ 2ë°° ì´ìƒ ë§ì€ ë¦¬ë·°ë¡œ í’ˆì§ˆ ê´€ë¦¬ì— ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤."),
    ],
}


class AwardStrategy(ABC):
    """Base class for award calculation strategies."""

    @abstractmethod
    def calculate(self, collection: CollectionResult) -> List[str]:
        """Calculate awards based on collection metrics.

        Args:
            collection: Collection of repository data

        Returns:
            List of award strings
        """
        pass


class TierBasedAwardStrategy(AwardStrategy):
    """Strategy for tier-based awards (commits, PRs, reviews, etc.)."""

    def calculate(self, collection: CollectionResult) -> List[str]:
        """Calculate tier-based awards."""
        awards = []
        month_span = max(collection.months, 1)

        # Direct metric awards
        self._add_tier_award(awards, "commits", collection.commits)
        self._add_tier_award(awards, "pull_requests", collection.pull_requests)
        self._add_tier_award(awards, "reviews", collection.reviews)
        self._add_tier_award(awards, "issues", collection.issues)

        # Velocity-based awards
        velocity_score = collection.commits / month_span
        self._add_tier_award(awards, "velocity", velocity_score)

        # Collaboration-based awards
        collaboration_score = (collection.pull_requests + collection.reviews) / month_span
        self._add_tier_award(awards, "collaboration", collaboration_score)

        # Large-scale change awards
        if collection.pull_request_examples:
            max_change = max(
                (pr.additions + pr.deletions for pr in collection.pull_request_examples),
                default=0
            )
            self._add_tier_award(awards, "change_scale", max_change)

        # Review dedication awards
        if collection.pull_requests > 0:
            review_ratio = collection.reviews / collection.pull_requests
            self._add_tier_award(awards, "review_dedication", review_ratio)

        return awards

    @staticmethod
    def _add_tier_award(awards: List[str], category: str, value: float) -> None:
        """Add tier-based award if value meets threshold."""
        if category not in AWARD_TIERS:
            return

        for threshold, award_text in AWARD_TIERS[category]:
            if value >= threshold:
                awards.append(award_text)
                break


class ActivityConsistencyAwardStrategy(AwardStrategy):
    """Strategy for activity consistency awards."""

    def calculate(self, collection: CollectionResult) -> List[str]:
        """Calculate activity consistency awards."""
        awards = []
        month_span = max(collection.months, 1)
        total_activity = collection.commits + collection.pull_requests + collection.reviews
        activity_per_month = total_activity / month_span

        # Activity consistency awards
        for (threshold_activity, threshold_months), award_text in AWARD_TIERS["activity_consistency"]:
            if activity_per_month >= threshold_activity and collection.months >= threshold_months:
                awards.append(award_text)
                break

        # Consistency king (ë§¤ìš° ê¾¸ì¤€í•œ í™œë™)
        if (collection.months >= AWARD_CONSISTENCY_THRESHOLDS['consistent_months'] and
            activity_per_month >= AWARD_CONSISTENCY_THRESHOLDS['consistent_activity_per_month']):
            awards.append(
                "ğŸ‘‘ ì¼ê´€ì„±ì˜ ì™• ìƒ â€” 6ê°œì›” ì´ìƒ ì›” 20íšŒ ì´ìƒì˜ ê¾¸ì¤€í•œ í™œë™ì„ ìœ ì§€í–ˆìŠµë‹ˆë‹¤."
            )

        # Sprint finisher (ìµœê·¼ í™œë™ì´ ë§ì€ ê²½ìš°)
        if collection.months >= AWARD_CONSISTENCY_THRESHOLDS['sprint_months']:
            velocity_score = collection.commits / month_span
            if velocity_score >= AWARD_CONSISTENCY_THRESHOLDS['sprint_velocity']:
                awards.append(
                    "ğŸ ìŠ¤í”„ë¦°íŠ¸ í”¼ë‹ˆì…” ìƒ â€” ë†’ì€ ì›”í‰ê·  ì†ë„ë¡œ í”„ë¡œì íŠ¸ë¥¼ ë¹ ë¥´ê²Œ ì „ì§„ì‹œì¼°ìŠµë‹ˆë‹¤."
                )

        return awards


class BalancedContributorAwardStrategy(AwardStrategy):
    """Strategy for balanced contributor awards."""

    def calculate(self, collection: CollectionResult) -> List[str]:
        """Calculate balanced contributor awards."""
        awards = []
        total_activity = collection.commits + collection.pull_requests + collection.reviews

        # All-rounder award
        if (collection.commits >= AWARD_BALANCED_THRESHOLDS['allrounder_commits'] and
            collection.pull_requests >= AWARD_BALANCED_THRESHOLDS['allrounder_prs'] and
            collection.reviews >= AWARD_BALANCED_THRESHOLDS['allrounder_reviews']):
            awards.append(
                "ğŸŒŸ ë‹¤ì¬ë‹¤ëŠ¥ ìƒ â€” ì»¤ë°‹, PR, ë¦¬ë·° ì „ ì˜ì—­ì—ì„œ ê· í˜•ì¡íŒ ê¸°ì—¬ë¥¼ ë³´ì—¬ì¤¬ìŠµë‹ˆë‹¤."
            )

        # Balanced contributor award
        if (collection.commits > 0 and collection.pull_requests > 0 and
            collection.reviews > 0 and total_activity > 0):
            commit_ratio = collection.commits / total_activity
            pr_ratio = collection.pull_requests / total_activity
            review_ratio = collection.reviews / total_activity

            # Check if all three are balanced (each between 20% and 50%)
            min_ratio = AWARD_BALANCED_THRESHOLDS['balanced_min_ratio']
            max_ratio = AWARD_BALANCED_THRESHOLDS['balanced_max_ratio']
            if all(min_ratio <= ratio <= max_ratio for ratio in [commit_ratio, pr_ratio, review_ratio]):
                awards.append(
                    "âš–ï¸ ê· í˜•ì¡íŒ ê¸°ì—¬ì ìƒ â€” ì»¤ë°‹, PR, ë¦¬ë·°ë¥¼ ì™„ë²½í•˜ê²Œ ê· í˜•ìˆê²Œ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤."
                )

        # Renaissance developer (ëª¨ë“  ì§€í‘œê°€ ë†’ìŒ)
        if (collection.commits >= AWARD_BALANCED_THRESHOLDS['renaissance_commits'] and
            collection.pull_requests >= AWARD_BALANCED_THRESHOLDS['renaissance_prs'] and
            collection.reviews >= AWARD_BALANCED_THRESHOLDS['renaissance_reviews'] and
            collection.issues >= AWARD_BALANCED_THRESHOLDS['renaissance_issues']):
            awards.append(
                "ğŸ­ ë¥´ë„¤ìƒìŠ¤ ê°œë°œì ìƒ â€” ëª¨ë“  ì˜ì—­ì—ì„œ ë›°ì–´ë‚œ í™œì•½ì„ í¼ì¹œ ì™„ë²½í•œ ì˜¬ë¼ìš´ë”ì…ë‹ˆë‹¤."
            )

        return awards


class PRCharacteristicAwardStrategy(AwardStrategy):
    """Strategy for PR characteristic-based awards."""

    def calculate(self, collection: CollectionResult) -> List[str]:
        """Calculate PR characteristic awards."""
        awards = []

        if not collection.pull_request_examples:
            return awards

        # Micro-commit artist award (ë§ì€ ì‘ì€ PR)
        small_prs = sum(1 for pr in collection.pull_request_examples
                      if (pr.additions + pr.deletions) < AWARD_PR_THRESHOLDS['micro_pr_size'])
        if small_prs >= AWARD_PR_THRESHOLDS['micro_pr_count']:
            awards.append(
                "ğŸ¨ ë¯¸ì„¸ ì¡°ìœ¨ ì¥ì¸ ìƒ â€” 10ê°œ ì´ìƒì˜ ì‘ì€ PRë¡œ ì ì§„ì  ê°œì„ ì˜ ë¯¸í•™ì„ ë³´ì—¬ì¤¬ìŠµë‹ˆë‹¤."
            )

        # Big bang award (í° PR)
        huge_prs = sum(1 for pr in collection.pull_request_examples
                     if (pr.additions + pr.deletions) > 1000)
        if huge_prs >= 3:
            awards.append(
                "ğŸ’¥ ë¹…ë±… ìƒ â€” 3ê°œ ì´ìƒì˜ ëŒ€ê·œëª¨ PRë¡œ í˜ì‹ ì ì¸ ë³€í™”ë¥¼ ì£¼ë„í–ˆìŠµë‹ˆë‹¤."
            )

        # Quick merger award (ë¹ ë¥¸ ë³‘í•©)
        quick_merges = sum(1 for pr in collection.pull_request_examples
                         if pr.merged_at and pr.created_at and
                         (pr.merged_at - pr.created_at).total_seconds() < 3600)
        if quick_merges >= 5:
            awards.append(
                "âš¡ ìŠ¤í”¼ë“œ ë¨¸ì € ìƒ â€” 5ê°œ ì´ìƒì˜ PRì„ 1ì‹œê°„ ë‚´ ë³‘í•©í•˜ëŠ” ë¯¼ì²©í•¨ì„ ë³´ì—¬ì¤¬ìŠµë‹ˆë‹¤."
            )

        # High PR merge rate
        if collection.pull_requests >= 20:
            merged_count = sum(1 for pr in collection.pull_request_examples if pr.merged_at)
            merge_rate = merged_count / len(collection.pull_request_examples)
            if merge_rate >= 0.9:
                awards.append(
                    "âœ… ë¨¸ì§€ ë§ˆìŠ¤í„° ìƒ â€” 90% ì´ìƒì˜ ë†’ì€ PR ë³‘í•©ë¥ ë¡œ íƒì›”í•œ ì½”ë“œ í’ˆì§ˆì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤."
                )

        return awards


class RoleBasedAwardStrategy(AwardStrategy):
    """Strategy for role-based awards (champion, machine, etc.)."""

    def calculate(self, collection: CollectionResult) -> List[str]:
        """Calculate role-based awards."""
        awards = []

        # Review champion (ë¦¬ë·°ê°€ ê°€ì¥ ë§ì€ ê²½ìš°)
        if (collection.reviews > collection.commits and
            collection.reviews > collection.pull_requests and
            collection.reviews >= 30):
            awards.append(
                "ğŸ‘¨â€ğŸ« ë¦¬ë·° ì±”í”¼ì–¸ ìƒ â€” ë‹¤ë¥¸ í™œë™ë³´ë‹¤ ë¦¬ë·°ì— ì§‘ì¤‘í•˜ë©° íŒ€ ì„±ì¥ì˜ ë©˜í† ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤."
            )

        # Commit machine (ì»¤ë°‹ì´ ì••ë„ì ìœ¼ë¡œ ë§ì€ ê²½ìš°)
        if (collection.commits > collection.pull_requests * 3 and
            collection.commits > collection.reviews * 3 and
            collection.commits >= 100):
            awards.append(
                "ğŸ”¥ ì»¤ë°‹ ë¨¸ì‹  ìƒ â€” ì••ë„ì ì¸ ì»¤ë°‹ ìˆ˜ë¡œ ì½”ë“œë² ì´ìŠ¤ì˜ í•µì‹¬ ë™ë ¥ì´ ë˜ì—ˆìŠµë‹ˆë‹¤."
            )

        # Issue warrior award
        if collection.issues > collection.commits and collection.issues >= 30:
            awards.append(
                "ğŸ› ï¸ ì´ìŠˆ ì „ì‚¬ ìƒ â€” ì»¤ë°‹ë³´ë‹¤ ë§ì€ ì´ìŠˆ ì²˜ë¦¬ë¡œ í”„ë¡œì íŠ¸ ì•ˆì •ì„±ì— ì§‘ì¤‘í–ˆìŠµë‹ˆë‹¤."
            )

        return awards


class QualityAwardStrategy(AwardStrategy):
    """Strategy for quality-based awards."""

    def calculate(self, collection: CollectionResult) -> List[str]:
        """Calculate quality-based awards."""
        awards = []

        # Stability award
        if collection.issues and collection.issues <= max(collection.commits // 6, 1):
            awards.append(
                "ğŸ›¡ï¸ ì•ˆì • ì§€í‚´ì´ ìƒ â€” í™œë™ ëŒ€ë¹„ ì ì€ ì´ìŠˆë¡œ ì•ˆì •ì„±ì„ ì§€ì¼°ìŠµë‹ˆë‹¤."
            )

        # Quality guardian (ì´ìŠˆ ëŒ€ë¹„ ë†’ì€ ë¦¬ë·°)
        if collection.reviews >= 30 and collection.issues > 0:
            review_issue_ratio = collection.reviews / collection.issues
            if review_issue_ratio >= 3:
                awards.append(
                    "ğŸ¯ í’ˆì§ˆ ìˆ˜í˜¸ì ìƒ â€” ì´ìŠˆ ëŒ€ë¹„ 3ë°° ì´ìƒì˜ ë¦¬ë·°ë¡œ ì‚¬ì „ í’ˆì§ˆ ê´€ë¦¬ì— í˜ì¼ìŠµë‹ˆë‹¤."
                )

        return awards


class ThemeBasedAwardStrategy(AwardStrategy):
    """Strategy for theme-based awards (docs, tests, refactor, etc.)."""

    def calculate(self, collection: CollectionResult) -> List[str]:
        """Calculate theme-based awards."""
        awards = []

        if not collection.pull_request_examples:
            return awards

        # Documentation hero
        doc_prs = sum(1 for pr in collection.pull_request_examples
                     if any(keyword in pr.title.lower()
                           for keyword in ['doc', 'readme', 'documentation', 'ë¬¸ì„œ']))
        if doc_prs >= 5:
            awards.append(
                "ğŸ“š ë¬¸ì„œí™” ì˜ì›… ìƒ â€” 5ê°œ ì´ìƒì˜ ë¬¸ì„œ PRë¡œ ì§€ì‹ ê³µìœ ì— ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤."
            )

        # Test advocate
        test_prs = sum(1 for pr in collection.pull_request_examples
                      if any(keyword in pr.title.lower()
                            for keyword in ['test', 'testing', 'í…ŒìŠ¤íŠ¸', 'spec']))
        if test_prs >= 5:
            awards.append(
                "ğŸ§ª í…ŒìŠ¤íŠ¸ ì˜¹í˜¸ì ìƒ â€” 5ê°œ ì´ìƒì˜ í…ŒìŠ¤íŠ¸ PRë¡œ ì½”ë“œ ì•ˆì •ì„±ì„ ê°•í™”í–ˆìŠµë‹ˆë‹¤."
            )

        # Refactoring master
        refactor_prs = sum(1 for pr in collection.pull_request_examples
                          if any(keyword in pr.title.lower()
                                for keyword in ['refactor', 'refactoring', 'ë¦¬íŒ©í„°ë§', 'cleanup', 'clean']))
        if refactor_prs >= 5:
            awards.append(
                "â™»ï¸ ë¦¬íŒ©í„°ë§ ë§ˆìŠ¤í„° ìƒ â€” 5ê°œ ì´ìƒì˜ ë¦¬íŒ©í„°ë§ PRë¡œ ì½”ë“œ í’ˆì§ˆì„ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤."
            )

        # Bug squasher
        bug_prs = sum(1 for pr in collection.pull_request_examples
                     if any(keyword in pr.title.lower()
                           for keyword in ['fix', 'bug', 'hotfix', 'ë²„ê·¸', 'ìˆ˜ì •']))
        if bug_prs >= 10:
            awards.append(
                "ğŸ› ë²„ê·¸ ìŠ¤ì¿¼ì…” ìƒ â€” 10ê°œ ì´ìƒì˜ ë²„ê·¸ ìˆ˜ì • PRë¡œ ì•ˆì •ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤."
            )

        # Feature factory
        feature_prs = sum(1 for pr in collection.pull_request_examples
                         if any(keyword in pr.title.lower()
                               for keyword in ['feature', 'feat', 'add', 'new', 'ì¶”ê°€', 'ê¸°ëŠ¥']))
        if feature_prs >= 10:
            awards.append(
                "ğŸ­ ê¸°ëŠ¥ ê³µì¥ ìƒ â€” 10ê°œ ì´ìƒì˜ ê¸°ëŠ¥ ì¶”ê°€ PRë¡œ ì œí’ˆì„ í’ë¶€í•˜ê²Œ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤."
            )

        return awards


class DefaultAwardStrategy(AwardStrategy):
    """Strategy for default award when no other awards are given."""

    def calculate(self, collection: CollectionResult) -> List[str]:
        """Return default award."""
        return [
            "ğŸŒ± ì„±ì¥ ì”¨ì•— ìƒ â€” ì‘ì€ ë°œê±¸ìŒë“¤ì´ ëª¨ì—¬ ë‚´ì¼ì˜ í° ì„±ì¥ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤."
        ]


@dataclass(slots=True)
class AwardCalculator:
    """Orchestrates multiple award strategies to determine all awards."""

    strategies: List[AwardStrategy]

    def __init__(self):
        """Initialize with all award strategies."""
        self.strategies = [
            TierBasedAwardStrategy(),
            ActivityConsistencyAwardStrategy(),
            BalancedContributorAwardStrategy(),
            PRCharacteristicAwardStrategy(),
            RoleBasedAwardStrategy(),
            QualityAwardStrategy(),
            ThemeBasedAwardStrategy(),
        ]

    def determine_awards(self, collection: CollectionResult) -> List[str]:
        """Determine all awards by running all strategies.

        Args:
            collection: Collection of repository data

        Returns:
            List of award strings. If no awards are found, returns default award.
        """
        awards = []

        # Run all strategies
        for strategy in self.strategies:
            strategy_awards = strategy.calculate(collection)
            awards.extend(strategy_awards)

        # If no awards were given, use default
        if not awards:
            default_strategy = DefaultAwardStrategy()
            awards = default_strategy.calculate(collection)

        return awards
