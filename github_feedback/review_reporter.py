"""Aggregate pull request reviews into an integrated annual report."""
from __future__ import annotations

import json
from dataclasses import dataclass
from datetime import datetime, timezone
from pathlib import Path
from typing import Iterable, List

import re

from .console import Console
from .llm import LLMClient
from .models import (
    GrowthIndicator,
    ImprovementArea,
    PersonalDevelopmentAnalysis,
    ReviewPoint,
    StrengthPoint,
)

PR_NUMBER_PATTERN = re.compile(r"PR #(\d+)")

console = Console()


@dataclass(slots=True)
class StoredReview:
    """Stored review summary reconstructed from cached artefacts."""

    number: int
    title: str
    author: str
    html_url: str
    created_at: datetime
    overview: str
    strengths: List[ReviewPoint]
    improvements: List[ReviewPoint]
    body: str = ""
    review_bodies: List[str] | None = None
    review_comments: List[str] | None = None


class ReviewReporter:
    """Build integrated Korean reports from individual pull request reviews."""

    def __init__(self, *, output_dir: Path = Path("reports/reviews"), llm: LLMClient | None = None) -> None:
        self.output_dir = output_dir
        self.llm = llm

    # ------------------------------------------------------------------
    # Internal helpers
    # ------------------------------------------------------------------

    def _repo_dir(self, repo: str) -> Path:
        safe_repo = repo.replace("/", "__")
        return self.output_dir / safe_repo

    @staticmethod
    def _load_points(raw_points: Iterable[dict]) -> List[ReviewPoint]:
        points: List[ReviewPoint] = []
        for payload in raw_points:
            if not isinstance(payload, dict):
                continue
            message = str(payload.get("message") or "").strip()
            if not message:
                continue
            example_raw = payload.get("example")
            example = str(example_raw).strip() if example_raw else None
            points.append(ReviewPoint(message=message, example=example))
        return points

    def _load_reviews(self, repo: str) -> List[StoredReview]:
        repo_dir = self._repo_dir(repo)
        if not repo_dir.exists():
            return []

        reviews: List[StoredReview] = []
        for pr_dir in sorted(repo_dir.glob("pr-*")):
            summary_path = pr_dir / "review_summary.json"
            artefact_path = pr_dir / "artefacts.json"
            if not summary_path.exists() or not artefact_path.exists():
                continue

            try:
                summary_text = summary_path.read_text(encoding="utf-8").strip()
                artefact_text = artefact_path.read_text(encoding="utf-8").strip()

                if not summary_text or not artefact_text:
                    console.log("Skipping empty review artefact", str(pr_dir))
                    continue

                summary_data = json.loads(summary_text)
                artefact_data = json.loads(artefact_text)
            except json.JSONDecodeError:
                console.log("Skipping invalid review artefact", str(pr_dir))
                continue

            try:
                number = int(artefact_data.get("number"))
                title = str(artefact_data.get("title") or "").strip()
                author = str(artefact_data.get("author") or "unknown").strip()
                html_url = str(artefact_data.get("html_url") or "").strip()
                created_at_raw = artefact_data.get("created_at")
                created_at = (
                    datetime.fromisoformat(created_at_raw)
                    if isinstance(created_at_raw, str)
                    else datetime.now(timezone.utc)
                )
            except Exception:  # pragma: no cover - defensive parsing guard
                console.log("Skipping malformed artefact", str(pr_dir))
                continue

            overview = str(summary_data.get("overview") or "").strip()
            strengths = self._load_points(summary_data.get("strengths", []))
            improvements = self._load_points(summary_data.get("improvements", []))

            # Load additional fields from artefacts
            body = str(artefact_data.get("body") or "").strip()
            review_bodies = artefact_data.get("review_bodies", [])
            review_comments = artefact_data.get("review_comments", [])

            reviews.append(
                StoredReview(
                    number=number,
                    title=title,
                    author=author,
                    html_url=html_url,
                    created_at=created_at,
                    overview=overview,
                    strengths=strengths,
                    improvements=improvements,
                    body=body,
                    review_bodies=review_bodies if isinstance(review_bodies, list) else [],
                    review_comments=review_comments if isinstance(review_comments, list) else [],
                )
            )

        reviews.sort(key=lambda item: (item.created_at, item.number))
        return reviews

    def _build_prompt_context(self, repo: str, reviews: List[StoredReview]) -> str:
        lines: List[str] = []
        lines.append(f"Repository: {repo}")
        lines.append(f"ì´ ë¦¬ë·° PR ìˆ˜: {len(reviews)}")
        lines.append("")
        lines.append("Pull Request ìš”ì•½:")
        for review in reviews:
            lines.append(
                f"- PR #{review.number} {review.title} (ì‘ì„±ì: {review.author}, ìƒì„±ì¼: {review.created_at.date()})"
            )
            if review.html_url:
                lines.append(f"  URL: {review.html_url}")

            # Include PR body for analyzing description quality
            if review.body:
                body_preview = review.body[:300] + "..." if len(review.body) > 300 else review.body
                lines.append(f"  PR ì„¤ëª…: {body_preview}")

            if review.overview:
                lines.append(f"  Overview: {review.overview}")

            # Include review comments for tone analysis
            if review.review_comments:
                lines.append(f"  ë¦¬ë·° ì½”ë©˜íŠ¸ ({len(review.review_comments)}ê°œ):")
                for idx, comment in enumerate(review.review_comments[:5], 1):  # Show first 5 comments
                    comment_preview = comment[:150] + "..." if len(comment) > 150 else comment
                    lines.append(f"    {idx}. {comment_preview}")
                if len(review.review_comments) > 5:
                    lines.append(f"    ... ì™¸ {len(review.review_comments) - 5}ê°œ ì½”ë©˜íŠ¸")

            if review.strengths:
                lines.append("  Strengths:")
                for point in review.strengths:
                    lines.append(f"    â€¢ {point.message}")
                    if point.example:
                        lines.append(f"      ì˜ˆì‹œ: {point.example}")
            if review.improvements:
                lines.append("  Improvements:")
                for point in review.improvements:
                    lines.append(f"    â€¢ {point.message}")
                    if point.example:
                        lines.append(f"      ì˜ˆì‹œ: {point.example}")
            lines.append("")

        return "\n".join(lines).strip()

    def _analyze_personal_development(
        self, repo: str, reviews: List[StoredReview]
    ) -> PersonalDevelopmentAnalysis:
        """Analyze personal development based on PR reviews using LLM."""
        if not self.llm or not reviews:
            return self._fallback_personal_development(reviews)

        context = self._build_prompt_context(repo, reviews)

        # Split reviews into early and recent for growth analysis
        midpoint = len(reviews) // 2
        early_reviews = reviews[:midpoint] if midpoint > 0 else []
        recent_reviews = reviews[midpoint:] if midpoint > 0 else reviews

        messages = [
            {
                "role": "system",
                "content": (
                    "ë‹¹ì‹ ì€ ê°œë°œìì˜ ì½”ë“œ ê¸°ì—¬ íŒ¨í„´ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n\n"
                    "ì œê³µëœ PR ë¦¬ë·° ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°œì¸ì˜ **ì½”ë“œ ì‘ì„± ìŠ¤íƒ€ì¼, ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ëŠ¥ë ¥, ê¸°ìˆ ì  ê°•ì , ê°œì„  ì˜ì—­**ì„ "
                    "êµ¬ì²´ì ì¸ ê·¼ê±°ì™€ í•¨ê»˜ ë¶„ì„í•˜ì„¸ìš”. ì¼ë°˜ì ì¸ 'ì¥ì /ë‹¨ì ' ë‚˜ì—´ì´ ì•„ë‹Œ, "
                    "**ì‹¤ì œ PR, ë¦¬ë·° ì½”ë©˜íŠ¸, PR ì œëª©, PR ì„¤ëª…ì—ì„œ ê´€ì°°ë˜ëŠ” íŒ¨í„´**ì— ì§‘ì¤‘í•˜ì„¸ìš”.\n\n"
                    "**ë¶„ì„ ì›ì¹™:**\n"
                    "1. ëª¨ë“  ì¸ì‚¬ì´íŠ¸ëŠ” êµ¬ì²´ì ì¸ PR ì˜ˆì‹œë¡œ ë’·ë°›ì¹¨\n"
                    "2. ì½”ë“œ ê¸°ì—¬ì˜ íŠ¹ì§•ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜ (ì•„í‚¤í…ì²˜ ì„¤ê³„, í…ŒìŠ¤íŠ¸ ì‘ì„±, ë¦¬íŒ©í† ë§, ë¬¸ì œ í•´ê²°, ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ë“±)\n"
                    "3. ê°œì„  ì˜ì—­ì€ ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ì œì•ˆê³¼ í•¨ê»˜ ì œê³µ\n"
                    "4. ì‹œê°„ì— ë”°ë¥¸ ë³€í™”ëŠ” ì´ˆê¸° PRê³¼ ìµœê·¼ PRì˜ ì‹¤ì œ ì°¨ì´ë¡œ ì„¤ëª…\n"
                    "5. ê±´ì„¤ì ì´ê³  ë°ì´í„° ì¤‘ì‹¬ì˜ í†¤ ìœ ì§€\n\n"
                    "**í•„ìˆ˜ ë¶„ì„ ì˜ì—­ (ê° ì˜ì—­ì—ì„œ êµ¬ì²´ì  ê·¼ê±° ì œì‹œ í•„ìš”):**\n"
                    "1. **PR ì œëª© í’ˆì§ˆ**: ì œëª©ì´ ë³€ê²½ ë‚´ìš©ì„ ëª…í™•íˆ ì „ë‹¬í•˜ëŠ”ì§€, ì¼ê´€ëœ í˜•ì‹ì„ ë”°ë¥´ëŠ”ì§€ ë¶„ì„\n"
                    "2. **PR ì„¤ëª… ì™„ì„±ë„**: PR ì„¤ëª…ì´ ë³€ê²½ ì´ìœ , êµ¬í˜„ ë°©ë²•, í…ŒìŠ¤íŠ¸ ê³„íšì„ í¬í•¨í•˜ëŠ”ì§€ ë¶„ì„\n"
                    "3. **ë¦¬ë·° ì½”ë©˜íŠ¸ í†¤**: ë¦¬ë·° ì½”ë©˜íŠ¸ê°€ ê±´ì„¤ì ì´ê³  êµ¬ì²´ì ì¸ì§€, í˜‘ë ¥ì  íƒœë„ë¥¼ ë³´ì´ëŠ”ì§€ ë¶„ì„\n"
                    "4. **ì½”ë“œ í’ˆì§ˆ íŒ¨í„´**: ì‹¤ì œ ì½”ë“œ ë³€ê²½ì—ì„œ ê´€ì°°ë˜ëŠ” ì„¤ê³„ ì›ì¹™, í…ŒìŠ¤íŠ¸ ìŠµê´€, ë¬¸ì„œí™” ìˆ˜ì¤€\n"
                    "5. **ë¬¸ì œ í•´ê²° ì ‘ê·¼**: ë³µì¡í•œ ë¬¸ì œë¥¼ ì–´ë–»ê²Œ ë¶„í•´í•˜ê³  í•´ê²°í•˜ëŠ”ì§€ íŒ¨í„´ ë¶„ì„\n\n"
                    "**ìƒì„¸ë„ ìš”êµ¬ì‚¬í•­:**\n"
                    "- **category**: ë‹¨ìˆœíˆ 'ì½”ë“œ í’ˆì§ˆ', 'ê°œì„  ì˜ì—­' ê°™ì€ ì¼ë°˜ì ì¸ ìš©ì–´ ëŒ€ì‹ , "
                    "êµ¬ì²´ì ì´ê³  ì˜ë¯¸ ìˆëŠ” ì¹´í…Œê³ ë¦¬ ì´ë¦„ ì‚¬ìš© (ì˜ˆ: 'ë³µì¡í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì„ ëª…í™•í•œ í•¨ìˆ˜ë¡œ ë¶„ë¦¬í•˜ëŠ” ë¦¬íŒ©í† ë§ ëŠ¥ë ¥', "
                    "'ëª…í™•í•˜ê³  ì¼ê´€ëœ PR ì œëª©ìœ¼ë¡œ ë³€ê²½ ì˜ë„ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì „ë‹¬', 'ê±´ì„¤ì ì´ê³  êµ¬ì²´ì ì¸ ë¦¬ë·° ì½”ë©˜íŠ¸ë¡œ í˜‘ì—… í’ˆì§ˆ í–¥ìƒ')\n"
                    "- **description**: ìµœì†Œ 2-3ë¬¸ì¥ìœ¼ë¡œ ìƒì„¸í•˜ê²Œ ì‘ì„±. ë‹¨ìˆœ ë‚˜ì—´ì´ ì•„ë‹Œ êµ¬ì²´ì ì¸ íŒ¨í„´ê³¼ ê·¸ ì˜í–¥ ì„¤ëª…\n"
                    "- **evidence**: PR ë²ˆí˜¸ì™€ í•¨ê»˜ ì‹¤ì œ ê´€ì°°ëœ ë‚´ìš© í¬í•¨ (ì˜ˆ: PR ì œëª©, PR ì„¤ëª… ë‚´ìš©, ë¦¬ë·° ì½”ë©˜íŠ¸ ì˜ˆì‹œ, ì½”ë“œ ë³€ê²½ ë‚´ìš©)\n"
                    "- **suggestions**: 'í…ŒìŠ¤íŠ¸ë¥¼ ì¶”ê°€í•˜ì„¸ìš”' ê°™ì€ ì¼ë°˜ì ì¸ ì¡°ì–¸ì´ ì•„ë‹Œ, ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ì•¡ì…˜ ì•„ì´í…œ\n\n"
                    "**ì‘ë‹µ í˜•ì‹ (JSON):**\n"
                    "{\n"
                    '  "strengths": [\n'
                    "    {\n"
                    '      "category": "êµ¬ì²´ì ì´ê³  ìƒì„¸í•œ ê°•ì  ì¹´í…Œê³ ë¦¬ (ì½”ë“œ/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜/ë¬¸ì„œí™” ë“± ë‹¤ì–‘í•œ ì¸¡ë©´ í¬í•¨)",\n'
                    '      "description": "ê´€ì°°ëœ íŒ¨í„´ì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª… (2-3ë¬¸ì¥). ì–´ë–¤ ê¸°ìˆ /ìŠµê´€ì„ ì–´ë–»ê²Œ í™œìš©í–ˆê³ , ê·¸ê²ƒì´ ì™œ íš¨ê³¼ì ì¸ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª….",\n'
                    '      "evidence": [\n'
                    '        "PR #123 \'feat: ì¸ì¦ ì‹œìŠ¤í…œì— JWT í† í° ê²€ì¦ ë¡œì§ ì¶”ê°€\': ëª…í™•í•œ ì»¨ë²¤ì…˜ prefixì™€ í•µì‹¬ ë³€ê²½ì‚¬í•­ì„ í¬í•¨í•œ ì œëª©",\n'
                    '        "PR #145: PR ì„¤ëª…ì— ë³€ê²½ ì´ìœ (ê¸°ì¡´ ì„¸ì…˜ ë°©ì‹ì˜ í™•ì¥ì„± ë¬¸ì œ), êµ¬í˜„ ë°©ë²•(JWT ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„ íƒ ì´ìœ ), í…ŒìŠ¤íŠ¸ ê³„íš(ë‹¨ìœ„/í†µí•© í…ŒìŠ¤íŠ¸)ì„ ìƒì„¸íˆ ê¸°ìˆ ",\n'
                    '        "PR #167: ë¦¬ë·° ì½”ë©˜íŠ¸ \'ì´ ë¶€ë¶„ì€ edge caseë¥¼ ê³ ë ¤í•˜ë©´ null checkê°€ í•„ìš”í•  ê²ƒ ê°™ì•„ìš”. ì˜ˆë¥¼ ë“¤ì–´...\' ì²˜ëŸ¼ êµ¬ì²´ì ì¸ ë¬¸ì œì™€ ì˜ˆì‹œë¥¼ í•¨ê»˜ ì œì‹œ",\n'
                    '        "PR #189: ë³µì¡í•œ ì¸ì¦ ë¡œì§ì„ validateToken, refreshToken, revokeTokenìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ 85%ë¡œ ì¦ê°€"\n'
                    '      ],\n'
                    '      "impact": "high|medium|low"\n'
                    "    }\n"
                    "  ],\n"
                    '  "improvement_areas": [\n'
                    "    {\n"
                    '      "category": "êµ¬ì²´ì ì´ê³  ìƒì„¸í•œ ê°œì„  ì˜ì—­ (ì½”ë“œ/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜/ë¬¸ì„œí™” ë“± ë‹¤ì–‘í•œ ì¸¡ë©´ í¬í•¨)",\n'
                    '      "description": "í˜„ì¬ íŒ¨í„´ì˜ êµ¬ì²´ì ì¸ ì œí•œì ê³¼ ê°œì„ ì´ í•„ìš”í•œ ì´ìœ  (2-3ë¬¸ì¥). ì–´ë–¤ ìƒí™©ì—ì„œ ë¬¸ì œê°€ ë˜ëŠ”ì§€ ëª…í™•íˆ ì„¤ëª….",\n'
                    '      "evidence": [\n'
                    '        "PR #134 \'Update API\': ì œëª©ì´ ë„ˆë¬´ ëª¨í˜¸í•˜ì—¬ ì–´ë–¤ APIë¥¼ ì–´ë–»ê²Œ ìˆ˜ì •í–ˆëŠ”ì§€ íŒŒì•… ë¶ˆê°€",\n'
                    '        "PR #156: PR ì„¤ëª…ì´ \'ë²„ê·¸ ìˆ˜ì •\'ìœ¼ë¡œë§Œ ì‘ì„±ë˜ì–´ ìˆì–´ ì–´ë–¤ ë²„ê·¸ë¥¼ ì–´ë–»ê²Œ í•´ê²°í–ˆëŠ”ì§€ ë¶ˆëª…í™•",\n'
                    '        "PR #178: ë¦¬ë·° ì½”ë©˜íŠ¸ \'ì´ê±° ê³ ì³ì£¼ì„¸ìš”\' ì²˜ëŸ¼ êµ¬ì²´ì ì¸ ì´ìœ ë‚˜ ì œì•ˆ ì—†ì´ ìš”ì²­ë§Œ í•˜ì—¬ í˜‘ì—… íš¨ìœ¨ ì €í•˜",\n'
                    '        "PR #192: API ì‘ë‹µ í•„ë“œ ë³€ê²½ ì‹œ ê¸°ì¡´ í´ë¼ì´ì–¸íŠ¸ í˜¸í™˜ì„± ê³ ë ¤ ì—†ì´ ì§ì ‘ ìˆ˜ì •í•˜ì—¬ ë°°í¬ ì‹œ ì¥ì•  ìœ„í—˜"\n'
                    '      ],\n'
                    '      "suggestions": [\n'
                    '        "PR ì œëª©ì€ \'feat/fix/refactor: êµ¬ì²´ì ì¸ ë³€ê²½ ë‚´ìš©\' í˜•ì‹ìœ¼ë¡œ ì¼ê´€ë˜ê²Œ ì‘ì„± (ì˜ˆ: \'fix: UserAPIì—ì„œ null ì‚¬ìš©ì ì²˜ë¦¬ ì‹œ 500 ì—ëŸ¬ ë°œìƒ ë¬¸ì œ í•´ê²°\')",\n'
                    '        "PR ì„¤ëª…ì— ìµœì†Œí•œ (1)ë³€ê²½ ì´ìœ  (2)êµ¬í˜„ ë°©ë²• (3)í…ŒìŠ¤íŠ¸ ë°©ë²• ì„¸ ê°€ì§€ë¥¼ í¬í•¨í•˜ì—¬ ë¦¬ë·°ì–´ì˜ ì´í•´ë¥¼ ë•ê¸°",\n'
                    '        "ë¦¬ë·° ì½”ë©˜íŠ¸ ì‘ì„± ì‹œ \'ì™œ\'ì™€ \'ì–´ë–»ê²Œ\'ë¥¼ í•¨ê»˜ ì œì‹œ (ì˜ˆ: \'ì´ ë¶€ë¶„ì€ ë™ì‹œì„± ì´ìŠˆê°€ ë°œìƒí•  ìˆ˜ ìˆìœ¼ë‹ˆ lockì„ ì¶”ê°€í•˜ëŠ” ê²Œ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤\')",\n'
                    '        "API ë³€ê²½ ì‹œ ë²„ì „ í—¤ë”(v1, v2) ë˜ëŠ” ë³„ë„ ì—”ë“œí¬ì¸íŠ¸ë¡œ ë¶„ë¦¬í•˜ì—¬ í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€"\n'
                    '      ],\n'
                    '      "priority": "critical|important|nice-to-have"\n'
                    "    }\n"
                    "  ],\n"
                    '  "growth_indicators": [\n'
                    "    {\n"
                    '      "aspect": "ë³€í™”ê°€ ê´€ì°°ëœ êµ¬ì²´ì  ì˜ì—­",\n'
                    '      "description": "êµ¬ì²´ì ì¸ ë³€í™” ë‚´ìš© (2-3ë¬¸ì¥)",\n'
                    '      "before_examples": ["ì´ˆê¸° PRì˜ êµ¬ì²´ì  íŠ¹ì§•ê³¼ íŒ¨í„´"],\n'
                    '      "after_examples": ["ìµœê·¼ PRì˜ êµ¬ì²´ì  íŠ¹ì§•ê³¼ ê°œì„ ëœ íŒ¨í„´"],\n'
                    '      "progress_summary": "ë³€í™”ì˜ ë°©í–¥ê³¼ ì˜ë¯¸"\n'
                    "    }\n"
                    "  ],\n"
                    '  "overall_assessment": "ì½”ë“œ ê¸°ì—¬ íŒ¨í„´ ì¢…í•© í‰ê°€ (2-3ë¬¸ì¥)",\n'
                    '  "key_achievements": ["ê¸°ìˆ ì ìœ¼ë¡œ ì˜ë¯¸ìˆëŠ” êµ¬ì²´ì  ê¸°ì—¬ (ì˜ˆ: \'ì¸ì¦ ì‹œìŠ¤í…œì„ JWT ê¸°ë°˜ìœ¼ë¡œ ì „í™˜í•˜ì—¬ ë³´ì•ˆì„± í–¥ìƒ ë° ì„¸ì…˜ ê´€ë¦¬ ë³µì¡ë„ ê°ì†Œ\')", ...],\n'
                    '  "next_focus_areas": ["ê¸°ìˆ  ì—­ëŸ‰ í–¥ìƒì„ ìœ„í•œ êµ¬ì²´ì  ì§‘ì¤‘ ì˜ì—­ (ì˜ˆ: \'ëŒ€ìš©ëŸ‰ íŠ¸ë˜í”½ ì²˜ë¦¬ë¥¼ ìœ„í•œ ìºì‹± ì „ëµ ë° ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ìµœì í™”\')", ...]\n'
                    "}\n\n"
                    "**ì¤‘ìš”:** ê° í•­ëª©ì€ êµ¬ì²´ì„±ê³¼ ì‹¤ìš©ì„±ì„ ìµœìš°ì„ ìœ¼ë¡œ í•˜ì„¸ìš”. "
                    "'ì½”ë“œ í’ˆì§ˆ', 'ê°œì„  ì˜ì—­' ê°™ì€ ì¶”ìƒì ì¸ í‘œí˜„ì€ í”¼í•˜ê³ , "
                    "ì‹¤ì œ ì½”ë“œì™€ PRì—ì„œ ê´€ì°°ëœ êµ¬ì²´ì ì¸ íŒ¨í„´ê³¼ í–‰ë™ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.\n\n"
                    "ê° ë°°ì—´ì€ ìµœì†Œ 1ê°œ, ìµœëŒ€ 5ê°œ í•­ëª©ì„ í¬í•¨í•˜ì„¸ìš”."
                ),
            },
            {
                "role": "user",
                "content": (
                    f"ë‹¤ìŒ PR ë¦¬ë·° ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ê°œì¸ì˜ ì½”ë“œ ê¸°ì—¬ íŒ¨í„´ê³¼ ê¸°ìˆ ì  íŠ¹ì§•ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:\n\n"
                    f"{context}\n\n"
                    f"ì´ˆê¸° PR ìˆ˜: {len(early_reviews)}ê°œ\n"
                    f"ìµœê·¼ PR ìˆ˜: {len(recent_reviews)}ê°œ\n\n"
                    "ë‹¤ìŒ ì˜ì—­ì„ **ë°˜ë“œì‹œ** í¬í•¨í•˜ì—¬ ë¶„ì„í•´ì£¼ì„¸ìš”:\n\n"
                    "**1. ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ í’ˆì§ˆ**\n"
                    "   - PR ì œëª©: ë³€ê²½ ë‚´ìš©ì„ ëª…í™•íˆ ì „ë‹¬í•˜ëŠ”ì§€, ì¼ê´€ëœ ì»¨ë²¤ì…˜(feat/fix/refactor ë“±)ì„ ë”°ë¥´ëŠ”ì§€\n"
                    "   - PR ì„¤ëª…: ë³€ê²½ ì´ìœ , êµ¬í˜„ ë°©ë²•, í…ŒìŠ¤íŠ¸ ê³„íš ë“± í•„ìˆ˜ ì •ë³´ë¥¼ í¬í•¨í•˜ëŠ”ì§€\n"
                    "   - ë¦¬ë·° ì½”ë©˜íŠ¸ í†¤: ê±´ì„¤ì ì´ê³  êµ¬ì²´ì ì¸ì§€, í˜‘ë ¥ì  íƒœë„ë¥¼ ë³´ì´ëŠ”ì§€\n\n"
                    "**2. ì½”ë“œ í’ˆì§ˆ ë° ì„¤ê³„**\n"
                    "   - ì½”ë“œ ì„¤ê³„ ë° êµ¬ì¡°í™” ëŠ¥ë ¥\n"
                    "   - ë¬¸ì œ í•´ê²° ì ‘ê·¼ ë°©ì‹\n"
                    "   - í…ŒìŠ¤íŠ¸ ë° ë¬¸ì„œí™” ìŠµê´€\n"
                    "   - ê¸°ìˆ  ìŠ¤íƒ í™œìš© ë° í™•ì¥\n\n"
                    "**ì¤‘ìš”:** ê° ì˜ì—­ì—ì„œ ì‹¤ì œ PR ì œëª©, PR ì„¤ëª… ë‚´ìš©, ë¦¬ë·° ì½”ë©˜íŠ¸ ì˜ˆì‹œë¥¼ evidenceì— í¬í•¨í•˜ì—¬ "
                    "êµ¬ì²´ì ì¸ ê·¼ê±°ë¥¼ ì œì‹œí•˜ì„¸ìš”. ì¶”ìƒì ì¸ í‰ê°€ê°€ ì•„ë‹Œ ê´€ì°°ëœ ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ë¶„ì„ì„ ì‘ì„±í•˜ì„¸ìš”."
                ),
            },
        ]

        try:
            import json as json_module

            content = self.llm.complete(messages, temperature=0.4)
            data = json_module.loads(content)

            # Parse strengths
            strengths = []
            for item in data.get("strengths", []):
                strengths.append(
                    StrengthPoint(
                        category=item.get("category", "ê¸°íƒ€"),
                        description=item.get("description", ""),
                        evidence=item.get("evidence", []),
                        impact=item.get("impact", "medium"),
                    )
                )

            # Parse improvement areas
            improvement_areas = []
            for item in data.get("improvement_areas", []):
                improvement_areas.append(
                    ImprovementArea(
                        category=item.get("category", "ê¸°íƒ€"),
                        description=item.get("description", ""),
                        evidence=item.get("evidence", []),
                        suggestions=item.get("suggestions", []),
                        priority=item.get("priority", "medium"),
                    )
                )

            # Parse growth indicators
            growth_indicators = []
            for item in data.get("growth_indicators", []):
                growth_indicators.append(
                    GrowthIndicator(
                        aspect=item.get("aspect", ""),
                        description=item.get("description", ""),
                        before_examples=item.get("before_examples", []),
                        after_examples=item.get("after_examples", []),
                        progress_summary=item.get("progress_summary", ""),
                    )
                )

            return PersonalDevelopmentAnalysis(
                strengths=strengths,
                improvement_areas=improvement_areas,
                growth_indicators=growth_indicators,
                overall_assessment=data.get("overall_assessment", ""),
                key_achievements=data.get("key_achievements", []),
                next_focus_areas=data.get("next_focus_areas", []),
            )
        except Exception as exc:  # pragma: no cover
            console.log("LLM ê°œì¸ ë°œì „ ë¶„ì„ ì‹¤íŒ¨", str(exc))
            return self._fallback_personal_development(reviews)

    def _fallback_personal_development(
        self, reviews: List[StoredReview]
    ) -> PersonalDevelopmentAnalysis:
        """Provide basic personal development analysis without LLM."""
        # Collect all strengths and improvements from reviews
        all_strengths: List[tuple[StoredReview, ReviewPoint]] = []
        all_improvements: List[tuple[StoredReview, ReviewPoint]] = []

        for review in reviews:
            all_strengths.extend((review, point) for point in review.strengths)
            all_improvements.extend((review, point) for point in review.improvements)

        # Create basic strength points
        strengths = []
        for review, point in all_strengths[:5]:
            strengths.append(
                StrengthPoint(
                    category="ì½”ë“œ í’ˆì§ˆ",
                    description=point.message,
                    evidence=[f"PR #{review.number}: {point.example or review.title}"],
                    impact="medium",
                )
            )

        # Create basic improvement areas
        improvement_areas = []
        for review, point in all_improvements[:5]:
            improvement_areas.append(
                ImprovementArea(
                    category="ê°œì„  ì˜ì—­",
                    description=point.message,
                    evidence=[f"PR #{review.number}: {point.example or review.title}"],
                    suggestions=["ì½”ë“œ ë¦¬ë·° í”¼ë“œë°±ì„ ì°¸ê³ í•˜ì—¬ ê°œì„ "],
                    priority="medium",
                )
            )

        # Basic growth analysis
        growth_indicators = []
        if len(reviews) >= 2:
            growth_indicators.append(
                GrowthIndicator(
                    aspect="ì§€ì†ì ì¸ ê¸°ì—¬",
                    description=f"ì´ {len(reviews)}ê°œì˜ PRì„ í†µí•´ ê¾¸ì¤€íˆ ê¸°ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
                    before_examples=[f"PR #{reviews[0].number}: {reviews[0].title}"],
                    after_examples=[f"PR #{reviews[-1].number}: {reviews[-1].title}"],
                    progress_summary="ì§€ì†ì ìœ¼ë¡œ PRì„ ì‘ì„±í•˜ë©° í”„ë¡œì íŠ¸ì— ê¸°ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
                )
            )

        return PersonalDevelopmentAnalysis(
            strengths=strengths,
            improvement_areas=improvement_areas,
            growth_indicators=growth_indicators,
            overall_assessment=f"ì´ {len(reviews)}ê°œì˜ PRì„ í†µí•´ í”„ë¡œì íŠ¸ì— ê¸°ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
            key_achievements=[f"{len(reviews)}ê°œì˜ PR ì‘ì„± ë° ë¦¬ë·° ì™„ë£Œ"],
            next_focus_areas=["ì½”ë“œ í’ˆì§ˆ í–¥ìƒ", "í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ê°œì„ "],
        )

    # ------------------------------------------------------------------
    # Reporting
    # ------------------------------------------------------------------

    def _render_personal_development(
        self, analysis: PersonalDevelopmentAnalysis, reviews: List[StoredReview]
    ) -> List[str]:
        """Render personal development analysis section."""
        lines: List[str] = []
        lines.append("## ğŸ‘¤ ê°œì¸ ì„±ì¥ ë¶„ì„")
        lines.append("")

        if analysis.overall_assessment:
            lines.append("### ì „ë°˜ì  í‰ê°€")
            lines.append("")
            lines.append(analysis.overall_assessment)
            lines.append("")
            self._append_section_separator(lines)

        pr_map = {review.number: review for review in reviews}

        lines.extend(self._render_strengths_section(analysis, pr_map))
        self._append_section_separator(lines)

        lines.extend(self._render_improvements_section(analysis, pr_map))
        self._append_section_separator(lines)

        lines.extend(self._render_growth_section(analysis))
        self._append_section_separator(lines)

        lines.extend(self._render_optional_list_section("### ğŸ† ì£¼ìš” ì„±ê³¼", analysis.key_achievements))

        if analysis.key_achievements:
            self._append_section_separator(lines)

        lines.extend(self._render_optional_list_section("### ğŸ¯ ë‹¤ìŒ ì§‘ì¤‘ ì˜ì—­", analysis.next_focus_areas))

        if analysis.next_focus_areas:
            self._append_section_separator(lines)

        return lines

    @staticmethod
    def _append_section_separator(lines: List[str]) -> None:
        lines.append("---")
        lines.append("")

    @staticmethod
    def _extract_pr_number(evidence: str) -> int | None:
        match = PR_NUMBER_PATTERN.search(evidence)
        return int(match.group(1)) if match else None

    @staticmethod
    def _build_links(evidences: Iterable[str] | None, pr_map: dict[int, StoredReview]) -> str:
        links: List[str] = []
        if not evidences:
            return "-"

        for evidence in evidences:
            pr_num = ReviewReporter._extract_pr_number(evidence)
            if pr_num is None:
                continue
            review = pr_map.get(pr_num)
            if review and review.html_url:
                links.append(f"[PR #{pr_num}]({review.html_url})")

        return "<br>".join(links) if links else "-"

    def _render_strengths_section(
        self, analysis: PersonalDevelopmentAnalysis, pr_map: dict[int, StoredReview]
    ) -> List[str]:
        lines: List[str] = []
        lines.append("### âœ¨ ì¥ì  (êµ¬ì²´ì  ê·¼ê±°)")
        lines.append("")

        if not analysis.strengths:
            lines.append("ë¶„ì„ëœ ì¥ì ì´ ì—†ìŠµë‹ˆë‹¤.")
            lines.append("")
            return lines

        lines.append("| ì¥ì  | ê·¼ê±°/ë‚´ìš© | ë§í¬ |")
        lines.append("|------|-----------|------|")

        for strength in analysis.strengths:
            impact_emoji = {"high": "ğŸ”¥", "medium": "â­", "low": "ğŸ’«"}.get(
                strength.impact, "â­"
            )
            category = f"**{strength.category}** {impact_emoji}"

            content_parts = [strength.description]
            if strength.evidence:
                content_parts.append("<br>**êµ¬ì²´ì  ê·¼ê±°:**")
                for evidence in strength.evidence:
                    content_parts.append(f"â€¢ {evidence}")
            content = "<br>".join(content_parts)

            link_cell = self._build_links(strength.evidence, pr_map)
            lines.append(f"| {category} | {content} | {link_cell} |")

        lines.append("")
        return lines

    def _render_improvements_section(
        self, analysis: PersonalDevelopmentAnalysis, pr_map: dict[int, StoredReview]
    ) -> List[str]:
        lines: List[str] = []
        lines.append("### ğŸ’¡ ë³´ì™„ì  (ì‹¤í–‰ ê°€ëŠ¥í•œ ì œì•ˆ)")
        lines.append("")

        if not analysis.improvement_areas:
            lines.append("ë¶„ì„ëœ ë³´ì™„ì ì´ ì—†ìŠµë‹ˆë‹¤.")
            lines.append("")
            return lines

        priority_order = {"critical": 0, "important": 1, "nice-to-have": 2}
        sorted_improvements = sorted(
            analysis.improvement_areas,
            key=lambda area: priority_order.get(area.priority, 1),
        )

        lines.append("| ê°œì„ ì  | ê·¼ê±°/ë‚´ìš© | ë§í¬ |")
        lines.append("|--------|-----------|------|")

        for area in sorted_improvements:
            priority_emoji = {
                "critical": "ğŸš¨",
                "important": "âš ï¸",
                "nice-to-have": "ğŸ’­",
            }.get(area.priority, "âš ï¸")
            category = f"**{area.category}** {priority_emoji}"

            content_parts = [area.description]
            if area.evidence:
                content_parts.append("<br>**êµ¬ì²´ì  ì˜ˆì‹œ:**")
                for evidence in area.evidence:
                    content_parts.append(f"â€¢ {evidence}")
            if area.suggestions:
                content_parts.append("<br>**ê°œì„  ì œì•ˆ:**")
                for suggestion in area.suggestions:
                    content_parts.append(f"â€¢ {suggestion}")
            content = "<br>".join(content_parts)

            link_cell = self._build_links(area.evidence, pr_map)
            lines.append(f"| {category} | {content} | {link_cell} |")

        lines.append("")
        return lines

    @staticmethod
    def _render_growth_section(analysis: PersonalDevelopmentAnalysis) -> List[str]:
        lines: List[str] = []
        lines.append("### ğŸŒ± ì„±ì¥í•œ ì  (ì‹œê°„ì— ë”°ë¥¸ ë³€í™”)")
        lines.append("")

        if not analysis.growth_indicators:
            lines.append("- ë¶„ì„ëœ ì„±ì¥ ì§€í‘œê°€ ì—†ìŠµë‹ˆë‹¤.")
            lines.append("")
            return lines

        for i, growth in enumerate(analysis.growth_indicators, 1):
            lines.append(f"{i}. **{growth.aspect}**")
            lines.append(f"   - {growth.description}")
            if growth.before_examples:
                lines.append("   - **ì´ˆê¸° ë‹¨ê³„:**")
                for example in growth.before_examples:
                    lines.append(f"     - {example}")
            if growth.after_examples:
                lines.append("   - **í˜„ì¬ ë‹¨ê³„:**")
                for example in growth.after_examples:
                    lines.append(f"     - {example}")
            if growth.progress_summary:
                lines.append(f"   - **ì„±ì¥ ìš”ì•½:** {growth.progress_summary}")
            lines.append("")

        return lines

    @staticmethod
    def _render_optional_list_section(title: str, items: Iterable[str]) -> List[str]:
        items = list(items)
        if not items:
            return []

        lines = [title, ""]
        for item in items:
            lines.append(f"- {item}")
        lines.append("")
        return lines

    def _fallback_report(self, repo: str, reviews: List[StoredReview]) -> str:
        lines: List[str] = []
        lines.append("# ğŸ¯ í†µí•© ì½”ë“œ ë¦¬ë·° ë³´ê³ ì„œ")
        lines.append("")
        lines.append(f"**ì €ì¥ì†Œ**: {repo}")
        lines.append(f"**ê²€í† í•œ PR ìˆ˜**: {len(reviews)}ê±´")
        lines.append("")
        lines.append("---")
        lines.append("")

        # Table of contents
        lines.append("## ğŸ“‘ ëª©ì°¨")
        lines.append("")
        lines.append("1. **ğŸ‘¤ ê°œì¸ ì„±ì¥ ë¶„ì„** - ì¥ì , ë³´ì™„ì , ì„±ì¥í•œ ì ")
        lines.append("2. **âœ¨ ì¥ì ** - ë›°ì–´ë‚¬ë˜ ì ë“¤")
        lines.append("3. **ğŸ’¡ ë³´ì™„ì ** - ê°œì„ í•  ìˆ˜ ìˆëŠ” ë¶€ë¶„")
        lines.append("4. **ğŸŒ± ì˜¬í•´ ì„±ì¥í•œ ì ** - ì„±ì¥ ì—¬ì •")
        lines.append("5. **ğŸŠ ì „ì²´ ì´í‰** - ì¢…í•© í‰ê°€")
        lines.append("6. **ğŸ“ ê°œë³„ PR í•˜ì´ë¼ì´íŠ¸** - ì£¼ìš” PR ëª©ë¡")
        lines.append("")
        lines.append("---")
        lines.append("")

        # Add personal development analysis
        personal_dev = self._fallback_personal_development(reviews)
        lines.extend(self._render_personal_development(personal_dev, reviews))

        def _render_points(title: str, emoji: str, entries: List[tuple[StoredReview, ReviewPoint]]) -> None:
            lines.append(f"## {emoji} {title}")
            lines.append("")
            if not entries:
                lines.append("ìˆ˜ì§‘ëœ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
                lines.append("")
                return

            lines.append(f"| {title} | ê·¼ê±°/ë‚´ìš© | ë§í¬ |")
            lines.append("|--------|-----------|------|")
            for review, point in entries:
                category = f"**PR #{review.number}**<br>`{review.title}`"

                # Combine message and example
                content_parts = [point.message]
                if point.example:
                    content_parts.append(f"<br>ğŸ’¡ **ì˜ˆì‹œ:**<br>`{point.example}`")
                content = "".join(content_parts)

                # Create link
                link_cell = f"[PR #{review.number}]({review.html_url})" if review.html_url else "-"
                lines.append(f"| {category} | {content} | {link_cell} |")
            lines.append("")
            lines.append("---")
            lines.append("")

        strength_entries: List[tuple[StoredReview, ReviewPoint]] = []
        improvement_entries: List[tuple[StoredReview, ReviewPoint]] = []

        for review in reviews:
            strength_entries.extend((review, point) for point in review.strengths)
            improvement_entries.extend((review, point) for point in review.improvements)

        _render_points("ì¥ì ", "âœ¨", strength_entries[:8])
        _render_points("ë³´ì™„ì ", "ğŸ’¡", improvement_entries[:8])

        lines.append("## ğŸŒ± ì˜¬í•´ ì„±ì¥í•œ ì ")
        lines.append("")
        growth_items = [review for review in reviews if review.overview]
        if not growth_items:
            lines.append("- ê°œë³„ ë¦¬ë·° ìš”ì•½ì´ ì—†ì–´ ì„±ì¥ í¬ì¸íŠ¸ë¥¼ ì¶”ë¡ í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.")
        else:
            for i, review in enumerate(growth_items[:8], 1):
                lines.append(f"{i}. **PR #{review.number}** `{review.title}`")
                lines.append(f"   - {review.overview}")
                lines.append("")
        lines.append("---")
        lines.append("")

        lines.append("## ğŸŠ ì „ì²´ ì´í‰")
        lines.append("")
        lines.append(
            "ì €ì¥ëœ ë¦¬ë·° ìš”ì•½ì„ ë°”íƒ•ìœ¼ë¡œ íŒ€ì´ ì§€ì†í•´ì„œ ì§€ì‹ì„ ê³µìœ í•˜ê³  ìˆìœ¼ë©°, "
            "í†µí•© ë³´ê³ ì„œë¥¼ í†µí•´ ë°˜ë³µë˜ëŠ” ê°•ì ê³¼ ê°œì„ ì ì„ ì¶”ì í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
            f"ì´ {len(reviews)}ê±´ì˜ PRì„ í†µí•´ ê¾¸ì¤€í•œ ì„±ì¥ì„ ì´ì–´ê°€ê³  ìˆìŠµë‹ˆë‹¤."
        )
        lines.append("")
        lines.append("---")
        lines.append("")

        lines.append("## ğŸ“ ê°œë³„ PR í•˜ì´ë¼ì´íŠ¸")
        lines.append("")
        for i, review in enumerate(reviews, 1):
            date_str = review.created_at.strftime("%Y-%m-%d")
            highlight = f"{i}. **PR #{review.number}** `{review.title}` ({date_str})"
            lines.append(highlight)
            if review.html_url:
                lines.append(f"   - ğŸ”— [{review.html_url}]({review.html_url})")
            lines.append("")

        return "\n".join(lines).strip()

    def _generate_report_text(self, repo: str, reviews: List[StoredReview]) -> str:
        if not self.llm:
            return self._fallback_report(repo, reviews)

        context = self._build_prompt_context(repo, reviews)

        messages = [
            {
                "role": "system",
                "content": (
                    "ë‹¹ì‹ ì€ ê¸°ìˆ  ë¦¬ë”ë¡œì„œ íŒ€ ë‹¨ìœ„ì˜ ì½”ë“œ ë¦¬ë·° í™œë™ì„ ë¶„ì„í•˜ëŠ” í†µí•© ë³´ê³ ì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.\n\n"
                    "**ë³´ê³ ì„œ ëª©ì :**\n"
                    "1. PR ë¦¬ë·° í™œë™ì˜ ì „ì²´ì  íë¦„ê³¼ íŒ¨í„´ íŒŒì•…\n"
                    "2. íŒ€ í˜‘ì—… ë° ì§€ì‹ ê³µìœ  í˜„í™© í‰ê°€\n"
                    "3. ë¦¬ë·° í”„ë¡œì„¸ìŠ¤ ê°œì„  ê¸°íšŒ ì‹ë³„\n"
                    "4. ë‹¤ìŒ ë¶„ê¸° íŒ€ ëª©í‘œ ìˆ˜ë¦½ ê·¼ê±° ì œê³µ\n\n"
                    "**ì¤‘ìš”: ê°œì¸ì˜ ê¸°ìˆ ì  ê°•ì /ì•½ì ì€ ë¶„ì„í•˜ì§€ ë§ˆì„¸ìš”.** "
                    "(ë³„ë„ì˜ ê°œì¸ ì„±ì¥ ë¶„ì„ì´ ì´ë¯¸ ì œê³µë©ë‹ˆë‹¤.) "
                    "ëŒ€ì‹  **íŒ€ ì „ì²´ì˜ í˜‘ì—… íŒ¨í„´, ë¦¬ë·° ë¬¸í™”, í”„ë¡œì„¸ìŠ¤ íš¨ìœ¨ì„±**ì— ì§‘ì¤‘í•˜ì„¸ìš”.\n\n"
                    "**ë¶„ì„ ê´€ì :**\n"
                    "- PR ë¦¬ë·°ì˜ ì–‘ì /ì§ˆì  íŠ¸ë Œë“œ\n"
                    "- íŒ€ ê°„ í˜‘ì—… í™œë°œë„ ë° ì§€ì‹ ê³µìœ  ì •ë„\n"
                    "- ë¦¬ë·° í”„ë¡œì„¸ìŠ¤ì˜ ë³‘ëª© ì§€ì \n"
                    "- ë°˜ë³µë˜ëŠ” ë¦¬ë·° íŒ¨í„´ (ê¸ì •ì /ë¶€ì •ì )\n"
                    "- íŒ€ ë¬¸í™” ë° ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ íŠ¹ì„±\n\n"
                    "**ë³´ê³ ì„œ êµ¬ì¡°:**\n\n"
                    "# ğŸ¯ í†µí•© ì½”ë“œ ë¦¬ë·° ë³´ê³ ì„œ\n\n"
                    "## ğŸ“Š ë¦¬ë·° í™œë™ ìš”ì•½\n"
                    "- ì „ì²´ PR ìˆ˜ ë° ê¸°ê°„ë³„ ë¶„í¬\n"
                    "- í‰ê·  ë¦¬ë·° ì‹œê°„, ë³‘í•©ê¹Œì§€ ì†Œìš” ì‹œê°„\n"
                    "- ì£¼ìš” í™œë™ íŠ¸ë Œë“œ (ì¦ê°€/ê°ì†Œ/ì•ˆì •)\n\n"
                    "## ğŸ¤ í˜‘ì—… ë° ì§€ì‹ ê³µìœ \n"
                    "- ë¦¬ë·° ì°¸ì—¬ ë¶„í¬ (ì§‘ì¤‘ë„ vs ë¶„ì‚°ë„)\n"
                    "- ì§€ì‹ ê³µìœ  í™œì„±í™” ì •ë„\n"
                    "- íŒ€ ê°„ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ íŒ¨í„´\n\n"
                    "## ğŸ”„ í”„ë¡œì„¸ìŠ¤ íš¨ìœ¨ì„±\n"
                    "- ë³‘ëª© êµ¬ê°„ ì‹ë³„\n"
                    "- ë¦¬ë·° ë°˜ì‘ ì†ë„\n"
                    "- ì¬ì‘ì—…(rework) ë¹ˆë„ì™€ ì›ì¸\n\n"
                    "## ğŸ“ˆ ì£¼ìš” ë³€í™” ë° íŠ¸ë Œë“œ\n"
                    "- ì´ì „ ê¸°ê°„ ëŒ€ë¹„ ë³€í™”\n"
                    "- ë°˜ë³µë˜ëŠ” ë¦¬ë·° íŒ¨í„´\n"
                    "- ìƒˆë¡­ê²Œ ë‚˜íƒ€ë‚œ íŠ¹ì§•\n\n"
                    "## ğŸ¯ í”„ë¡œì„¸ìŠ¤ ê°œì„  ì œì•ˆ\n"
                    "1. ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„ ì‚¬í•­ (1-3ê°œ)\n"
                    "2. ì¤‘ê¸° ê°œì„  ëª©í‘œ (1-2ê°œì›”)\n"
                    "3. ì¥ê¸° íˆ¬ì ì˜ì—­\n\n"
                    "## ğŸ“ ì£¼ìš” PR ì‚¬ë¡€\n"
                    "- íŒ€ì— í•™ìŠµ ê°€ì¹˜ê°€ ë†’ì•˜ë˜ ë¦¬ë·°\n"
                    "- í˜‘ì—…ì˜ ëª¨ë²” ì‚¬ë¡€\n\n"
                    "**ì‘ì„± ì›ì¹™:**\n"
                    "- íŒ€ ë‹¨ìœ„ ê´€ì  ìœ ì§€ (ê°œì¸ í‰ê°€ ì§€ì–‘)\n"
                    "- êµ¬ì²´ì  ë°ì´í„°ì™€ ì˜ˆì‹œ í™œìš©\n"
                    "- ê±´ì„¤ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì œì•ˆ\n"
                    "- íŒ€ ë§¥ë½ê³¼ ë¬¸í™” ê³ ë ¤\n\n"
                    "ì¶œë ¥ì€ Markdown í˜•ì‹, ì´ëª¨ì§€ëŠ” ì ì ˆíˆ ì‚¬ìš©í•˜ì„¸ìš”. ëª¨ë“  ì‘ë‹µì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”."
                ),
            },
            {
                "role": "user",
                "content": (
                    f"ë‹¤ìŒ PR ë¦¬ë·° ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ íŒ€ ë‹¨ìœ„ì˜ í†µí•© ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”:\n\n"
                    f"{context}\n\n"
                    "íŠ¹íˆ ë‹¤ìŒ ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”:\n"
                    "1. ì´ ê¸°ê°„ ë™ì•ˆ íŒ€ì˜ ë¦¬ë·° í™œë™ì—ì„œ ê°€ì¥ í° ë³€í™”ëŠ”?\n"
                    "2. í˜‘ì—… ë° ì§€ì‹ ê³µìœ ê°€ ê°€ì¥ í™œë°œí•œ ì˜ì—­ì€?\n"
                    "3. ë¦¬ë·° í”„ë¡œì„¸ìŠ¤ì—ì„œ ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ì€?\n"
                    "4. ë‹¤ìŒ ë¶„ê¸°ì— íŒ€ì´ ì§‘ì¤‘í•´ì•¼ í•  ëª©í‘œëŠ”?"
                ),
            },
        ]

        try:
            content = self.llm.complete(messages, temperature=0.4)
            if content.strip():
                return content.strip()
        except Exception as exc:  # pragma: no cover - network errors hard to simulate
            console.log("LLM í†µí•© ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨", str(exc))

        return self._fallback_report(repo, reviews)

    # ------------------------------------------------------------------
    # Public API
    # ------------------------------------------------------------------

    def create_integrated_report(self, repo: str) -> Path:
        """Create or refresh the integrated review report for a repository."""

        repo_input = repo.strip()
        if not repo_input:
            raise ValueError("Repository cannot be empty")

        reviews = self._load_reviews(repo_input)
        if not reviews:
            raise ValueError("No review summaries found for the given repository")

        # Generate personal development analysis
        console.log("ê°œì¸ ì„±ì¥ ë¶„ì„ ìƒì„± ì¤‘...")
        personal_dev = self._analyze_personal_development(repo_input, reviews)

        # Generate main report
        console.log("í†µí•© ë³´ê³ ì„œ ìƒì„± ì¤‘...")
        report_text = self._generate_report_text(repo_input, reviews)

        # If LLM report doesn't include personal development section, add it at the beginning
        if "## ğŸ‘¤ ê°œì¸ ì„±ì¥ ë¶„ì„" not in report_text and "ê°œì¸ ì„±ì¥ ë¶„ì„" not in report_text:
            lines = report_text.split("\n")
            # Find where to insert (after the header and initial metadata)
            insert_idx = 0
            for i, line in enumerate(lines):
                if line.startswith("---") or line.startswith("##"):
                    insert_idx = i
                    break

            # Insert personal development section
            personal_dev_lines = self._render_personal_development(personal_dev, reviews)
            lines = lines[:insert_idx] + personal_dev_lines + lines[insert_idx:]
            report_text = "\n".join(lines)

        # Save report
        repo_dir = self._repo_dir(repo_input)
        repo_dir.mkdir(parents=True, exist_ok=True)
        report_path = repo_dir / "integrated_report.md"
        report_path.write_text(report_text, encoding="utf-8")

        # Also save personal development analysis as JSON for programmatic access
        personal_dev_path = repo_dir / "personal_development.json"
        personal_dev_path.write_text(
            json.dumps(personal_dev.to_dict(), indent=2, ensure_ascii=False),
            encoding="utf-8",
        )

        console.log(f"ê°œì¸ ì„±ì¥ ë¶„ì„ ì €ì¥: {personal_dev_path}")
        return report_path


__all__ = ["ReviewReporter", "StoredReview"]
