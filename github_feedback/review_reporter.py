"""Aggregate pull request reviews into an integrated annual report."""

from __future__ import annotations

import json
from dataclasses import dataclass
from datetime import datetime, timezone
from pathlib import Path
from typing import Iterable, List

from .console import Console
from .llm import LLMClient
from .models import (
    GrowthIndicator,
    ImprovementArea,
    PersonalDevelopmentAnalysis,
    ReviewPoint,
    StrengthPoint,
)

console = Console()


@dataclass(slots=True)
class StoredReview:
    """Stored review summary reconstructed from cached artefacts."""

    number: int
    title: str
    author: str
    html_url: str
    created_at: datetime
    overview: str
    strengths: List[ReviewPoint]
    improvements: List[ReviewPoint]


class ReviewReporter:
    """Build integrated Korean reports from individual pull request reviews."""

    def __init__(self, *, output_dir: Path = Path("reports/reviews"), llm: LLMClient | None = None) -> None:
        self.output_dir = output_dir
        self.llm = llm

    # ------------------------------------------------------------------
    # Internal helpers
    # ------------------------------------------------------------------

    def _repo_dir(self, repo: str) -> Path:
        safe_repo = repo.replace("/", "__")
        return self.output_dir / safe_repo

    @staticmethod
    def _load_points(raw_points: Iterable[dict]) -> List[ReviewPoint]:
        points: List[ReviewPoint] = []
        for payload in raw_points:
            if not isinstance(payload, dict):
                continue
            message = str(payload.get("message") or "").strip()
            if not message:
                continue
            example_raw = payload.get("example")
            example = str(example_raw).strip() if example_raw else None
            points.append(ReviewPoint(message=message, example=example))
        return points

    def _load_reviews(self, repo: str) -> List[StoredReview]:
        repo_dir = self._repo_dir(repo)
        if not repo_dir.exists():
            return []

        reviews: List[StoredReview] = []
        for pr_dir in sorted(repo_dir.glob("pr-*")):
            summary_path = pr_dir / "review_summary.json"
            artefact_path = pr_dir / "artefacts.json"
            if not summary_path.exists() or not artefact_path.exists():
                continue

            try:
                summary_data = json.loads(summary_path.read_text(encoding="utf-8"))
                artefact_data = json.loads(artefact_path.read_text(encoding="utf-8"))
            except json.JSONDecodeError:
                console.log("Skipping invalid review artefact", str(pr_dir))
                continue

            try:
                number = int(artefact_data.get("number"))
                title = str(artefact_data.get("title") or "").strip()
                author = str(artefact_data.get("author") or "unknown").strip()
                html_url = str(artefact_data.get("html_url") or "").strip()
                created_at_raw = artefact_data.get("created_at")
                created_at = (
                    datetime.fromisoformat(created_at_raw)
                    if isinstance(created_at_raw, str)
                    else datetime.now(timezone.utc)
                )
            except Exception:  # pragma: no cover - defensive parsing guard
                console.log("Skipping malformed artefact", str(pr_dir))
                continue

            overview = str(summary_data.get("overview") or "").strip()
            strengths = self._load_points(summary_data.get("strengths", []))
            improvements = self._load_points(summary_data.get("improvements", []))

            reviews.append(
                StoredReview(
                    number=number,
                    title=title,
                    author=author,
                    html_url=html_url,
                    created_at=created_at,
                    overview=overview,
                    strengths=strengths,
                    improvements=improvements,
                )
            )

        reviews.sort(key=lambda item: (item.created_at, item.number))
        return reviews

    def _build_prompt_context(self, repo: str, reviews: List[StoredReview]) -> str:
        lines: List[str] = []
        lines.append(f"Repository: {repo}")
        lines.append(f"ì´ ë¦¬ë·° PR ìˆ˜: {len(reviews)}")
        lines.append("")
        lines.append("Pull Request ìš”ì•½:")
        for review in reviews:
            lines.append(
                f"- PR #{review.number} {review.title} (ì‘ì„±ì: {review.author}, ìƒì„±ì¼: {review.created_at.date()})"
            )
            if review.html_url:
                lines.append(f"  URL: {review.html_url}")
            if review.overview:
                lines.append(f"  Overview: {review.overview}")
            if review.strengths:
                lines.append("  Strengths:")
                for point in review.strengths:
                    lines.append(f"    â€¢ {point.message}")
                    if point.example:
                        lines.append(f"      ì˜ˆì‹œ: {point.example}")
            if review.improvements:
                lines.append("  Improvements:")
                for point in review.improvements:
                    lines.append(f"    â€¢ {point.message}")
                    if point.example:
                        lines.append(f"      ì˜ˆì‹œ: {point.example}")
            lines.append("")

        return "\n".join(lines).strip()

    def _analyze_personal_development(
        self, repo: str, reviews: List[StoredReview]
    ) -> PersonalDevelopmentAnalysis:
        """Analyze personal development based on PR reviews using LLM."""
        if not self.llm or not reviews:
            return self._fallback_personal_development(reviews)

        context = self._build_prompt_context(repo, reviews)

        # Split reviews into early and recent for growth analysis
        midpoint = len(reviews) // 2
        early_reviews = reviews[:midpoint] if midpoint > 0 else []
        recent_reviews = reviews[midpoint:] if midpoint > 0 else reviews

        messages = [
            {
                "role": "system",
                "content": (
                    "ë‹¹ì‹ ì€ ê°œë°œìì˜ ì½”ë“œ ê¸°ì—¬ íŒ¨í„´ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n\n"
                    "ì œê³µëœ PR ë¦¬ë·° ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°œì¸ì˜ **ì½”ë“œ ì‘ì„± ìŠ¤íƒ€ì¼, ê¸°ìˆ ì  ê°•ì , ê°œì„  ì˜ì—­**ì„ "
                    "êµ¬ì²´ì ì¸ ê·¼ê±°ì™€ í•¨ê»˜ ë¶„ì„í•˜ì„¸ìš”. ì¼ë°˜ì ì¸ 'ì¥ì /ë‹¨ì ' ë‚˜ì—´ì´ ì•„ë‹Œ, "
                    "**ì‹¤ì œ ì½”ë“œì™€ PRì—ì„œ ê´€ì°°ë˜ëŠ” íŒ¨í„´**ì— ì§‘ì¤‘í•˜ì„¸ìš”.\n\n"
                    "**ë¶„ì„ ì›ì¹™:**\n"
                    "1. ëª¨ë“  ì¸ì‚¬ì´íŠ¸ëŠ” êµ¬ì²´ì ì¸ PR ì˜ˆì‹œë¡œ ë’·ë°›ì¹¨\n"
                    "2. ì½”ë“œ ê¸°ì—¬ì˜ íŠ¹ì§•ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜ (ì•„í‚¤í…ì²˜ ì„¤ê³„, í…ŒìŠ¤íŠ¸ ì‘ì„±, ë¦¬íŒ©í† ë§, ë¬¸ì œ í•´ê²° ë“±)\n"
                    "3. ê°œì„  ì˜ì—­ì€ ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ì œì•ˆê³¼ í•¨ê»˜ ì œê³µ\n"
                    "4. ì‹œê°„ì— ë”°ë¥¸ ë³€í™”ëŠ” ì´ˆê¸° PRê³¼ ìµœê·¼ PRì˜ ì‹¤ì œ ì°¨ì´ë¡œ ì„¤ëª…\n"
                    "5. ê±´ì„¤ì ì´ê³  ë°ì´í„° ì¤‘ì‹¬ì˜ í†¤ ìœ ì§€\n\n"
                    "**ì‘ë‹µ í˜•ì‹ (JSON):**\n"
                    "{\n"
                    '  "strengths": [\n'
                    "    {\n"
                    '      "category": "ê¸°ìˆ ì  ê°•ì  ì¹´í…Œê³ ë¦¬",\n'
                    '      "description": "ê´€ì°°ëœ íŒ¨í„´ê³¼ ê·¸ ì˜ë¯¸",\n'
                    '      "evidence": ["PR #ë²ˆí˜¸: êµ¬ì²´ì  ì½”ë“œ/ë¦¬ë·° ì˜ˆì‹œ", ...],\n'
                    '      "impact": "high|medium|low"\n'
                    "    }\n"
                    "  ],\n"
                    '  "improvement_areas": [\n'
                    "    {\n"
                    '      "category": "ê°œì„  ì˜ì—­ ì¹´í…Œê³ ë¦¬",\n'
                    '      "description": "í˜„ì¬ íŒ¨í„´ì˜ ì œí•œì ",\n'
                    '      "evidence": ["PR #ë²ˆí˜¸: êµ¬ì²´ì  ì˜ˆì‹œ", ...],\n'
                    '      "suggestions": ["ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ë°©ë²•", ...],\n'
                    '      "priority": "critical|important|nice-to-have"\n'
                    "    }\n"
                    "  ],\n"
                    '  "growth_indicators": [\n'
                    "    {\n"
                    '      "aspect": "ë³€í™”ê°€ ê´€ì°°ëœ ì˜ì—­",\n'
                    '      "description": "êµ¬ì²´ì ì¸ ë³€í™” ë‚´ìš©",\n'
                    '      "before_examples": ["ì´ˆê¸° PRì˜ íŠ¹ì§•"],\n'
                    '      "after_examples": ["ìµœê·¼ PRì˜ íŠ¹ì§•"],\n'
                    '      "progress_summary": "ë³€í™”ì˜ ë°©í–¥ê³¼ ì˜ë¯¸"\n'
                    "    }\n"
                    "  ],\n"
                    '  "overall_assessment": "ì½”ë“œ ê¸°ì—¬ íŒ¨í„´ ì¢…í•© í‰ê°€ (2-3ë¬¸ì¥)",\n'
                    '  "key_achievements": ["ê¸°ìˆ ì ìœ¼ë¡œ ì˜ë¯¸ìˆëŠ” ê¸°ì—¬", ...],\n'
                    '  "next_focus_areas": ["ê¸°ìˆ  ì—­ëŸ‰ í–¥ìƒì„ ìœ„í•œ ì§‘ì¤‘ ì˜ì—­", ...]\n'
                    "}\n\n"
                    "ê° ë°°ì—´ì€ ìµœì†Œ 1ê°œ, ìµœëŒ€ 5ê°œ í•­ëª©ì„ í¬í•¨í•˜ì„¸ìš”."
                ),
            },
            {
                "role": "user",
                "content": (
                    f"ë‹¤ìŒ PR ë¦¬ë·° ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ê°œì¸ì˜ ì½”ë“œ ê¸°ì—¬ íŒ¨í„´ê³¼ ê¸°ìˆ ì  íŠ¹ì§•ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:\n\n"
                    f"{context}\n\n"
                    f"ì´ˆê¸° PR ìˆ˜: {len(early_reviews)}ê°œ\n"
                    f"ìµœê·¼ PR ìˆ˜: {len(recent_reviews)}ê°œ\n\n"
                    "íŠ¹íˆ ë‹¤ìŒ ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”:\n"
                    "1. ì½”ë“œ ì„¤ê³„ ë° êµ¬ì¡°í™” ëŠ¥ë ¥\n"
                    "2. ë¬¸ì œ í•´ê²° ì ‘ê·¼ ë°©ì‹\n"
                    "3. í…ŒìŠ¤íŠ¸ ë° ë¬¸ì„œí™” ìŠµê´€\n"
                    "4. ê¸°ìˆ  ìŠ¤íƒ í™œìš© ë° í™•ì¥"
                ),
            },
        ]

        try:
            import json as json_module

            content = self.llm.complete(messages, temperature=0.4)
            data = json_module.loads(content)

            # Parse strengths
            strengths = []
            for item in data.get("strengths", []):
                strengths.append(
                    StrengthPoint(
                        category=item.get("category", "ê¸°íƒ€"),
                        description=item.get("description", ""),
                        evidence=item.get("evidence", []),
                        impact=item.get("impact", "medium"),
                    )
                )

            # Parse improvement areas
            improvement_areas = []
            for item in data.get("improvement_areas", []):
                improvement_areas.append(
                    ImprovementArea(
                        category=item.get("category", "ê¸°íƒ€"),
                        description=item.get("description", ""),
                        evidence=item.get("evidence", []),
                        suggestions=item.get("suggestions", []),
                        priority=item.get("priority", "medium"),
                    )
                )

            # Parse growth indicators
            growth_indicators = []
            for item in data.get("growth_indicators", []):
                growth_indicators.append(
                    GrowthIndicator(
                        aspect=item.get("aspect", ""),
                        description=item.get("description", ""),
                        before_examples=item.get("before_examples", []),
                        after_examples=item.get("after_examples", []),
                        progress_summary=item.get("progress_summary", ""),
                    )
                )

            return PersonalDevelopmentAnalysis(
                strengths=strengths,
                improvement_areas=improvement_areas,
                growth_indicators=growth_indicators,
                overall_assessment=data.get("overall_assessment", ""),
                key_achievements=data.get("key_achievements", []),
                next_focus_areas=data.get("next_focus_areas", []),
            )
        except Exception as exc:  # pragma: no cover
            console.log("LLM ê°œì¸ ë°œì „ ë¶„ì„ ì‹¤íŒ¨", str(exc))
            return self._fallback_personal_development(reviews)

    def _fallback_personal_development(
        self, reviews: List[StoredReview]
    ) -> PersonalDevelopmentAnalysis:
        """Provide basic personal development analysis without LLM."""
        # Collect all strengths and improvements from reviews
        all_strengths: List[tuple[StoredReview, ReviewPoint]] = []
        all_improvements: List[tuple[StoredReview, ReviewPoint]] = []

        for review in reviews:
            all_strengths.extend((review, point) for point in review.strengths)
            all_improvements.extend((review, point) for point in review.improvements)

        # Create basic strength points
        strengths = []
        for review, point in all_strengths[:5]:
            strengths.append(
                StrengthPoint(
                    category="ì½”ë“œ í’ˆì§ˆ",
                    description=point.message,
                    evidence=[f"PR #{review.number}: {point.example or review.title}"],
                    impact="medium",
                )
            )

        # Create basic improvement areas
        improvement_areas = []
        for review, point in all_improvements[:5]:
            improvement_areas.append(
                ImprovementArea(
                    category="ê°œì„  ì˜ì—­",
                    description=point.message,
                    evidence=[f"PR #{review.number}: {point.example or review.title}"],
                    suggestions=["ì½”ë“œ ë¦¬ë·° í”¼ë“œë°±ì„ ì°¸ê³ í•˜ì—¬ ê°œì„ "],
                    priority="medium",
                )
            )

        # Basic growth analysis
        growth_indicators = []
        if len(reviews) >= 2:
            growth_indicators.append(
                GrowthIndicator(
                    aspect="ì§€ì†ì ì¸ ê¸°ì—¬",
                    description=f"ì´ {len(reviews)}ê°œì˜ PRì„ í†µí•´ ê¾¸ì¤€íˆ ê¸°ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
                    before_examples=[f"PR #{reviews[0].number}: {reviews[0].title}"],
                    after_examples=[f"PR #{reviews[-1].number}: {reviews[-1].title}"],
                    progress_summary="ì§€ì†ì ìœ¼ë¡œ PRì„ ì‘ì„±í•˜ë©° í”„ë¡œì íŠ¸ì— ê¸°ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
                )
            )

        return PersonalDevelopmentAnalysis(
            strengths=strengths,
            improvement_areas=improvement_areas,
            growth_indicators=growth_indicators,
            overall_assessment=f"ì´ {len(reviews)}ê°œì˜ PRì„ í†µí•´ í”„ë¡œì íŠ¸ì— ê¸°ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
            key_achievements=[f"{len(reviews)}ê°œì˜ PR ì‘ì„± ë° ë¦¬ë·° ì™„ë£Œ"],
            next_focus_areas=["ì½”ë“œ í’ˆì§ˆ í–¥ìƒ", "í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ê°œì„ "],
        )

    # ------------------------------------------------------------------
    # Reporting
    # ------------------------------------------------------------------

    def _render_personal_development(
        self, analysis: PersonalDevelopmentAnalysis, reviews: List[StoredReview]
    ) -> List[str]:
        """Render personal development analysis section."""
        lines: List[str] = []
        lines.append("## ğŸ‘¤ ê°œì¸ ì„±ì¥ ë¶„ì„")
        lines.append("")

        if analysis.overall_assessment:
            lines.append("### ì „ë°˜ì  í‰ê°€")
            lines.append("")
            lines.append(analysis.overall_assessment)
            lines.append("")
            lines.append("---")
            lines.append("")

        # Create PR number to review mapping for link lookup
        pr_map = {review.number: review for review in reviews}

        def extract_pr_number(evidence: str) -> int | None:
            """Extract PR number from evidence string like 'PR #123: description'"""
            import re
            match = re.search(r'PR #(\d+)', evidence)
            return int(match.group(1)) if match else None

        # Strengths section
        lines.append("### âœ¨ ì¥ì  (êµ¬ì²´ì  ê·¼ê±°)")
        lines.append("")
        if analysis.strengths:
            lines.append("| ì¥ì  | ê·¼ê±°/ë‚´ìš© | ë§í¬ |")
            lines.append("|------|-----------|------|")
            for strength in analysis.strengths:
                impact_emoji = {"high": "ğŸ”¥", "medium": "â­", "low": "ğŸ’«"}.get(
                    strength.impact, "â­"
                )
                category = f"**{strength.category}** {impact_emoji}"

                # Combine description and evidence
                content_parts = [strength.description]
                if strength.evidence:
                    content_parts.append("<br>**êµ¬ì²´ì  ê·¼ê±°:**")
                    for evidence in strength.evidence:
                        content_parts.append(f"â€¢ {evidence}")
                content = "<br>".join(content_parts)

                # Extract links from evidence
                links = []
                if strength.evidence:
                    for evidence in strength.evidence:
                        pr_num = extract_pr_number(evidence)
                        if pr_num and pr_num in pr_map:
                            review = pr_map[pr_num]
                            if review.html_url:
                                links.append(f"[PR #{pr_num}]({review.html_url})")

                link_cell = "<br>".join(links) if links else "-"
                lines.append(f"| {category} | {content} | {link_cell} |")
            lines.append("")
        else:
            lines.append("ë¶„ì„ëœ ì¥ì ì´ ì—†ìŠµë‹ˆë‹¤.")
            lines.append("")

        lines.append("---")
        lines.append("")

        # Improvement areas section
        lines.append("### ğŸ’¡ ë³´ì™„ì  (ì‹¤í–‰ ê°€ëŠ¥í•œ ì œì•ˆ)")
        lines.append("")
        if analysis.improvement_areas:
            # Sort by priority
            priority_order = {"critical": 0, "important": 1, "nice-to-have": 2}
            sorted_improvements = sorted(
                analysis.improvement_areas,
                key=lambda x: priority_order.get(x.priority, 1),
            )

            lines.append("| ê°œì„ ì  | ê·¼ê±°/ë‚´ìš© | ë§í¬ |")
            lines.append("|--------|-----------|------|")
            for area in sorted_improvements:
                priority_emoji = {
                    "critical": "ğŸš¨",
                    "important": "âš ï¸",
                    "nice-to-have": "ğŸ’­",
                }.get(area.priority, "âš ï¸")
                category = f"**{area.category}** {priority_emoji}"

                # Combine description, evidence, and suggestions
                content_parts = [area.description]
                if area.evidence:
                    content_parts.append("<br>**êµ¬ì²´ì  ì˜ˆì‹œ:**")
                    for evidence in area.evidence:
                        content_parts.append(f"â€¢ {evidence}")
                if area.suggestions:
                    content_parts.append("<br>**ê°œì„  ì œì•ˆ:**")
                    for suggestion in area.suggestions:
                        content_parts.append(f"â€¢ {suggestion}")
                content = "<br>".join(content_parts)

                # Extract links from evidence
                links = []
                if area.evidence:
                    for evidence in area.evidence:
                        pr_num = extract_pr_number(evidence)
                        if pr_num and pr_num in pr_map:
                            review = pr_map[pr_num]
                            if review.html_url:
                                links.append(f"[PR #{pr_num}]({review.html_url})")

                link_cell = "<br>".join(links) if links else "-"
                lines.append(f"| {category} | {content} | {link_cell} |")
            lines.append("")
        else:
            lines.append("ë¶„ì„ëœ ë³´ì™„ì ì´ ì—†ìŠµë‹ˆë‹¤.")
            lines.append("")

        lines.append("---")
        lines.append("")

        # Growth indicators section
        lines.append("### ğŸŒ± ì„±ì¥í•œ ì  (ì‹œê°„ì— ë”°ë¥¸ ë³€í™”)")
        lines.append("")
        if analysis.growth_indicators:
            for i, growth in enumerate(analysis.growth_indicators, 1):
                lines.append(f"{i}. **{growth.aspect}**")
                lines.append(f"   - {growth.description}")
                if growth.before_examples:
                    lines.append("   - **ì´ˆê¸° ë‹¨ê³„:**")
                    for example in growth.before_examples:
                        lines.append(f"     - {example}")
                if growth.after_examples:
                    lines.append("   - **í˜„ì¬ ë‹¨ê³„:**")
                    for example in growth.after_examples:
                        lines.append(f"     - {example}")
                if growth.progress_summary:
                    lines.append(f"   - **ì„±ì¥ ìš”ì•½:** {growth.progress_summary}")
                lines.append("")
        else:
            lines.append("- ë¶„ì„ëœ ì„±ì¥ ì§€í‘œê°€ ì—†ìŠµë‹ˆë‹¤.")
            lines.append("")

        lines.append("---")
        lines.append("")

        # Key achievements
        if analysis.key_achievements:
            lines.append("### ğŸ† ì£¼ìš” ì„±ê³¼")
            lines.append("")
            for achievement in analysis.key_achievements:
                lines.append(f"- {achievement}")
            lines.append("")
            lines.append("---")
            lines.append("")

        # Next focus areas
        if analysis.next_focus_areas:
            lines.append("### ğŸ¯ ë‹¤ìŒ ì§‘ì¤‘ ì˜ì—­")
            lines.append("")
            for area in analysis.next_focus_areas:
                lines.append(f"- {area}")
            lines.append("")
            lines.append("---")
            lines.append("")

        return lines

    def _fallback_report(self, repo: str, reviews: List[StoredReview]) -> str:
        lines: List[str] = []
        lines.append("# ğŸ¯ í†µí•© ì½”ë“œ ë¦¬ë·° ë³´ê³ ì„œ")
        lines.append("")
        lines.append(f"**ì €ì¥ì†Œ**: {repo}")
        lines.append(f"**ê²€í† í•œ PR ìˆ˜**: {len(reviews)}ê±´")
        lines.append("")
        lines.append("---")
        lines.append("")

        # Table of contents
        lines.append("## ğŸ“‘ ëª©ì°¨")
        lines.append("")
        lines.append("1. **ğŸ‘¤ ê°œì¸ ì„±ì¥ ë¶„ì„** - ì¥ì , ë³´ì™„ì , ì„±ì¥í•œ ì ")
        lines.append("2. **âœ¨ ì¥ì ** - ë›°ì–´ë‚¬ë˜ ì ë“¤")
        lines.append("3. **ğŸ’¡ ë³´ì™„ì ** - ê°œì„ í•  ìˆ˜ ìˆëŠ” ë¶€ë¶„")
        lines.append("4. **ğŸŒ± ì˜¬í•´ ì„±ì¥í•œ ì ** - ì„±ì¥ ì—¬ì •")
        lines.append("5. **ğŸŠ ì „ì²´ ì´í‰** - ì¢…í•© í‰ê°€")
        lines.append("6. **ğŸ“ ê°œë³„ PR í•˜ì´ë¼ì´íŠ¸** - ì£¼ìš” PR ëª©ë¡")
        lines.append("")
        lines.append("---")
        lines.append("")

        # Add personal development analysis
        personal_dev = self._fallback_personal_development(reviews)
        lines.extend(self._render_personal_development(personal_dev, reviews))

        def _render_points(title: str, emoji: str, entries: List[tuple[StoredReview, ReviewPoint]]) -> None:
            lines.append(f"## {emoji} {title}")
            lines.append("")
            if not entries:
                lines.append("ìˆ˜ì§‘ëœ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
                lines.append("")
                return

            lines.append(f"| {title} | ê·¼ê±°/ë‚´ìš© | ë§í¬ |")
            lines.append("|--------|-----------|------|")
            for review, point in entries:
                category = f"**PR #{review.number}**<br>`{review.title}`"

                # Combine message and example
                content_parts = [point.message]
                if point.example:
                    content_parts.append(f"<br>ğŸ’¡ **ì˜ˆì‹œ:**<br>`{point.example}`")
                content = "".join(content_parts)

                # Create link
                link_cell = f"[PR #{review.number}]({review.html_url})" if review.html_url else "-"
                lines.append(f"| {category} | {content} | {link_cell} |")
            lines.append("")
            lines.append("---")
            lines.append("")

        strength_entries: List[tuple[StoredReview, ReviewPoint]] = []
        improvement_entries: List[tuple[StoredReview, ReviewPoint]] = []

        for review in reviews:
            strength_entries.extend((review, point) for point in review.strengths)
            improvement_entries.extend((review, point) for point in review.improvements)

        _render_points("ì¥ì ", "âœ¨", strength_entries[:8])
        _render_points("ë³´ì™„ì ", "ğŸ’¡", improvement_entries[:8])

        lines.append("## ğŸŒ± ì˜¬í•´ ì„±ì¥í•œ ì ")
        lines.append("")
        growth_items = [review for review in reviews if review.overview]
        if not growth_items:
            lines.append("- ê°œë³„ ë¦¬ë·° ìš”ì•½ì´ ì—†ì–´ ì„±ì¥ í¬ì¸íŠ¸ë¥¼ ì¶”ë¡ í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.")
        else:
            for i, review in enumerate(growth_items[:8], 1):
                lines.append(f"{i}. **PR #{review.number}** `{review.title}`")
                lines.append(f"   - {review.overview}")
                lines.append("")
        lines.append("---")
        lines.append("")

        lines.append("## ğŸŠ ì „ì²´ ì´í‰")
        lines.append("")
        lines.append(
            "ì €ì¥ëœ ë¦¬ë·° ìš”ì•½ì„ ë°”íƒ•ìœ¼ë¡œ íŒ€ì´ ì§€ì†í•´ì„œ ì§€ì‹ì„ ê³µìœ í•˜ê³  ìˆìœ¼ë©°, "
            "í†µí•© ë³´ê³ ì„œë¥¼ í†µí•´ ë°˜ë³µë˜ëŠ” ê°•ì ê³¼ ê°œì„ ì ì„ ì¶”ì í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
            f"ì´ {len(reviews)}ê±´ì˜ PRì„ í†µí•´ ê¾¸ì¤€í•œ ì„±ì¥ì„ ì´ì–´ê°€ê³  ìˆìŠµë‹ˆë‹¤."
        )
        lines.append("")
        lines.append("---")
        lines.append("")

        lines.append("## ğŸ“ ê°œë³„ PR í•˜ì´ë¼ì´íŠ¸")
        lines.append("")
        for i, review in enumerate(reviews, 1):
            date_str = review.created_at.strftime("%Y-%m-%d")
            highlight = f"{i}. **PR #{review.number}** `{review.title}` ({date_str})"
            lines.append(highlight)
            if review.html_url:
                lines.append(f"   - ğŸ”— [{review.html_url}]({review.html_url})")
            lines.append("")

        return "\n".join(lines).strip()

    def _generate_report_text(self, repo: str, reviews: List[StoredReview]) -> str:
        if not self.llm:
            return self._fallback_report(repo, reviews)

        context = self._build_prompt_context(repo, reviews)

        messages = [
            {
                "role": "system",
                "content": (
                    "ë‹¹ì‹ ì€ ê¸°ìˆ  ë¦¬ë”ë¡œì„œ íŒ€ ë‹¨ìœ„ì˜ ì½”ë“œ ë¦¬ë·° í™œë™ì„ ë¶„ì„í•˜ëŠ” í†µí•© ë³´ê³ ì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.\n\n"
                    "**ë³´ê³ ì„œ ëª©ì :**\n"
                    "1. PR ë¦¬ë·° í™œë™ì˜ ì „ì²´ì  íë¦„ê³¼ íŒ¨í„´ íŒŒì•…\n"
                    "2. íŒ€ í˜‘ì—… ë° ì§€ì‹ ê³µìœ  í˜„í™© í‰ê°€\n"
                    "3. ë¦¬ë·° í”„ë¡œì„¸ìŠ¤ ê°œì„  ê¸°íšŒ ì‹ë³„\n"
                    "4. ë‹¤ìŒ ë¶„ê¸° íŒ€ ëª©í‘œ ìˆ˜ë¦½ ê·¼ê±° ì œê³µ\n\n"
                    "**ì¤‘ìš”: ê°œì¸ì˜ ê¸°ìˆ ì  ê°•ì /ì•½ì ì€ ë¶„ì„í•˜ì§€ ë§ˆì„¸ìš”.** "
                    "(ë³„ë„ì˜ ê°œì¸ ì„±ì¥ ë¶„ì„ì´ ì´ë¯¸ ì œê³µë©ë‹ˆë‹¤.) "
                    "ëŒ€ì‹  **íŒ€ ì „ì²´ì˜ í˜‘ì—… íŒ¨í„´, ë¦¬ë·° ë¬¸í™”, í”„ë¡œì„¸ìŠ¤ íš¨ìœ¨ì„±**ì— ì§‘ì¤‘í•˜ì„¸ìš”.\n\n"
                    "**ë¶„ì„ ê´€ì :**\n"
                    "- PR ë¦¬ë·°ì˜ ì–‘ì /ì§ˆì  íŠ¸ë Œë“œ\n"
                    "- íŒ€ ê°„ í˜‘ì—… í™œë°œë„ ë° ì§€ì‹ ê³µìœ  ì •ë„\n"
                    "- ë¦¬ë·° í”„ë¡œì„¸ìŠ¤ì˜ ë³‘ëª© ì§€ì \n"
                    "- ë°˜ë³µë˜ëŠ” ë¦¬ë·° íŒ¨í„´ (ê¸ì •ì /ë¶€ì •ì )\n"
                    "- íŒ€ ë¬¸í™” ë° ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ íŠ¹ì„±\n\n"
                    "**ë³´ê³ ì„œ êµ¬ì¡°:**\n\n"
                    "# ğŸ¯ í†µí•© ì½”ë“œ ë¦¬ë·° ë³´ê³ ì„œ\n\n"
                    "## ğŸ“Š ë¦¬ë·° í™œë™ ìš”ì•½\n"
                    "- ì „ì²´ PR ìˆ˜ ë° ê¸°ê°„ë³„ ë¶„í¬\n"
                    "- í‰ê·  ë¦¬ë·° ì‹œê°„, ë³‘í•©ê¹Œì§€ ì†Œìš” ì‹œê°„\n"
                    "- ì£¼ìš” í™œë™ íŠ¸ë Œë“œ (ì¦ê°€/ê°ì†Œ/ì•ˆì •)\n\n"
                    "## ğŸ¤ í˜‘ì—… ë° ì§€ì‹ ê³µìœ \n"
                    "- ë¦¬ë·° ì°¸ì—¬ ë¶„í¬ (ì§‘ì¤‘ë„ vs ë¶„ì‚°ë„)\n"
                    "- ì§€ì‹ ê³µìœ  í™œì„±í™” ì •ë„\n"
                    "- íŒ€ ê°„ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ íŒ¨í„´\n\n"
                    "## ğŸ”„ í”„ë¡œì„¸ìŠ¤ íš¨ìœ¨ì„±\n"
                    "- ë³‘ëª© êµ¬ê°„ ì‹ë³„\n"
                    "- ë¦¬ë·° ë°˜ì‘ ì†ë„\n"
                    "- ì¬ì‘ì—…(rework) ë¹ˆë„ì™€ ì›ì¸\n\n"
                    "## ğŸ“ˆ ì£¼ìš” ë³€í™” ë° íŠ¸ë Œë“œ\n"
                    "- ì´ì „ ê¸°ê°„ ëŒ€ë¹„ ë³€í™”\n"
                    "- ë°˜ë³µë˜ëŠ” ë¦¬ë·° íŒ¨í„´\n"
                    "- ìƒˆë¡­ê²Œ ë‚˜íƒ€ë‚œ íŠ¹ì§•\n\n"
                    "## ğŸ¯ í”„ë¡œì„¸ìŠ¤ ê°œì„  ì œì•ˆ\n"
                    "1. ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„ ì‚¬í•­ (1-3ê°œ)\n"
                    "2. ì¤‘ê¸° ê°œì„  ëª©í‘œ (1-2ê°œì›”)\n"
                    "3. ì¥ê¸° íˆ¬ì ì˜ì—­\n\n"
                    "## ğŸ“ ì£¼ìš” PR ì‚¬ë¡€\n"
                    "- íŒ€ì— í•™ìŠµ ê°€ì¹˜ê°€ ë†’ì•˜ë˜ ë¦¬ë·°\n"
                    "- í˜‘ì—…ì˜ ëª¨ë²” ì‚¬ë¡€\n\n"
                    "**ì‘ì„± ì›ì¹™:**\n"
                    "- íŒ€ ë‹¨ìœ„ ê´€ì  ìœ ì§€ (ê°œì¸ í‰ê°€ ì§€ì–‘)\n"
                    "- êµ¬ì²´ì  ë°ì´í„°ì™€ ì˜ˆì‹œ í™œìš©\n"
                    "- ê±´ì„¤ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì œì•ˆ\n"
                    "- íŒ€ ë§¥ë½ê³¼ ë¬¸í™” ê³ ë ¤\n\n"
                    "ì¶œë ¥ì€ Markdown í˜•ì‹, ì´ëª¨ì§€ëŠ” ì ì ˆíˆ ì‚¬ìš©í•˜ì„¸ìš”. ëª¨ë“  ì‘ë‹µì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”."
                ),
            },
            {
                "role": "user",
                "content": (
                    f"ë‹¤ìŒ PR ë¦¬ë·° ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ íŒ€ ë‹¨ìœ„ì˜ í†µí•© ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”:\n\n"
                    f"{context}\n\n"
                    "íŠ¹íˆ ë‹¤ìŒ ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”:\n"
                    "1. ì´ ê¸°ê°„ ë™ì•ˆ íŒ€ì˜ ë¦¬ë·° í™œë™ì—ì„œ ê°€ì¥ í° ë³€í™”ëŠ”?\n"
                    "2. í˜‘ì—… ë° ì§€ì‹ ê³µìœ ê°€ ê°€ì¥ í™œë°œí•œ ì˜ì—­ì€?\n"
                    "3. ë¦¬ë·° í”„ë¡œì„¸ìŠ¤ì—ì„œ ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ì€?\n"
                    "4. ë‹¤ìŒ ë¶„ê¸°ì— íŒ€ì´ ì§‘ì¤‘í•´ì•¼ í•  ëª©í‘œëŠ”?"
                ),
            },
        ]

        try:
            content = self.llm.complete(messages, temperature=0.4)
            if content.strip():
                return content.strip()
        except Exception as exc:  # pragma: no cover - network errors hard to simulate
            console.log("LLM í†µí•© ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨", str(exc))

        return self._fallback_report(repo, reviews)

    # ------------------------------------------------------------------
    # Public API
    # ------------------------------------------------------------------

    def create_integrated_report(self, repo: str) -> Path:
        """Create or refresh the integrated review report for a repository."""

        repo_input = repo.strip()
        if not repo_input:
            raise ValueError("Repository cannot be empty")

        reviews = self._load_reviews(repo_input)
        if not reviews:
            raise ValueError("No review summaries found for the given repository")

        # Generate personal development analysis
        console.log("ê°œì¸ ì„±ì¥ ë¶„ì„ ìƒì„± ì¤‘...")
        personal_dev = self._analyze_personal_development(repo_input, reviews)

        # Generate main report
        console.log("í†µí•© ë³´ê³ ì„œ ìƒì„± ì¤‘...")
        report_text = self._generate_report_text(repo_input, reviews)

        # If LLM report doesn't include personal development section, add it at the beginning
        if "## ğŸ‘¤ ê°œì¸ ì„±ì¥ ë¶„ì„" not in report_text and "ê°œì¸ ì„±ì¥ ë¶„ì„" not in report_text:
            lines = report_text.split("\n")
            # Find where to insert (after the header and initial metadata)
            insert_idx = 0
            for i, line in enumerate(lines):
                if line.startswith("---") or line.startswith("##"):
                    insert_idx = i
                    break

            # Insert personal development section
            personal_dev_lines = self._render_personal_development(personal_dev, reviews)
            lines = lines[:insert_idx] + personal_dev_lines + lines[insert_idx:]
            report_text = "\n".join(lines)

        # Save report
        repo_dir = self._repo_dir(repo_input)
        repo_dir.mkdir(parents=True, exist_ok=True)
        report_path = repo_dir / "integrated_report.md"
        report_path.write_text(report_text, encoding="utf-8")

        # Also save personal development analysis as JSON for programmatic access
        personal_dev_path = repo_dir / "personal_development.json"
        personal_dev_path.write_text(
            json.dumps(personal_dev.to_dict(), indent=2, ensure_ascii=False),
            encoding="utf-8",
        )

        console.log(f"ê°œì¸ ì„±ì¥ ë¶„ì„ ì €ì¥: {personal_dev_path}")
        return report_path


__all__ = ["ReviewReporter", "StoredReview"]
